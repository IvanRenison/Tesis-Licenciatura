\documentclass[12pt]{report}

\usepackage{fontspec}
\usepackage{polyglossia}
\setdefaultlanguage{spanish}

\usepackage{ccicons}

\usepackage{amsthm}
\usepackage{enumitem}
\usepackage[bookmarks]{hyperref}
\defaultfontfeatures{Renderer=Basic,Ligatures={TeX}}
\usepackage[math-style=ISO,bold-style=ISO]{unicode-math}
\setmathfont{Asana Math}
\usepackage{witharrows}
\WithArrowsOptions{displaystyle,i,tikz={font={\small\normalfont}},ygap=0.5em,wrap-lines} % Agregar fleqn para que se ponga a la izquierda

\usepackage{titlesec}
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries}  % Estilo del t√≠tulo
  {Cap√≠tulo \thechapter}                 % N√∫mero del cap√≠tulo
  {20pt}                        % Espacio entre el n√∫mero y el t√≠tulo
  {}                            % Formato del t√≠tulo
\titlespacing*{\chapter}{0pt}{-15pt}{25pt}  % Ajusta los m√°rgenes

\DeclareEmphSequence{\bfseries}

\hfuzz=1cm % Elimina warnings de "Overfull \hbox"

\usepackage[a4paper, margin=2cm, top=1cm, bottom=1cm]{geometry} % Adjust the margin values as desired

\usepackage{float}
\usepackage[ruled, vlined, linesnumbered, spanish]{algorithm2e}
\SetKw{Break}{break}
\SetKwFor{Loop}{loop}{}{end loop}

\usepackage{listings}
\lstset{basicstyle=\ttfamily} % Cambia la fuente a monospace
\usepackage{minted}
\setminted{autogobble}

\usepackage[capitalise, nameinlink]{cleveref}
\crefname{section}{Secci√≥n}{Secciones} % Para que use "Secci√≥n" en vez de "Apartado"
\crefname{subsection}{Subsecci√≥n}{Subsecciones} % Para que use "Subsecci√≥n" en vez de "Subapartado"

\usepackage[backend=biber, autolang=hyphen, bibencoding=inputenc, isbn=false, uniquename=false, style=alphabetic]{biblatex}
\addbibresource{biblio.bib}
% P√°gina para buscar citas: zbmath.org

\setlist[enumerate,1]{label={\em{(\arabic*)}}}

\usepackage{fancyhdr}
\setlength{\footskip}{0.6cm} % Evita que los n√∫meros de p√°gina se salgan de la p√°gina

\usepackage{pgfplots} % Para los gr√°ficos

\newtheoremstyle{customstyle} % <name>
{} % <Space above>
{} % <Space below>
{\slshape} % <Body font> % Preguntar que opinan, y porque hay un warning
{} % <Indent amount>
{\bfseries} % <Theorem head font>
{.} % <Punctuation after theorem head>
{.5em} % <Space after theorem head>
{} % <Theorem head spec (can be left empty, meaning `normal`)

\theoremstyle{customstyle}
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{definition}[theorem]{Definici√≥n}
\newtheorem{lemma}[theorem]{Lema}
\newtheorem{colorary}[theorem]{Colorario}
\newtheorem{problem}{Problema}
\newtheorem{observation}[theorem]{Observaci√≥n}
\addto\captionsspanish{\renewcommand{\proofname}{Demostraci√≥n}}
\renewenvironment{proof}[1][\proofname]{{\noindent \bfseries #1: }}{\qed} % Cambiar estilo del t√≠tulo de la demostraci√≥n

\newtheoremstyle{factstyle} % <name>
{} % <Space above>
{} % <Space below>
{\normalfont} % <Body font> % Preguntar que opinan, y porque hay un warning
{1.5em} % <Indent amount>
{\bfseries} % <Theorem head font>
{.} % <Punctuation after theorem head>
{.5em} % <Space after theorem head>
{} % <Theorem head spec (can be left empty, meaning `normal`)

\theoremstyle{factstyle}
\newtheorem{fact}{Afirmaci√≥n}[theorem]


\newcommand\cpp{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\relsize{-3}{\textbf{++}}}\xspace}
\newcommand\cppXX{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\relsize{-3}{\textbf{++}}}20\xspace}

\DeclareMathOperator{\sop}{sop}
\DeclareMathOperator{\lm}{lm}
\DeclareMathOperator{\lc}{lc}
\DeclareMathOperator{\lt}{lt}
\DeclareMathOperator{\tail}{tail}
\DeclareMathOperator{\amb}{amb}
\renewcommand{\S}{\text{S}}
\DeclareMathOperator{\B}{B}
\DeclareMathOperator{\spn}{span} % span est√° ocupado y re rompe todo si lo re-declaro
\DeclareMathOperator{\mat}{mat}
\DeclareMathOperator{\poli}{poli}
\DeclareMathOperator{\filas}{filas}

% Convenciones de uso de letras:
% X: Alfabeto
% K: Cuerpo
% R: Anillo
% I: Ideal
% G: Conjunto generador
% F: Conjunto de polinomios (que no sea un conjunto generador)
% f, g: Polinomios
% m: Monomios
% M: Conjunto de monomios
% c, k: Coeficiente de K
% a, b, c, d: Coeficientes de monomios
% Œ±: Ambig√ºedades
% n: L√≠mite de sumatorias
% i, j: √çndices

% Metadatos del PDF
\hypersetup{
  pdftitle = {Implementaci√≥n de bases de Gr√∂bner no conmutativas en C++ con un poquito de paralelismo},    % T√≠tulo del documento
  pdfauthor = {Iv√°n Ariel Renison}%,       % Autor del documento
  % pdfsubject = {Asunto o tema},         % Asunto o tema del documento
  % pdfkeywords = {palabras clave, XeLaTeX, metadatos}, % Palabras clave
  % pdfcreator = {XeLaTeX},               % Herramienta de creaci√≥n
  % pdfproducer = {XeLaTeX con hyperref}  % Productor del PDF
}


\begin{document}

\def\tituloTesis{Implementaci√≥n de bases de Gr√∂bner no conmutativas en \cpp con un poquito de paralelismo} % Repito el t√≠tulo porque en los metadatos tengo que poner C++ y ac√° \cpp
\input{Car√°tula}


\tableofcontents

\chapter{Introducci√≥n}

En este cap√≠tulo se explica informalmente de qu√© se trata la tesis.

Usted posiblemente haya escuchado hablar de los polinomios de varias variables, esos como $5 + 3 y - 2 x y + x^3 y^5$, y que todo el conjunto de los polinomios con, por ejemplo, variables $x, y$ sobre un cuerpo $K$ se denota como $K[x, y]$. En esos polinomios el producto entre las variables conmuta; por ejemplo, el polinomio $x y$ es igual al polinomio $y x$. Se puede considerar que el producto entre las variables no conmuta, as√≠ que por ejemplo, $x y ‚â† y x$; pero el producto de las variables con los coeficientes s√≠ sigue conmutando, por ejemplo $x 3 y = 3 x y$. As√≠ se obtiene algo como los polinomios, pero en el que los monomios son palabras. A esos nuevos polinomios se los llama polinomios no conmutativos y, por ejemplo, para las variables $x, y$ con coeficientes en un cuerpo $K$ se denotan $K‚ü®x, y‚ü©$. En general si $X$ es un alfabeto, $K‚ü®X‚ü©$ es el conjunto de los polinomios no conmutativos sobre $X$.

Un problema de decisi√≥n que existe sobre los polinomios no conmutativos es: dado un conjunto $G$ de polinomios no conmutativos y un polinomio no conmutativo $f$, decidir si $f$ se puede escribir como combinaci√≥n lineal de elementos de $G$ con coeficientes en $K‚ü®X‚ü©$, o escrito formalmente:

\begin{problem}\label{problem:principal}
  Dados $G$ un conjunto de polinomios no conmutativos y $f$ un polinomio no conmutativo, determinar si vale que
  \[ ‚àÉn ‚àà ‚Ñï, g_1, ‚Ä¶, g_n ‚àà G, f_1, ‚Ä¶, f_n, f'_1, ‚Ä¶, f'_n ‚àà K‚ü®X‚ü© : f = ‚àë_{i = 1}^n f_i g_i f'_i \text{.}\]
\end{problem}

Ac√° los $f_i$ y $f'_i$ se llaman cofactores. Este problema as√≠ planteado no es decidible, pero s√≠ es semi-decidible. Esto significa que no hay un algoritmo que dice si vale la expresi√≥n o no, pero s√≠ hay un algoritmo que en los casos en los que s√≠ vale termina diciendo que s√≠ y los casos en los que no vale puede no terminar.

El motivo por el cual no es decidible es que el problema de la palabra se reduce a esto. Ver \cite{web:wiki:WordPproblem} para informaci√≥n del problema de la palabra y la Secci√≥n 1.3 de \cite{article:MORA1994131} para saber c√≥mo es la reducci√≥n.

Para trabajar en algoritmos para ese problema se considera el conjunto $(G)$ (que as√≠ se denota) de todos los polinomios no conmutativos que satisfacen ese $‚àÉ$ y se calcula algo que se llama una base de Gr√∂bner de $(G)$, que puede ser finita o infinita computacionalmente enumerable. Son estos √∫ltimos casos los que hacen que el problema no sea computable. % Pongo computacionalmente enumerable y no solo enumerable porque enumerable no dice nada

Para calcular esas bases de Gr√∂bner hay dos algoritmos destacados, llamados el algoritmo de Buchberger y el algoritmo F4. Estos algoritmos, al igual que mucha de la teor√≠a, est√°n inspirados en la teor√≠a para resolver el problema an√°logo para los polinomios conmutativos. De hecho, muchos de los nombres de las cosas se usaron primero para el caso conmutativo y despu√©s se us√≥ el mismo nombre para el caso no conmutativo. Por ejemplo, ``algoritmo de Buchberger'' en otros contextos puede referirse al algoritmo para el caso conmutativo. En esta tesis siempre se estar√° hablando del caso no conmutativo. Para una explicaci√≥n del caso conmutativo ver \cite{book:ideals-varieties-algorithms}.

De antes de esta tesis existen varias implementaciones del algoritmo de Buchberger en el caso no conmutativo, por ejemplo \cite{lib:GBNP, lib:DGPS, lib:NCAlgebra}. El algoritmo F4 para el caso no conmutativo fue primero adaptado por Xiu Xingqiang en \cite{phdthesis:XiuXingqiang12} y est√° implementada en el sistema algebraico computacional Magma. Luego, Clemens Hofstadler hizo en \cite{thesis:Hof20} su propia implementaci√≥n en Python con SageMath, que es otro sistema algebraico computacional que al mismo tiempo es librer√≠a de Python (su elecci√≥n de SageMath la justifica en la Secci√≥n 6.2). Que yo sepa esas son las √∫nicas dos implementaciones de F4 para el caso no conmutativo.

La parte de implementar en \cpp esos algoritmos se logr√≥, pero hay una optimizaci√≥n que ayuda bastante y no se hizo. La parte de hacerlo correr en paralelo se hizo, pero solo para una parte y para la parte de la optimizaci√≥n que no se hizo tampoco se hizo nada en paralelo. Por lo tanto, la implementaci√≥n que se logr√≥ en los casos muy grandes no le logra ganar a la implementaci√≥n en Python con SageMath. Esto no significa que todo el trabajo no haya servido para nada, porque se podr√≠a continuar con el desarrollo del c√≥digo y lograr mejorar suficiente la implementaci√≥n para que sea al menos igual de buena que la de Python con SageMath.

Alguien podr√≠a preguntar para qu√© sirve tratar de resolver ese problema y calcular bases de Gr√∂bner no conmutativas. En el caso conmutativo hay un mont√≥n de aplicaciones pr√°cticas importantes, por ejemplo en rob√≥tica porque el caso conmutativo tiene mucho significado geom√©trico. En el caso no conmutativo en cambio las aplicaciones son m√°s limitadas, pero existen.

Algo para lo que las bases de Gr√∂bner no conmutativas son muy √∫tiles es para trabajar con √°lgebras presentadas por generadores y relaciones. En este contexto, los generadores son las variables y las relaciones est√°n dadas por los polinomios generadores del ideal. Un problema que ayuda a resolver las bases de Gr√∂bner es el c√°lculo de la dimensi√≥n de este tipo de √°lgebras. Por ejemplo, algunos investigadores de FAMAF (incluido Cristian Vay, el director de este trabajo) se enfrentan a este problema trabajando con (las que llaman) √°lgebras de Nichols, que est√°n explicadas en \cite{book:introNichols}. Usaremos algunos ejemplos de estas en el \cref{cap:Benchmarks}.

Tambi√©n hay algunas aplicaciones de bases de Gr√∂bner no conmutativas (y tambi√©n de conmutativas) en criptograf√≠a. En \cite{article:crypto_gb} se habla de eso.

En el \cref{cap:Preliminares} se explica toda la parte matem√°tica necesaria para entender el trabajo, incluyendo algunos temas que no son parte del tema de bases de Gr√∂bner, pero son necesaria para que la exposici√≥n sea autocontenida. En el \cref{cap:Librer√≠a} se explica como usar la librer√≠a que se desarroll√≥. En el \cref{cap:Implementaci√≥n} se explica como son las implementaciones. En el \cref{cap:Tests} se explica brevemente que tests se hicieron para que la librer√≠a ande bien. En el \cref{cap:Benchmarks} se muestran algunos resultados de benchmarks que se hicieron, comparando cosas dentro de la librer√≠a y comparando con la implementaci√≥n de Python con SageMath. Por √∫ltimo en el \cref{cap:Conclusiones} se destacan algunos puntos positivos del trabajo y se mencionan algunos trabajos futuros que se podr√≠an hacer.

\chapter{Preliminares}\label{cap:Preliminares}

En este cap√≠tulo se desarrolla toda la parte matem√°tica, basada principalmente en la exposici√≥n de \cite{thesis:Hof20}. Primero se explican sistemas de re-escritura, despu√©s se introduce el √°lgebra libre, se prueba que es un anillo, se dan algunas definiciones y propiedades de anillos y se definen las bases de Gr√∂bner. Por √∫ltimo se explican y dan seudoc√≥digos para los algoritmos de Buchberger y F4, que son los dos algoritmos importantes para calcular bases de Gr√∂bner no conmutativas.

El cap√≠tulo incluye demostraciones de muchos de los resultados expuestos pero quienes tengan inter√©s principalmente en la implementaci√≥n de los algoritmos pueden obviar su lectura o leerlas solo por encima.

\section{Sistemas de re-escritura}

Sistemas de re-escritura trata b√°sicamente sobre el estudio de relaciones entre objetos con la idea de usar las relaciones para convertir un objeto en otro. En general usaremos relaciones denotadas con alg√∫n s√≠mbolo con forma de flecha porque se tiene la idea de que se \textsl{usa} la relaci√≥n para convertir el objeto de la base de la flecha en el objeto de la punta de la flecha. Como recordatorio, una relaci√≥n entre $A$ y $B$ es un subconjunto de $A √ó B$ y una relaci√≥n sobre $A$ un subconjunto de $A^2$.

Para toda esta secci√≥n fijemos un conjunto $A$. Primero recordamos algunas operaciones muy comunes sobre relaciones.

\begin{definition}\label{def:operaciones relaciones}
  Dadas relaciones $‚Üí$ y $‚üø$ sobre $A$ se define:
  \begin{itemize}
    \item $‚Üí ‚àò ‚üø\ = \{(x, z) ‚àà A^2 : ‚àÉy ‚àà A : x ‚Üí y ‚àß y ‚üø z\}$.
    \item $‚Üí^0\ = \{(x, x) : x ‚àà A\}$.
    \item $‚Üí^{i + 1}\ =\ ‚Üí^i ‚àò ‚Üí$.
    \item $‚Üí^*\ = ‚ãÉ_{i = 0}^‚àû ‚Üí^i$.
    \item $‚Üê\ = \{(y, x) ‚àà A^2 : (x, y) ‚àà\ ‚Üí\}$.
    \item $‚Üî\ =\ ‚Üí ‚à™ ‚Üê$.
  \end{itemize}

  Con est√° definici√≥n se define autom√°ticamente tambi√©n $‚Üî^*$ que se llama la clausura reflexo-transitiva de $‚Üí$.
\end{definition}

Con $‚Üê$ y $‚Üî$ podr√≠a haber problema para usarlas con una relaci√≥n denotada por un s√≠mbolo que no tenga forma de flecha, pero en esta tesis las relaciones que se usan siempre se denotan con un s√≠mbolo con forma de flecha.

Para el resto de la secci√≥n fijemos una relaci√≥n $‚Üí$ sobre $A$. Tenemos los siguientes dos lemas.

\begin{lemma}\label{lemma:‚Üí* como ‚àÉ}
  Sean $a, b ‚àà A$. Entonces
  \[ a ‚Üí^* b ‚áî ‚àÉn ‚àà ‚Ñï ‚à™ \{0\}, x_0, ‚Ä¶, x_n ‚àà A : x_0 = a ‚àß x_n = b ‚àß ‚àÄi ‚àà \{1, ‚Ä¶, n\} : x_{i-1} ‚Üí x_i \text{.}\]
  \qed
\end{lemma}

\begin{lemma}\label{lemma:‚Üî* min equiv que contiene a ‚Üí}
  $‚Üî^*$ es la m√≠nima relaci√≥n de equivalencia que contiene a $‚Üí$.
  \qed
\end{lemma}

Como querremos hablar de usar $‚Üí$ para transformar un objeto en otro, es √∫til la pr√≥xima definici√≥n que permite hablar de una forma normal de un objeto como un elemento al que se llega aplicando $‚Üí$ hasta que no se pueda m√°s.

\begin{definition}\label{def:forma normal}
  Dados $a, b ‚àà A$ se define:
  \begin{itemize}
    \item $a$ est√° en forma normal $‚áî ‚àÑx ‚àà A : a ‚Üí x$.
    \item $b$ es forma normal de $a ‚áî a ‚Üí^* b ‚àß b$ est√° en forma normal.
    \item $a$ tiene forma normal $‚áî ‚àÉx ‚àà A : x$ es forma normal de $a$.
    \item $a ‚Üì b ‚áî ‚àÉx ‚àà A : a ‚Üí^* x ‚àß b ‚Üí^* x$.
  \end{itemize}
\end{definition}

Con $‚Üì$ pasa lo mismo que con $‚Üê$ y $‚Üî$ de que podr√≠a ser problem√°tico usarla para una relaci√≥n denotada con un s√≠mbolo que no tenga forma de flecha, pero en esta tesis eso no pasa.

Tambi√©n necesitamos definir las siguientes propiedades de las relaciones.

\begin{definition} Se define que
  \begin{itemize}
    \item $‚Üí$ es confluente $‚áî ‚àÄx, y, z ‚àà A : x ‚Üí^* y ‚àß x ‚Üí^* z ‚áí y ‚Üì z$.
    \item $‚Üí$ es Church-Rosser $‚áî ‚àÄx, y ‚àà A : x ‚Üî^* y ‚áî x ‚Üì y$.
    \item $‚Üí$ es normalizante $‚áî ‚àÄx ‚àà A : x$ tiene forma normal.
    \item $‚Üí$ es terminante $‚áî ‚àÑX ‚àà A^‚Ñï : ‚àÄi ‚àà ‚Ñï : X_i ‚Üí X_{i + 1}$.
  \end{itemize}
\end{definition}

Las siguientes propiedades referidas a relaciones ser√°n de utilidad.

\begin{theorem}\label{thm:terminante ‚áí normalizante}
  $‚Üí$ es terminante $‚áí¬†‚Üí$ es normalizante.
  \qed
\end{theorem}

\begin{theorem}\label{thm:confluente ‚áî Church-Rosser}
  $‚Üí$ es confluente $‚áî¬†‚Üí$ es Church-Rosser.
  \qed
\end{theorem}

Si $‚Üí$ es confluente y normalizante entonces todos los elementos tienen una √∫nica forma normal, y si adem√°s es terminante tenemos la siguiente observaci√≥n.

\begin{observation}\label{obs:‚Üí confluente y terminante}
  Si $‚Üí$ es confluente y terminante entonces calcular la forma normal de $a$ y de $b$ permite decidir si $a ‚Üî ^* b$.
  \qed
\end{observation}

Con esto ya est√° todo lo necesario sobre sistemas de re-escritura. Para aprender m√°s sobre el tema se puede leer \cite{book:term-rewriting}.

\section{√Ålgebra libre}

El √°lgebra libre es b√°sicamente el conjunto de los polinomios no conmutativos con sus operaciones. En los polinomios no conmutativos los monomios son palabras y la √∫nica operaci√≥n interna de los monomios (entre monomios y que devuelve monomios) es la multiplicaci√≥n, que equivale a la concatenaci√≥n de palabras.

\begin{definition}
  Sea $X$ un alfabeto finito. Se define la estructura $(‚ü®X‚ü©, ¬∑)$ de la siguiente manera:
  \begin{itemize}
    \item $‚ü®X‚ü©$ es el conjunto de palabras finitas sobre $X$.
    \item $¬∑ : ‚ü®X‚ü©^2 ‚Üí ‚ü®X‚ü©$ es la concatenaci√≥n.
  \end{itemize}
  Al par $(‚ü®X‚ü©, ¬∑)$ se lo llama el monoide libre sobre $X$, a los elementos de $‚ü®X‚ü©$ se los llama monomios libres sobre $X$ y a $¬∑$ el producto de $‚ü®X‚ü©$.

  Si $X = \{x_1, ‚Ä¶, x_n\}$ escribimos $‚ü®x_1, ‚Ä¶, x_n‚ü©$ en lugar de $‚ü®X‚ü©$.
\end{definition}

Por ejemplo, si $X = \{a, b, c\}$, algunos monomios son:

\begin{align*}
  m_0 &= abbcb \text{,} \\
  m_1 &= bbc \text{,} \\
  m_2 &= bcb \text{,} \\
  m_3 &= Œµ \text{,} \\
  m_1 ¬∑ m_2 &= bccbcb \text{.}
\end{align*}

El $Œµ$ de $m_3$ es la palabra vac√≠a. Notar que $m_1 ‚â† m_2$ ya que el producto es no conmutativo.

\

Para todo el resto de la tesis fijemos un alfabeto finito $X$.

\

En estos monomios, al igual que en los conmutativos, se puede hablar de que un monomio divida a otro, pero ac√° que un monomio divida a otro es equivalente a que sea una sub-palabra.

\begin{definition}
  Sean $m, m' ‚àà ‚ü®X‚ü©$. Se define que $m$ divida a $m'$, denotado como $m | m'$ de la siguiente forma:
  \begin{itemize}
    \item $m | m' ‚áî ‚àÉa , b ‚àà ‚ü®X‚ü© : m' = a m b$.
  \end{itemize}
\end{definition}

En el ejemplo de antes tenemos que $m_1 | m_0$ ya que $m_0 = a m_1 b$.

Hablar del resultado de la divisi√≥n es un poco m√°s complicado ac√° porque tendr√≠a que haber dos resultados, el $a$ y el $b$ de la definici√≥n, as√≠ que en ning√∫n momento hablaremos de dividir un monomio en otro ni escribiremos divisiones entre monomios.

M√°s adelante ser√° necesario tener un orden entre los elementos de $‚ü®X‚ü©$. Se podr√≠a fijar uno concreto definiendo directamente $‚â§$ para $‚ü®X‚ü©$, pero es mejor enunciar las m√≠nimas propiedades necesarias y trabajar con cualquier orden que las satisfaga. Eso se logra con la siguiente definici√≥n.

\begin{definition}\label{def:buen orden monomial}
  Sea $‚â§$ un orden total sobre $‚ü®X‚ü©$. Se define que $‚â§$ es un buen orden monomial si y solo si:
  \begin{enumerate}
    \item $‚àÄm, m', a, b ‚àà ‚ü®X‚ü© : m ‚â§ m' ‚áí a m b ‚â§ a m' b$.
    \item $‚àÄS ‚äÜ ‚ü®X‚ü© : S ‚â† ‚àÖ ‚áí S$ tiene m√≠nimo elemento con respecto a $‚â§$.
  \end{enumerate}
\end{definition}

Un ejemplo de orden que cumple con esta definici√≥n es el siguiente.

\begin{definition}
  Fijemos $X = \{x_1, ‚Ä¶, x_n\}$ y un orden total sobre $X$: $x_1 ‚â§ ‚Ä¶ ‚â§ x_n$, el cual se extiende (como es usual) de forma lexicogr√°fica a $‚ü®X‚ü©$. El orden lexicogr√°fico por grado $ ‚â§_{deglex}$ sobre $‚ü®X‚ü©$ se define as√≠:
  \[ m ‚â§_{deglex} m' ‚áî |m| < |m'| ‚à® (|m| = |m'| ‚àß m ‚â§ m') \text{.}\]
\end{definition}

O sea, el orden lexicogr√°fico por grado ordena primero por cardinalidad, tambi√©n llamado grado, y desempata con el orden lexicogr√°fico. Por ejemplo, tenemos que $bc ‚â§_{deglex} abb$, $aabbc ‚â§_{deglex} abbcc$ y $Œµ ‚â§_{deglex} a$. Se puede probar f√°cilmente que este orden es un buen orden monomial.

\

A partir de ahora fijamos un buen orden monomial $‚â§$ y usaremos $<$, $‚â•$ y $>$ como se usan habitualmente.

La siguiente propiedad es consecuencia directa de la definici√≥n de buen orden monomial.

\begin{theorem}\label{thm:‚â§ no sucesiones dec inf}
  La relaci√≥n $‚â§$ no tiene sucesiones estrictamente decrecientes infinitas.
  \qed
\end{theorem}

Ahora pasemos a hablar de sumar monomios entre s√≠ para tener polinomios no conmutativos.

\begin{definition}
  Sea $R$ un anillo conmutativo. Se define la $R$-√°lgebra libre sobre $X$ como el conjunto
  \[ R‚ü®X‚ü© = \{‚àë_{i = 1}^n c_i m_i : c_1, ‚Ä¶, c_n ‚àà R, m_1, ‚Ä¶, m_n ‚àà ‚ü®X‚ü©\}\]
  con las siguientes operaciones: la suma de los elementos de $R‚ü®X‚ü©$ como definido unir las $‚àë$, el producto por escalares definido como
  \[ c (‚àë_{i = 1}^n c_i m_i) = (‚àë_{i = 1}^n c c_i m_i) \text{,}\]
  y el producto entre elementos de $R‚ü®X‚ü©$ definido como
  \[ (‚àë_{i = 1}^n c_i m_i) ¬∑ (‚àë_{i = 1}^m c'_i m'_i) = ‚àë_{i = 1}^n ‚àë_{j = 1}^m c_i c'_j m_i m'_j \text{.}\]

  A los elementos de $R‚ü®X‚ü©$ se los llama polinomios no conmutativos. Cuando tengamos una lista de variables $x_1, ‚Ä¶, x_n$ escribimos $R‚ü®x_1, ‚Ä¶, x_n‚ü©$ en lugar de $R‚ü®\{x_1, ‚Ä¶, x_n\}‚ü©$.
\end{definition}

Algunos ejemplos de polinomios no conmutativos en $‚Ñö‚ü®a, b, c‚ü©$ son los siguientes:
\begin{align*}
  f_0 &= a \text{,} \\
  f_1 &= ab + cb \text{,} \\
  f_2 &= 3 abb - 2 acab + 4 bcca \text{.}
\end{align*}

\noindent Notar que $f_1 ‚â† ab + bc$ ya que el producto es no conmutativo.

Sobre los polinomios no conmutativos se hacen las siguientes definiciones.

\begin{definition}\label{def:cosas de polinomios}
  Sean $R$ un anillo conmutativo, $f ‚àà R‚ü®X‚ü©$, $c_1, ‚Ä¶, c_n ‚àà R - \{0\}$, $m_1, ‚Ä¶, m_n, m ‚àà ‚ü®X‚ü©$, $f = ‚àë_{i = 1}^n c_i m_i$ y $‚â§$ un buen orden monomial. Se definen:
  \begin{itemize}
    \item el coeficiente de $m$ en $f$ es $f_m = \begin{cases} c_0&\text{si }m = m_0 \\ ‚ãÆ & \\ c_n&\text{si }m = m_n \\ 0&\text{en otro caso} \end{cases} $.
    \item el soporte de $f$ es el conjunto $\sop(f) = \{m_1, ‚Ä¶, m_n\}$.
    \item el monomio principal de $f$ es $\lm_‚â§(f) = \max_‚â§(\sop(f))$.
    \item el coeficiente principal de $f$ es $\lc_‚â§(f) = f_{\lm_‚â§(f)}$.
    \item el t√©rmino principal de $f$ es $\lt_‚â§(f) = \lc_‚â§(f) ¬∑ \lm_‚â§(f)$.
    \item $\tail_‚â§(f) = f - \lt_‚â§(f)$.
  \end{itemize}

  Los nombres lm, lc, lt y tail vienen del ingl√©s leading monomial, leading coefficient, leading term y tail respectivamente.
\end{definition}

Siguiendo con el ejemplo tenemos:
\begin{align*}
  {f_2}_{abb} &= 3 \text{,} \\
  \sop(f_2) &= \{abb, acab, bcca\} \text{,} \\
  \lm_{‚â§_{deglex}}(f_2) &= bcca \text{,} \\
  \lc_{‚â§_{deglex}}(f_2) &= 4 \text{,} \\
  \lt_{‚â§_{deglex}}(f_2) &= 4 bcca \text{,} \\
  \tail_{‚â§_{deglex}}(f_2) &= 3 abb - 2 acab \text{.}
\end{align*}

Sobre estas definiciones valen muchas propiedades f√°ciles de probar, como por ejemplo $\lm_‚â§(f) \lm_‚â§(f') = \lm_‚â§(f f')$, que durante el resto de la tesis usaremos mucho, pero no las probamos una por una porque ser√≠a tedioso y aburrido.

M√°s adelante ser√° necesario comparar no solo monomios sino tambi√©n polinomios, as√≠ que el orden $‚â§$ se extiende a $K‚ü®X‚ü©$ as√≠:

\begin{definition}
  Sean $f, g ‚àà K‚ü®X‚ü©$. Se define que $f < g$ si y solo si vale alguna de las siguientes:
  \begin{enumerate}
    \item $f = 0 ‚àß g ‚â† 0$.
    \item $\lm_‚â§(f) < \lm_‚â§(g)$.
    \item $\lm_‚â§(f) = \lm_‚â§(g) ‚àß \tail_‚â§(f) < \tail_‚â§(g)$.
  \end{enumerate}
  Y como es usual $f ‚â§ g$ si y solo si $f < g ‚à® f = g$.
\end{definition}

Dicho en palabras, el orden en los polinomios es orden lexicogr√°fico con el polinomio visto como una lista de monomios, sin coeficientes, ordenada de mayor a menor. Por ejemplo, tenemos estas desigualdades en $K‚ü®X‚ü©$:
\begin{align*}
  a &< ab \text{,} \\
  bcc + c &< bcc + abb \text{,} \\
  ac &< ac + aa \text{.}
\end{align*}

Si bien a este $<$ lo estamos llamando (y lo continuaremos llamando) orden, en realidad no es un orden sino un preorden porque cuando solo cambian los coeficientes entre un polinomio y otro, ninguno de los polinomios es menor que el otro.

\begin{theorem}
  La relaci√≥n $<$ en $K‚ü®X‚ü©$ es un preorden parcial.
  \qed
\end{theorem}

Adem√°s, el polinomio $0$ es el m√≠nimo.

\begin{lemma}\label{lemma:0 es m√≠nimo}
  $0$ es el m√≠nimo de $<$.
  \qed
\end{lemma}

En este orden, al igual que para los monomios, vale que no hay sucesiones estrictamente decrecientes infinitas.

\begin{lemma}\label{lemma:‚â§ en KX no sucesiones dec inf}
  La relaci√≥n $‚â§$ en $K‚ü®X‚ü©$ no tiene sucesiones estrictamente decrecientes infinitas.
\end{lemma}
\begin{proof}
  Supongamos que existen sucesiones estrictamente decrecientes infinitas. Tomemos una sucesi√≥n estrictamente decreciente infinita $P$, o sea que valga $P_1 > P_2 > P_3 > ‚Ä¶$, que minimice $\lm_‚â§(P_1)$. Tomar este m√≠nimo es posible por el \cref{thm:‚â§ no sucesiones dec inf} que dice que no hay sucesiones estrictamente decrecientes infinitas en los monomios.

  Notemos que:

  \begin{fact}\label{fact:‚â§ en KX no sucesiones dec inf:1}
    $‚àÄi ‚àà ‚Ñï : \lm_‚â§(P_i) = \lm_‚â§(P_1)$.
  \end{fact}
  En efecto, no puede ser $\lm_‚â§(P_i) < \lm_‚â§(P_1)$ porque entonces $P_i, P_{i + 1}, ‚Ä¶$ ser√≠a una sucesi√≥n estrictamente decreciente infinita que romper√≠a la minimalidad de $\lm_‚â§(P_1)$ y no puede ser $\lm_‚â§(P_i) > \lm_‚â§(P_1)$ porque eso implicar√≠a $P_i > P_1$ y eso contradice que $P$ sea decreciente.

  \begin{fact}\label{fact:‚â§ en KX no sucesiones dec inf:2}
    $\tail_‚â§(P_1), \tail_‚â§(P_2), ‚Ä¶$ es una sucesi√≥n estrictamente decreciente infinita.
  \end{fact}
  Esto vale porque al aplicar la definici√≥n del orden polinomial sobre $P_1 > P_2 > P_3 > ‚Ä¶$ y usar la \cref{fact:‚â§ en KX no sucesiones dec inf:1} queda $\tail_‚â§(P_1) > \tail_‚â§(P_2) > \tail_‚â§(P_3) > ‚Ä¶$

  Como por el \cref{lemma:0 es m√≠nimo} $0$ es un m√≠nimo:

  \begin{fact}\label{fact:‚â§ en KX no sucesiones dec inf:3}
    $P_1 ‚â† 0$.
  \end{fact}

  Sin embargo, la \cref{fact:‚â§ en KX no sucesiones dec inf:2} contradice la minimalidad de $\lm_‚â§(P_1)$ ya que por la \cref{fact:‚â§ en KX no sucesiones dec inf:3} vale que $\lm_‚â§(\tail_‚â§(P_1)) < \lm_‚â§(P_1)$.

\end{proof}

La estructura del √°lgebra libre es un anillo, lo cual es muy √∫til por muchas definiciones y teoremas que ya existen sobre los anillos.

\begin{theorem}
  Sea $R$ un anillo conmutativo. Entonces
  \[ (R‚ü®X‚ü©, +, ¬∑)\text{ es un anillo} \text{.}\]
  \qed
\end{theorem}
% Tendr√≠a que decir algo de que no se incluye la demostraci√≥n porque es f√°cil?

Las definiciones y teoremas sobre anillos necesarios est√°n a continuaci√≥n.

\begin{definition}\label{def:ideal}
  Sean $R$ un anillo e $I ‚äÜ R$. Se define que $I$ es un ideal de $R$ si y solo si:
  \begin{enumerate}
    \item $I ‚â† ‚àÖ$.
    \item $‚àÄa, b ‚àà I : a + b ‚àà I$.
    \item $‚àÄa ‚àà I, r, r' ‚àà R : r a r' ‚àà I$.
  \end{enumerate}
\end{definition}

Los ideales son b√°sicamente conjuntos cerrados por la suma y por el producto por cualquier elemento del anillo. Si se tiene un conjunto que no es un ideal se puede agregar todo lo m√≠nimo necesario para convertirlo en un ideal. La siguiente definici√≥n define eso y el siguiente teorema dice que efectivamente se obtiene un ideal.

\begin{definition}\label{def:ideal gen}
  Sean $R$ un anillo y $G ‚äÜ R$. Se define el ideal generado por $G$, denotado $(G)$, como
  \[ (G) = \{‚àë_{i = 1}^n c_i g_i c_i' : n ‚àà ‚Ñï ‚à™ \{0\}, g_1, ‚Ä¶, g_n ‚àà G, c_1, ‚Ä¶, c_n, c_1', ‚Ä¶, c_n' ‚àà R\} \text{.}\]
  A los $c_i, c'_i$ se los llama cofactores. % ¬øEst√° bien poner esto as√≠?
\end{definition}

\begin{theorem}
  Sean $R$ un anillo y $G ‚äÜ R$. Entonces
  \[ (G)\text{ es un ideal de }R \text{.}\]
  \qed
\end{theorem}

Sobre los ideales generados por un conjunto valen los siguientes dos lemas b√°sicos.

\begin{lemma}\label{lemma:gen G = gen G U a con a ‚àà gen G}
  Sean $R$ un anillo, $G ‚äÜ R$ y $a ‚àà (G)$. Entonces
  \[ (G) = (G ‚à™ \{a\}) \text{.}\]
  \qed
\end{lemma}

\begin{lemma}\label{lemma:sub gen y sub gen ‚áî eq}
  Sean $R$ un anillo y $G, G' ‚äÜ R$. Entonces
  \[ G ‚äÜ (G') ‚àß G' ‚äÜ (G) ‚áî (G) = (G') \text{.}\]
  \qed
\end{lemma}


Cada ideal define una clase de equivalencia en el anillo, la cual se llama congruencia m√≥dulo el ideal.

\begin{definition}\label{def:congruencia mod ideal}
  Sean $R$ un anillo e $I ‚äÜ R$. Se define la relaci√≥n $‚â°_I$ en $R$ as√≠:
  \[ a ‚â°_I b ‚áî a - b ‚àà I \text{.}\]
\end{definition}

\begin{theorem}\label{thm:congruencia mod ideal es equivalencia}
  Sean $R$ un anillo e $I ‚äÜ R$ un ideal. Entonces
  \[ ‚â°_I \text{es una relaci√≥n de equivalencia} \text{.}\]
  \qed
\end{theorem}

Esta congruencia es parecida a la de los enteros m√≥dulo un natural (de hecho, la congruencia de los enteros m√≥dulo un natural es un subcaso de esta tomando como ideal a todos los m√∫ltiplos del m√≥dulo). Vale que la clase de equivalencia del $0$ es el propio ideal:

\begin{lemma}\label{lemma:en ideal ‚áî congruente 0}
  Sean $R$ un anillo, $I ‚äÜ R$ un ideal y $a ‚àà R$. Entonces
  \[ a ‚àà I ‚áî a ‚â°_I 0 \text{.}\]
  \qed
\end{lemma}

% Estar√≠a bueno citar alg√∫n libro para aprender m√°s sobre anillos

Ahora volvemos al √°lgebra libre y a partir de ahora fijamos un cuerpo $K$.

\begin{observation}
  Con las definiciones que tenemos ahora el \cref{problem:principal} se puede escribir como: dado un conjunto finito $G ‚äÜ K‚ü®X‚ü©$ y un elemento $f ‚àà K‚ü®X‚ü©$, determinar si $f ‚àà (G)$.
\end{observation}

Si bien $(G)$ para un anillo general est√° definido usando combinaciones lineales con coeficientes en el anillo, para el √°lgebra libre es √∫til la siguiente equivalencia que dice que alcanza con considerar solo monomios y elementos del cuerpo como cofactores.

\begin{lemma}\label{lemma:(G) equiv}
  Sea $G ‚äÜ K‚ü®X‚ü©$. Entonces
  \[ (G) = \{‚àë_{i = 0}^n c_i m_i g_i m'_i : n ‚àà ‚Ñï ‚à™ \{0\}, c_1, ‚Ä¶, c_n ‚àà K, m_1, ‚Ä¶, m_n, m'_1, ‚Ä¶, m'_n ‚àà ‚ü®X‚ü©, g_1,‚Äà‚Ä¶, g_n ‚àà G\} \text{.}\]
\end{lemma}
\begin{proof} Probemos que $f$ est√° en uno si y solo si est√° en el otro.
  \begin{description}
    \item[Ida ($‚áí$):] Supongamos $f ‚àà (G)$. Sean:

    \begin{itemize}
      \item $g_1, ‚Ä¶, g_n ‚àà G, f_1, ‚Ä¶, f_n, f'_1, ‚Ä¶, f'_n ‚àà K‚ü®X‚ü©$ tales que $f = ‚àë_{i = 1}^n f_i g_i f'_i$, los cuales existen porque estamos suponiendo $f ‚àà (G)$ y por la definici√≥n de $(G)$.
      \item Para cada $i ‚àà\{1, ‚Ä¶, n\}$:
      \begin{itemize}
        \item $c_{i, 1}, ‚Ä¶, c_{i, n_i} ‚àà K, m_{i, 1}, ‚Ä¶, m_{i, n_i} ‚àà ‚ü®X‚ü©$ tales que $f_i = ‚àë_{j = 1}^{n_i} c_{i, j} m_{i, j}$.
        \item $c'_{i, 1}, ‚Ä¶, c'_{i, n'_i} ‚àà K, m'_{i, 1}, ‚Ä¶, m'_{i, n'_i} ‚àà ‚ü®X‚ü©$ tales que $f'_i = ‚àë_{j = 1}^{n'_i} c'_{i, j} m'_{i, j}$.
      \end{itemize}
    \end{itemize}

    Con esto tenemos:
    \begin{DispWithArrows*}
      f &= ‚àë_{i = 1}^n f_i g_i f'_i \\
        &= ‚àë_{i = 1}^n (‚àë_{j = 1}^{n_i} c_{i, j} m_{i, j}) g_i (‚àë_{j = 1}^{n'_i} c'_{i, j} m'_{i, j}) \\
        &= ‚àë_{i = 1}^n ‚àë_{j = 1}^{n_i} ‚àë_{j' = 1}^{n'_i} c_{i, j} c'_{i, j'} m_{i, j} g_i m'_{i, j'} \text{.}
    \end{DispWithArrows*}

    Esto √∫ltimo es una expresi√≥n que se transforma a la forma que queremos. % ¬øEst√° bien esto?

    \item[Vuelta ($‚áê$):] La vuelta es cierta porque, como $c_i m_i, m'_i ‚àà K‚ü®X‚ü©$, es un caso particular de la definici√≥n.
  \end{description}
\end{proof}

\section{Reducci√≥n de polinomios}

Ahora definiremos una relaci√≥n de reducci√≥n en los polinomios no conmutativos la cual depende del orden monomial y de un conjunto generador $G$, cuya clausura reflexo-transitiva es igual a $‚â°_{(G)}$. La relaci√≥n que definiremos siempre es terminante, pero no siempre confluente. Para los casos en los que s√≠ sea confluente la \cref{obs:‚Üí confluente y terminante} nos permitir√° chequear si dos polinomios son equivalentes y en particular, por el \cref{lemma:en ideal ‚áî congruente 0}, si un polinomio est√° en $(G)$. A los casos en los que no sea confluente despu√©s trataremos de convertirlos en confluentes.

\begin{definition}\label{def:reducciones}
  Sean $G ‚äÜ K‚ü®X‚ü©$ y $f, f' ‚àà K‚ü®X‚ü©$. Se define la relaci√≥n $‚Üí_{‚â§, G}$ del siguiente modo:
  \[ f ‚Üí_{‚â§, G} f' ‚áî ‚àÉa, b ‚àà ‚ü®X‚ü©, g ‚àà G : \lm_‚â§(agb) ‚àà \sop(f) ‚àß f' = f - \frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb \text{.} \]
  Cuando vale $f ‚Üí_{‚â§, G}f'$ se dice que $f$ se reduce a $f'$ (v√≠a $G$).
\end{definition}

Por ejemplo, si tenemos $f = 2 cba + 3 dbcda$, $g_0 = a - bcd$ y $G = \{g_0\}$ tenemos:

\[f ‚Üí_{‚â§, G} f + 3d g_0 a = 3 daa + 2 cba \text{.}\]

\

Como ten√≠amos la \cref{def:operaciones relaciones} y la \cref{def:forma normal} quedan definidas autom√°ticamente las relaciones $‚Üí^*_{‚â§, G}$, $‚Üî^*_{‚â§, G}$ y $‚Üì_{‚â§, G}$.

A continuaci√≥n la prueba de que esta relaci√≥n efectivamente achica.

\begin{theorem}\label{thm:‚Üí achican}
  Sean $G ‚äÜ K‚ü®X‚ü©$ y $f, f' ‚àà K‚ü®X‚ü©$. Entonces
  \[ f ‚Üí_{‚â§, G} f' ‚áí f' < f \text{.} \]
\end{theorem}
\begin{proof}
  Supongamos el antecedente. Por definici√≥n de reducciones tomemos $a, b ‚àà ‚ü®X‚ü©, g ‚àà G$ tales que:
  \begin{enumerate}[label=(\roman*)]
    \item $\lm_‚â§(agb) ‚àà \sop(f)$. \label{thm:‚Üí achican:i}
    \item $f' = f - \frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb$. \label{thm:‚Üí achican:ii}
  \end{enumerate}

  Sean:
  \begin{itemize}
    \item $c_1, ‚Ä¶, c_n ‚àà K, m_1, ‚Ä¶, m_n ‚àà ‚ü®X‚ü©$ con $m_1 > m_2 > ‚ãØ > m_n$ tales que $f = ‚àë_{i = 1}^n c_i m_i$.
    \item $i$ tal que $m_i = \lm_‚â§(agb)$, el cual existe por \ref{thm:‚Üí achican:i}.
  \end{itemize}

  Notar tambi√©n que:

  \begin{enumerate}[label=(\roman*)]
    \setcounter{enumi}{2}
    \item $m_i = \lm_‚â§(\frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb)$. \label{thm:‚Üí achican:iii}
  \end{enumerate}

  \ref{thm:‚Üí achican:ii} y \ref{thm:‚Üí achican:iii} implican que los t√©rminos $c_1 m_1, c_2 m_2, ‚Ä¶, c_{i-1}, m_{i-1}$ son iguales en $f$ y en $f'$ y no hay nada m√°s en el medio, porque $f'$ es $f$ con t√©rminos menores o iguales a $\lm_‚â§(\frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb)$ restadas (por \ref{thm:‚Üí achican:ii}).

  Adem√°s, por \ref{thm:‚Üí achican:iii} y \ref{thm:‚Üí achican:ii} vale que $f'_{m_i} = 0$, por ende, el t√©rmino que sigue despu√©s de $m_{i-1}$ (si es que hay) es menor que $m_i$.

  Combinando que los primeros $i - 1$ t√©rminos son iguales y el $i$ es menor en $f'$ que en $f$, por la definici√≥n de $<$ para polinomios vale que $f' < f$.

\end{proof}

La relaci√≥n $‚Üí_{‚â§, G}$ tiene varias propiedades √∫tiles que se prueban a continuaci√≥n.

\begin{lemma}\label{lemma:suma ‚Üí‚Üì}
  Sean $G ‚äÜ K‚ü®X‚ü©$ y $f_0, f_1, f ‚àà K‚ü®X‚ü©$. Entonces
  \[ f_0 ‚Üí_{‚â§, G} f_1 ‚áí f_0 + f ‚Üì_{‚â§, G} f_1 + f \text{.}\]
\end{lemma}
\begin{proof}
  Supongamos el antecedente $f_0 ‚Üí_{‚â§, G} f_1$.

  Sean $g ‚àà G, a, b ‚àà K‚ü®X‚ü©$ tales que $f_1 = f_0 - \frac{{f_0}_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb $, los cuales existen por definici√≥n de $‚Üí_{‚â§, G}$.

  Dividamos la demostraci√≥n en casos seg√∫n la pertenencia de $\lm_‚â§(agb)$ a $\sop(f)$:

  \begin{description}
    \item[Caso $\lm_‚â§(agb) ‚àâ \sop(f)$:] Partiendo de la condici√≥n de $a, g, b$ hacemos lo siguiente:
    \begin{DispWithArrows*}
      &f_1 = f_0 - \frac{{f_0}_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} \\
      & ‚áí f_1 + f = f_0 - \frac{{f_0}_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} + f \Arrow{Definici√≥n de $‚Üí_{‚â§, G}$}\\
      & ‚áí f_0 + f ‚Üí_{‚â§, G} f_1 + f \Arrow{Definici√≥n de $‚Üì$, ambos se reducen a $f_1 + f$}\\
      & ‚áí f_0 + f ‚Üì_{‚â§, G} f_1 + f \text{.}
    \end{DispWithArrows*}

    \item[Caso $\lm_‚â§(agb) ‚àà \sop(f)$:]\
    \begin{description}
      \item[Subcaso $f_{\lm_‚â§(agb)} = -{f_0}_{\lm_‚â§(agb)}$]

      En este caso $\lm_‚â§(agb)$ se cancela en la suma $f_0 + f$. Y como adem√°s $\lm_‚â§(agb) ‚àâ \sop(f_1)$ por el antecedente, tenemos:
      \begin{DispWithArrows*}
        &f_1 + f ‚Üí_{‚â§, G} f_1 + f - \frac{f_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb \Arrow{Subcaso} \\
        & ‚áí f_1 + f ‚Üí_{‚â§, G} f_1 + f + \frac{{f_0}_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb \Arrow{Condici√≥n de $g$, $a$ y $b$} \\
        & ‚áí f_1 + f ‚Üí_{‚â§, G} f_0 + f \\
        & ‚áí f_1 + f ‚Üì_{‚â§, G} f_0 + f \text{.}
      \end{DispWithArrows*}

      \item[Subcaso $f_{\lm_‚â§(agb)} ‚â† -{f_0}_{\lm_‚â§(agb)}$:] En este caso $\lm_‚â§(agb)$ no se cancela en la suma $f_0 + f$, as√≠ que podemos aplicar $‚Üí_{‚â§, G}$ con $a$, $g$, $b$:
      \begin{DispWithArrows*}
        &f_0 + f ‚Üí_{‚â§, G} f_0 + f - \frac{(f_0 + f)_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb \\
        & ‚áí f_0 + f ‚Üí_{‚â§, G} f_0 + f - \frac{{f_0}_{\lm_‚â§(agb)} + f_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb \\
        & ‚áí f_0 + f ‚Üí_{‚â§, G} f_0 + f - \frac{{f_0}_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb - \frac{f_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb \Arrow{Condici√≥n de $g$, $a$ y $b$}\\
        & ‚áí f_0 + f ‚Üí_{‚â§, G} f_1 + f - \frac{f_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb  \text{.}
      \end{DispWithArrows*}
      ¬†¬†Llamemos (i) a este √∫ltimo resultado.

      Adem√°s por el caso y el hecho de que $\lm_‚â§(agb) ‚àâ \sop(f_1)$ tambi√©n tenemos $\lm_‚â§(agb) ‚àà \sop(f_1 + f)$, entonces:
      \begin{DispWithArrows*}
        &f_1 + f ‚Üí_{‚â§, G} f_1 + f - \frac{(f_1 + f)_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb \\
        & ‚áí f_1 + f ‚Üí_{‚â§, G} f_1 + f - \frac{{f_1}_{\lm_‚â§(agb)} + f_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb \Arrow{$\lm_‚â§(agb) ‚àâ \sop(f_1)$ porque $f_0 ‚Üí_{‚â§, G} f_1$ y definici√≥n de $‚Üí_{‚â§, G}$}\\
        & ‚áí f_1 + f ‚Üí_{‚â§, G} f_1 + f - \frac{0 + f_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb \\
        & ‚áí f_1 + f ‚Üí_{‚â§, G} f_1 + f - \frac{f_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb \text{.}
      \end{DispWithArrows*}
      ¬†¬†Llamemos (ii) a este √∫ltimo resultado.

      Por (i) e (ii) tenemos $f_0 + f ‚Üì_{‚â§, G} f_0' + f$. % No se como hacer esto con labels
    \end{description}
  \end{description}
\end{proof}

\begin{lemma}\label{lemma:prod mon ‚Üí}
  Sean $G ‚äÜ K‚ü®X‚ü©$, $f, f' ‚àà K‚ü®X‚ü©$, $c ‚àà K$ y $m, m' ‚àà ‚ü®X‚ü©$. Entonces
  \[ f ‚Üí_{‚â§, G} f' ‚áí c m f m' ‚Üí_{‚â§, G} c m f' m' \text{.}\]
\end{lemma}
\begin{proof} Supongamos el antecedente.

  Sean $g ‚àà G$ y $a, b ‚àà ‚ü®X‚ü©$ tales que $f' = f - \frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb$, los cuales existen por definici√≥n de $‚Üí_{‚â§, G}$. Tenemos:
  \begin{DispWithArrows*}
    &f' = f - \frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb \\
    & ‚áí c m f' m' = c m (f - \frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb) m' \\
    & ‚áí c m f' m' = c m f m' - \frac{{(c m f m')}_{\lm_‚â§(c ma g bm')}}{\lc_‚â§(g)}c ma g bm'  \Arrow{Definici√≥n $‚Üí_{‚â§, G}$} \\
    & ‚áí c m f' m' ‚Üí_{‚â§, G} c m f m' \text{.}
  \end{DispWithArrows*}

\end{proof}

Ahora el ya anunciado teorema de que la clausura reflexo transitiva de $‚Üí_{‚â§, G}$ es una congruencia.

\begin{theorem}\label{theorem:‚Üí^* = ‚â°}
  Sea $G ‚äÜ K‚ü®X‚ü©$. Entonces
  \[ ‚Üî^*_{‚â§, G}\ =\ ‚â°_{(G)} \text{.}\]
\end{theorem}
\begin{proof} Probemos las dos inclusiones.
  \begin{description}
    \item[Prueba de $‚Üî^*_{‚â§, G}\ ‚äÜ\ ‚â°_{(G)}$:] Como $‚Üî^*_{‚â§, G}$ y $‚â°_{(G)}$ son relaciones de equivalencia y adem√°s por el \cref{lemma:‚Üî* min equiv que contiene a ‚Üí} $‚Üî^*_{‚â§, G}$ es la m√≠nima relaci√≥n de equivalencia que contiene a $‚Üí_{‚â§, G}$, alcanza con probar $‚Üí_{‚â§, G}\ ‚äÜ\ ‚â°_{(G)}$. Para eso supongamos $f ‚Üí_{‚â§, G} f'$ y probemos $f ‚â°_{(G)} f'$.

    Sean $g ‚àà G, a, b ‚àà K‚ü®X‚ü©$ tales que $\lm_‚â§(agb) ‚àà f$ y $f' = f - \frac{f_{\lm_‚â§(agb)}}{g_{\lm_‚â§(agb)}} agb$, los cuales existen por definici√≥n de $‚Üí_{‚â§, G}$. Tenemos:
    \begin{DispWithArrows*}
      &f ‚â°_{(G)} f' \\
      & ‚áî f - f' ‚àà (G) \\
      & ‚áî f - (f - \frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb) ‚àà (G) \\
      & ‚áî \frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb ‚àà (G) \text{.}
    \end{DispWithArrows*}
    Y esto √∫ltimo es claramente cierto por la definici√≥n de (G) (\cref{def:ideal gen}).

    \item[Prueba de $‚â°_{(G)}\ ‚äÜ\ ‚Üî^*_{‚â§, G}$:] Supongamos $f ‚â°_{(G)} f'$ y probemos $f ‚Üî^*_{‚â§, G} f'$. Sean:
    \begin{itemize}
      \item $g = f - f'$.
      \item $c_1, ‚Ä¶, c_n ‚àà K, m_1, ‚Ä¶, m_n, m_1', ‚Ä¶, m_n' ‚àà ‚ü®X‚ü©$, $g_1, ‚Ä¶, g_n ‚àà G$ tales que $g = ‚àë_{i = 1}^n c_i m_i g_i m_i'$, los cuales existen porque por definici√≥n de $‚â°_G$ tenemos $g ‚àà (G)$ y por el \cref{lemma:(G) equiv}.
      \item $f_0 = f$.
      \item Para cada $i ‚àà \{1, ‚Ä¶, n\}$: $f_i = f_{i - 1} - c_i m_i g_i m_i'$.
    \end{itemize}

    Tenemos entonces:
    \begin{DispWithArrows*}
      &‚àÄi ‚àà \{1, ‚Ä¶, n\} : g_i ‚Üí_{‚â§, G} 0 \Arrow{\Cref{lemma:prod mon ‚Üí}} \\
      & ‚áí ‚àÄi ‚àà \{1, ‚Ä¶, n\} : c_i m_i g_i m_i' ‚Üí_{‚â§, G} 0 \Arrow{\Cref{lemma:suma ‚Üí‚Üì}} \\
      & ‚áí ‚àÄi ‚àà \{1, ‚Ä¶, n\} : c_i m_i g_i m_i' + f_i ‚Üì_{‚â§, G} 0 + f_i \Arrow{Definici√≥n de los $f_i$}\\
      & ‚áí ‚àÄi ‚àà \{1, ‚Ä¶, n\} : f_{i - 1} ‚Üì_{‚â§, G} f_i \\
      & ‚áí ‚àÄi ‚àà \{1, ‚Ä¶, n\} : f_{i - 1} ‚Üî^*_{‚â§, G} f_i \\
      & ‚áí f_0 ‚Üî^*_{‚â§, G} f_n \Arrow{$f_n = f - g = f'$} \\
      & ‚áí f ‚Üî^*_{‚â§, G} f_n \text{.}
    \end{DispWithArrows*}

  \end{description}
\end{proof}

\begin{lemma}\label{thm:‚Üí mantiene pertenencia a ideal}
  Sean $G ‚äÜ K‚ü®X‚ü©, f, f' ‚àà K‚ü®X‚ü©$. Entonces
  \[ f ‚Üí^*_{‚â§, G} f' ‚áí (f ‚àà (G) ‚áî f' ‚àà (G)) \text{.}\]
\end{lemma}
\begin{proof}
  Si asumimos $f ‚Üí^*_{‚â§, G} f'$, tenemos por el \cref{theorem:‚Üí^* = ‚â°} que $f ‚â°_{(G)} f'$ y entonces por el \cref{lemma:en ideal ‚áî congruente 0} vale que $f ‚àà (G) ‚áî f' ‚àà (G)$.
\end{proof}

\begin{theorem}
  Sea $G ‚äÜ K‚ü®X‚ü©$. Entonces
  \[ ‚Üí_{‚â§, G} \text{ es terminante.} \]
\end{theorem}
\begin{proof}
  Por contradicci√≥n. Supongamos que $‚Üí_{‚â§, G}$ no es terminante. Por definici√≥n podemos tomar una sucesi√≥n $P ‚àà K‚ü®X‚ü©^‚Ñï$ tal que:

  \[ ‚àÄi ‚àà ‚Ñï : P_i ‚Üí_{‚â§, G} P_{i+1}. \]

  \noindent Por el \cref{thm:‚Üí achican} tenemos que:

  \[ ‚àÄi ‚àà ‚Ñï : P_i > P_{i+1}. \]

  \noindent Pero esto contradice el \cref{lemma:‚â§ en KX no sucesiones dec inf} que dice que no hay sucesiones estrictamente decrecientes infinitas en $K‚ü®X‚ü©$.
\end{proof}

El siguiente teorema caracteriza las formas normales de $‚Üí$.

\begin{theorem}
  Sean $G ‚äÜ K‚ü®X‚ü©, f ‚àà K‚ü®X‚ü©$. Entonces
  \[ f\text{ est√° en forma normal con respecto a} ‚Üí_{‚â§, G} ‚áî ‚àÑg ‚àà G, m ‚àà \sop(f) : \lm_‚â§(g) | m \text{.}\]
\end{theorem}
\begin{proof} Probemos ida y vuelta por separado
  \begin{description}
    \item[Ida ($‚áí$):] por contradicci√≥n, supongamos el antecedente y que tenemos $g ‚àà G, m ‚àà \sop(f)$ tales que $\lm_‚â§(g) | m$.

    \noindent Sean $a, b ‚àà ‚ü®X‚ü©$ tales que $m = agb$, los cuales existen por la definici√≥n de divisibilidad.

    \noindent Entonces tenemos $f ‚Üí_{‚â§, G} f - \frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb$ y por ende $f$ no est√° en forma normal.

    \item[Vuelta ($‚áê$):] por contrarrec√≠proca, supongamos que $f$ no est√° en forma normal con respecto a $‚Üí_{‚â§, G}$ y probemos existe $g$ que satisface el $‚àÉ$. Sean:
    \begin{itemize}
      \item $f' ‚àà K‚ü®X‚ü©$ tal que $f ‚Üí_{‚â§, G} f'$, el cual existe por el antecedente.
      \item $a, b ‚àà ‚ü®X‚ü©, g ‚àà G$ tales que $\lm_‚â§(agb) ‚àà \sop(f)$ y $f' = f - \frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb$, los cuales existen por la definici√≥n de $‚Üí_{‚â§, G}$.
    \end{itemize}

    Con esto es claro que $g$ satisface el $‚àÉ$.
  \end{description}
\end{proof}

Probamos que $‚Üí_{‚â§, G}$ es terminante, pero no que sea confluente, ya que (como hab√≠amos anticipado) no siempre lo es. Por ejemplo, siguiendo con el mismo ejemplo de antes en el que ya ten√≠amos $f = 2 cba + 3 dbcda$, $g_0 = a - bcd$, si ahora agregamos $g_1 = b - cda$ y $G = \{g_0, g_1\}$ tenemos, como antes:

\[f ‚Üí_{‚â§, G} f + 3d g_0 a = 3 daa + 2 cba = f' \text{.}\]

\noindent Y tambi√©n:

\[f ‚Üí_{‚â§, G} f - 3db g_1 = 3 dbb + 2 cba = f'' \text{.}\]

\noindent Pero ning√∫n monomio principal de $G$ divide a ning√∫n monomio de $f'$ o $f''$ as√≠ que $f'$ y $f''$ no se pueden reducir m√°s.

La siguiente definici√≥n nos permite hablar m√°s c√≥modamente de una forma normal de un elemento (tanto en las definiciones y teoremas como en los algoritmos).

\begin{definition}\label{def:reductor}
  Sea $e_‚â§ : ùí´(K‚ü®X‚ü©) ‚Üí K‚ü®X‚ü© ‚Üí K‚ü®X‚ü©$. Se define que
  \[ e_‚â§\text{ es un reductor }‚áî ‚àÄG ‚äÜ K‚ü®X‚ü©, f ‚àà K‚ü®X‚ü© : e_‚â§(G)(f)\text{ es forma normal de }f\text{ con respecto a }‚Üí_{‚â§, G} \text{.} \]
\end{definition}

Un ejemplo de reductor podr√≠a calcularse con el siguiente seudoc√≥digo.

\begin{algorithm}[H] % La H es para que se quede ac√°, porque se iba a otra p√°gina. Estar√≠a bueno hacerlo global
  \caption{Ejemplo de reductor}\label{alg:reductor}
  \KwData{$G = \{g_1, ‚Ä¶, g_n\} ‚äÜ K‚ü®X‚ü©, f ‚àà K‚ü®X‚ü©$}
  \KwResult{$f' ‚àà K‚ü®X‚ü©$}
  $f' ‚Üê f$

  $i ‚Üê 1$

  \While{$i ‚â§ n$} {
    $r ‚Üê False$

    \For{$m ‚àà \sop(f')$} {
      \If{$\lm_‚â§(g_i) | m$} {
        calcular $a, b ‚àà ‚ü®X‚ü©$ tales que $m = a \lm_‚â§(g_i) b$
        $f' ‚Üê f' - \frac{f'_{\lm_‚â§(g_i)}}{\lc_‚â§(g_i)}a g_i b$

        $r ‚Üê True$

        \Break
      }
    }

    \If{$r$} {
      $i ‚Üê 1$
    } \Else {
      $i ‚Üê i + 1$
    }
  }
  \Return{$f'$}
\end{algorithm}

Este algoritmo consiste b√°sicamente en siempre buscar entre los elementos de $G$ si hay alguno con el cual reducir, y parar cuando ya no hay ninguno.

Una propiedad sobre los reductores que necesitaremos es que mantienen la pertenencia a ideales (lo cual tiene mucho sentido por la definici√≥n).

\begin{lemma}\label{lemma:e mantiene pertenencia a ideal}
  Sean $e_‚â§$ un reductor, $G ‚äÜ K‚ü®X‚ü©$ y $f ‚àà (G)$. Entonces
  \[ e_‚â§(G)(f) ‚àà (G) \text{.}\]
\end{lemma}
\begin{proof}
  Es consecuencia directa de la definici√≥n y del \cref{thm:‚Üí mantiene pertenencia a ideal}.
\end{proof}

\section{Bases de Gr√∂bner}

Que $‚Üí_{‚â§, G}$ fuera confluente siempre ser√≠a muy √∫til porque significar√≠a que para cualquier clase de equivalencia de $‚â°_{(G)}$ podr√≠amos siempre llegar a una misma forma normal y as√≠ determinar si dos elementos son equivalentes. En particular podr√≠amos determinar si un elemento est√° en el ideal viendo si se llega a $0$ como forma normal. Los casos en los que s√≠ es confluente se llaman bases de Gr√∂bner y despu√©s algo que haremos es calcularle una base de Gr√∂bner de un ideal generado por un conjunto que no es base de Gr√∂bner.

\begin{definition}\label{def:base de Gr√∂bner}
  Sean $I$ un ideal de $K‚ü®X‚ü©$ y $G ‚äÜ K‚ü®X‚ü©$. Se define que
  \[G\text{ es una base de Gr√∂bner de }I ‚áî (G) = I¬†‚àß ‚Üí_{‚â§, G}\text{ es confluente} \text{.} \]
  Adem√°s se dice que ``$G$ es una base de Gr√∂bner'' si lo es de alg√∫n ideal.
\end{definition}

Una consecuencia directa de la definici√≥n es el siguiente lema.

\begin{lemma}\label{lemma:‚Üí gr√∂bner es Church-Rosser}
  Sea $G$ una base de Gr√∂bner. Entonces
  \[‚Üí_{‚â§, G}\text{ es Church-Rosser.}\]
\end{lemma}
\begin{proof}
  Es una aplicaci√≥n directa del \cref{thm:confluente ‚áî Church-Rosser}.
\end{proof}

Las bases de Gr√∂bner se definieron por la propiedad m√°s importante que queremos que tengan, pero las siguientes equivalencias las har√°n mucho m√°s c√≥modas de trabajar.

\begin{theorem}\label{thm:equivalencias de base de Gr√∂bner}
  Sean $I$ un ideal de $K‚ü®X‚ü©$ y $G ‚äÜ K‚ü®X‚ü©$. Las siguientes afirmaciones son equivalentes:
  \begin{enumerate}
    \item $G$ es una base de Gr√∂bner de $I$. \label{thm:egb:1}

    \item $‚àÄf ‚àà K‚ü®X‚ü© : f ‚àà I ‚áî f ‚Üí^*_{‚â§, G} 0$. \label{thm:egb:2}

    \item $(G) = I ‚àß ‚àÄf ‚àà K‚ü®X‚ü© : f ‚àà I ‚áí f ‚Üí^*_{‚â§, G} 0$. \label{thm:egb:3}

    \item $(G) = I ‚àß ‚àÄf ‚àà I - \{0\} : ‚àÉg ‚àà G : \lm_‚â§(g) | \lm_‚â§(f)$. \label{thm:egb:4}

    \item $‚àÄf ‚àà I - \{0\} : ‚àÉc_1, ‚Ä¶, c_n ‚àà K, g_1, ‚Ä¶, g_n ‚àà G, a_1, ‚Ä¶, a_n, b_1, ‚Ä¶, b_n ‚àà ‚ü®X‚ü© : \lm_‚â§(a_i g_i b_i) ‚â§ \lm_‚â§(f) ‚àß f = ‚àë_{i = 1}^n c_i a_i g_i b_i$.  \label{thm:egb:5}
  \end{enumerate}
\end{theorem}
\begin{proof} Probaremos \ref{thm:egb:1} $‚áí$ \ref{thm:egb:2}, \ref{thm:egb:2} $‚áí$ \ref{thm:egb:3}, \ref{thm:egb:3} $‚áí$ \ref{thm:egb:1}, \ref{thm:egb:3} $‚áí$ \ref{thm:egb:2}, \ref{thm:egb:4} $‚áí$ \ref{thm:egb:3}, \ref{thm:egb:2} $‚áí$ \ref{thm:egb:5} y \ref{thm:egb:5} $‚áí$ \ref{thm:egb:4}.
  \begin{description}

    \item[\ref{thm:egb:1} $‚áí$ \ref{thm:egb:2}:] Supongamos que $G$ es una base de Gr√∂bner de $I$ y tomemos $f ‚àà K‚ü®X‚ü©$. Tenemos que probar $f ‚àà I ‚áî f ‚Üí^*_{‚â§, G} 0$. Vamos de un lado para el otro:
    \begin{DispWithArrows*}
      &f ‚àà I \Arrow{\Cref{lemma:en ideal ‚áî congruente 0}} \\
      & ‚áî f ‚â°_I 0 \Arrow{\Cref{theorem:‚Üí^* = ‚â°}} \\
      & ‚áî f ‚Üî^*_{‚â§, G} 0 \Arrow{Por \cref{lemma:‚Üí gr√∂bner es Church-Rosser}, $‚Üí_{‚â§, G}$ es Church-Rosser, definici√≥n de Church-Rosser} \\
      & ‚áî f ‚Üì_{‚â§, G} 0 \Arrow{Definici√≥n de $‚Üì$} \\
      & ‚áî ‚àÉf' ‚àà K‚ü®X‚ü© : f ‚Üí^*_{‚â§, G} f' ‚àß 0 ‚Üí^*_{‚â§, G} f' \Arrow{\Cref{thm:‚Üí achican} y \cref{lemma:0 es m√≠nimo}} \\
      & ‚áî ‚àÉf' ‚àà K‚ü®X‚ü© : f ‚Üí^*_{‚â§, G} f' ‚àß f' = 0 \\
      & ‚áî f ‚Üí^*_{‚â§, G} 0 \text{.}
    \end{DispWithArrows*}

    \item[\ref{thm:egb:2} $‚áí$ \ref{thm:egb:3}:] Supongamos el antecedente $‚àÄf ‚àà K‚ü®X‚ü© : f ‚àà I ‚áî f ‚Üí^*_{‚â§, G} 0$. Tenemos que probar que $(G) = I ‚àß ‚àÄf ‚àà K‚ü®X‚ü© : f ‚àà I ‚áí f ‚Üí^*_{‚â§, G} 0$. Probemos cada t√©rmino del $‚àß$ por separado:

    \begin{description}
      \item[Prueba de $(G) = I$:] Es cierto porque \ref{thm:egb:2} $‚áí$ \ref{thm:egb:1} y $(G) = I$ es parte de la definici√≥n de base de Gr√∂bner.
      \item[Prueba de $‚àÄf ‚àà K‚ü®X‚ü© : f ‚àà I ‚áí f ‚Üí^*_{‚â§, G} 0$:] Es cierto por \ref{thm:egb:2}.
    \end{description}

    \item[\ref{thm:egb:3} $‚áí$ \ref{thm:egb:1}:] Supongamos el antecedente $(G) = I ‚àß ‚àÄf ‚àà K‚ü®X‚ü© : f ‚àà I ‚áí f ‚Üí^*_{‚â§, G} 0$. Tenemos que probar que $G$ es una base de Gr√∂bner de $I$, es decir $(G) = I¬†‚àß ‚Üí_{‚â§, G}$ es confluente. La parte de $(G) = I$ es v√°lida porque es parte de \ref{thm:egb:3}.

    Para la otra parte, por definici√≥n de confluente, alcanza con probar $‚àÄf, f_0, f_1 ‚àà K‚ü®X‚ü© : f ‚Üí^*_{‚â§, G} f_0 ‚àß f ‚Üí^*_{‚â§, G} f_1 ‚áí f_0 ‚Üì_{‚â§, G} f_1$. En tal caso, vale por lo siguiente:
    \begin{DispWithArrows*}
      &f ‚Üí^*_{‚â§, G} f_0 ‚àß f ‚Üí^*_{‚â§, G} f_1 \\
      & ‚áí f_0 ‚Üî^*_{‚â§, G} f_1 \Arrow{\Cref{theorem:‚Üí^* = ‚â°}} \\
      & ‚áí f_0 ‚â°_{(G)} f_1 \Arrow{Definici√≥n de $‚â°_G$} \\
      & ‚áí f_0 - f_1 ‚àà (G) \Arrow{Antecedente} \\
      & ‚áí f_0 - f_1 ‚Üí^*_{‚â§, G} 0 \Arrow{\Cref{lemma:suma ‚Üí‚Üì}} \\
      & ‚áí (f_0 - f_1) + f_1 ‚Üì_{‚â§, G} 0 + f_1 \\
      & ‚áí f_0 ‚Üì_{‚â§, G} f_1 \text{.}
    \end{DispWithArrows*}

    \item[\ref{thm:egb:4} $‚áí$ \ref{thm:egb:3}:] Supongamos el antecedente $(G) = I ‚àß ‚àÄf ‚àà I - \{0\} : ‚àÉg ‚àà G : \lm_‚â§(g) | \lm_‚â§(f)$. Tenemos que probar $(G) = I ‚àß ‚àÄf ‚àà K‚ü®X‚ü© : f ‚àà I ‚áí f ‚Üí^*_{‚â§, G} 0$. La parte de $(G) = I$ es v√°lida porque es parte de \ref{thm:egb:4}. Para la otra parte prob√©moslo por contradicci√≥n. En particular tomemos el m√≠nimo $f$ tal que $f ‚àà I$ pero no se cumple que $f ‚Üí^*_{‚â§, G} 0$.

    Por \ref{thm:egb:4} sea $g ‚àà G$ tal que $\lm_‚â§(g) | \lm_‚â§(f)$ y sean tambi√©n:
    \begin{itemize}
      \item $a, b ‚àà ‚ü®X‚ü©$ tales que $a \lm_‚â§(g) b = \lm_‚â§(f)$.
      \item $f' = f - \frac{f_{\lm_‚â§(agb)}}{\lc_‚â§(g)}agb$.
    \end{itemize}

    Notar que:

    \begin{itemize}
      \item $f' ‚àà I$ ya que $f ‚àà I$ y $g ‚àà (G) = I$,
      \item $f ‚Üí_{‚â§, G} f'$ por definici√≥n de $‚Üí_{‚â§, G}$ y
      \item $f' < f$ por el \cref{thm:‚Üí achican}.
    \end{itemize}

    \noindent Ahora como no vale $f ‚Üí^*_{‚â§, G} 0$, tampoco puede valer $f' ‚Üí^*_{‚â§, G} 0$. Sin embargo, esto contradice que $f$ sea m√≠nimo.

    \item[\ref{thm:egb:2} $‚áí$ \ref{thm:egb:5}:] Supongamos \ref{thm:egb:2} y tomemos $f ‚àà I - \{0\}$.

    Por \ref{thm:egb:2} tenemos que $f ‚Üí^*_{‚â§, G} 0$.

    Sean:
    \begin{itemize}
      \item $n ‚àà ‚Ñï, f_0, ‚Ä¶, f_n ‚àà K‚ü®X‚ü©$ tales que $f_0 = f$, $f_n = 0$ y $f_0 ‚Üí_{‚â§, G} f_1 ‚Üí_{‚â§, G} ‚Ä¶ ‚Üí_{‚â§, G} f_n$, los cuales existen porque $f ‚Üí^*_{‚â§, G} 0$ y por el \cref{lemma:‚Üí* como ‚àÉ}.
      \item Para cada $i ‚àà \{1, ‚Ä¶, n\}$, $g_i ‚àà G, a_i, b_i ‚àà X$ tales que $\lm_‚â§(a_i g_i b_i) ‚àà \sop(f_{i-1})$ y $f_i = f_{i-1} - \frac{(f_{i-1})_{\lm_‚â§(a_i g_i b_i)}}{\lc_‚â§(g_i)}a_i g_i b_i$ los cuales existen por definici√≥n de $‚Üí_{‚â§, G}$.
    \end{itemize}

    Probaremos que el $‚àÉ$ de \ref{thm:egb:5}, se satisface con $c_i = \frac{(f_{i-1})_{\lm_‚â§(a_i g_i b_i)}}{\lc_‚â§(g_i)}, g_i, a_i, b_i$. O sea, tenemos que probar $\lm_‚â§(a_i g_i b_i) ‚â§ \lm_‚â§(f)$ y $f = ‚àë_{i = 1}^n \frac{(f_{i-1})_{\lm_‚â§(a_i g_i b_i)}}{\lc_‚â§(g_i)} a_i g_i b_i$.

    \begin{description}
      \item[Prueba de $\lm_‚â§(a_i g_i b_i) ‚â§ \lm_‚â§(f)$ fijando $i$:] Por el \cref{thm:‚Üí achican} y por transitividad de $<$ tenemos $f_{i-1} ‚â§ f$. Adem√°s tenemos $a_i g_i b_i ‚â§ f_{i-1}$ porque $\lm_‚â§(a_i g_i b_i) ‚àà \sop(f_{i-1})$, as√≠ que por transitividad de $‚â§$ vale $\lm_‚â§(a_i g_i b_i) ‚â§ \lm_‚â§(f)$.
      \item[Prueba de $f = ‚àë_{i = 1}^n \frac{(f_{i-1})_{\lm_‚â§(a_i g_i b_i)}}{\lc_‚â§(g_i)} a_i g_i b_i$:] Es consecuencia directa de como se eligieron los $g_i, a_i, b_i$.
    \end{description}

    \item[\ref{thm:egb:5} $‚áí$ \ref{thm:egb:4}:] Supongamos \ref{thm:egb:5} y probemos \ref{thm:egb:4}. Para eso tenemos que probar $(G) = I$ y $‚àÄf ‚àà I : ‚àÉg ‚àà G - \{0\} : \lm_‚â§(g) | \lm_‚â§(f)$.

    \begin{description}
      \item[Prueba de $(G) = I$:] Tomemos $f ‚àà I$ y probemos $f ‚àà (G)$.

      Por \ref{thm:egb:5} tenemos que $f = ‚àë_{i = 1}^n c_i a_i g_i b_i$ con $c_i ‚àà K$, $a_i, b_i ‚àà ‚ü®X‚ü©$ y $g_i ‚àà G$.

      Esto encaja exactamente con la definici√≥n de $(G)$, as√≠ que queda probado $f ‚àà (G)$.

      \item[Prueba de $‚àÄf ‚àà I - \{0\} : ‚àÉg ‚àà G : \lm_‚â§(g) | \lm_‚â§(f)$:] Fijemos $f ‚àà I - \{0\}$.

      Por \ref{thm:egb:5} tenemos que $f = ‚àë_{i = 1}^n c_i a_i g_i b_i$ con $c_i ‚àà K$, $a_i, b_i ‚àà ‚ü®X‚ü©$, $g_i ‚àà G$ y $\lm_‚â§(a_i g_i b_i) ‚â§ \lm_‚â§(f)$.

      Como $\lm_‚â§(a_i g_i b_i) ‚â§ \lm_‚â§(f)$, s√≠ o s√≠ tiene que pasar para alg√∫n $j$ que $\lm_‚â§(a_j g_j b_j) = \lm_‚â§(f)$ y para este $g_j$ vale que $\lm_‚â§(g_j) | \lm_‚â§(f)$.
    \end{description}

  \end{description}
  Con esto se termina la prueba.
\end{proof}

\begin{observation}
  \ref{thm:egb:2} del \cref{thm:equivalencias de base de Gr√∂bner} nos da una manera precisa de responder al \cref{problem:principal}. Para decidir si $f$ est√° en el ideal generado por $G$, primero le calculamos una base de Gr√∂bner al ideal y si la tiene, aplicamos el \cref{alg:reductor} con esta base y si el resultado es $0$ entonces $f$ est√° en el ideal.
\end{observation}

Combinando esta observaci√≥n con el \cref{lemma:sub gen y sub gen ‚áî eq} tenemos el siguiente colorario. % ¬øEst√° bien escrito colorario? Porque me lo pone como error

\begin{colorary}\label{col:(G) = (G') cond}
  Sean $G, G' ‚äÜ K‚ü®X‚ü©$ bases de Gr√∂bner, entonces
  \[ (G) = (G') ‚áî (‚àÄg ‚àà G : g ‚Üí_{‚â§, G'} 0) ‚àß (‚àÄg' ‚àà G' : g' ‚Üí_{‚â§, G} 0)\]
  \qed
\end{colorary}


\section{Algoritmo de Buchberger}

En esta secci√≥n se explica el primer algoritmo para calcular bases de Gr√∂bner llamado Algoritmo de Buchberger.

Antes de poder calcular bases de Gr√∂bner algo que estar√≠a bueno hacer es poder computar si un conjunto es una Base de Gr√∂bner, porque ninguna de las equivalencias del \cref{thm:equivalencias de base de Gr√∂bner} es directamente calculable porque hacen cuantificaciones sobre conjuntos infinitos. Para eso definiremos algo llamado S-polinomio de dos polinomios y los usaremos para enunciar un teorema que nos da una forma computable de determinar si un conjunto es una Base de Gr√∂bner. Los S-polinomios entre dos polinomios multiplican cada polinomio por monomios a cada lado y por un escalar de forma que los monomios principales se cancelen. O sea, para polinomios $f$ y $g$ tendremos una cuenta $k a f b - k' c g d$ de forma que se cancelen los monomios principales.

Primero definimos las ambig√ºedades, que representan los polinomios para los cuales puede pasar eso.

\begin{definition}
  Sean $m, m', a, b, c, d ‚àà ‚ü®X‚ü©$. Se define
  \[ (a, b, c, d, m, m')\text{ es una ambig√ºedad} ‚áî amb = cm'd \text{.}\]

  La ambig√ºedad $(a, b, c, d, m, m')$ se define como:
  \begin{itemize}
    \item de superposici√≥n $‚áî (a = Œµ = d ‚àß |b| < |m'| ‚àß |c| < |m|) ‚à® (b = Œµ = c ‚àß |a| < |m'| ‚àß |d| < |m|)$.
    \item de inclusi√≥n $‚áî a = Œµ = b ‚à® c = Œµ = d$.
    \item relevante $‚áî$ es de superposici√≥n o de inclusi√≥n.
  \end{itemize}

  Si $f, f' ‚àà K‚ü®X‚ü©$ se define que $(a, b, c, d, f, f')$ es una ambig√ºedad si y solo si $(a, b, c, d, \lm_‚â§{(f)}, \lm_‚â§{(f')})$ es una ambig√ºedad y lo mismo para ambig√ºedades de superposici√≥n, de inclusi√≥n y relevantes.

  Adem√°s se define
  \[ \amb(f, f') = \{(a, b, c, d, f, f') : (a, b, c, d, f, f')\text{ es una ambig√ºedad relevante}\} \text{.} \]

  Finalmente para $F ‚äÜ K‚ü®X‚ü©$ se define
  \[ \amb(F) = ‚ãÉ_{f, f' ‚àà F - \{0\}}{\amb(f, f')} \text{.} \]

\end{definition}

Notar que por como es la definici√≥n de ambig√ºedad, cuando es relevante siempre hay una parte de $m$ y una parte de $m'$ que son iguales y que no est√°n en los monomios $a$, $b$, $c$ y $d$. Los casos relevantes son los √∫nicos importantes, y por eso son los que se usan para definir $\amb$. No relevantes siempre hay entre cualquier par de monomios, por ejemplo tomando $a = d = Œµ$, $b = m'$ y $c = m$.

\begin{definition}
  Sean $a, b, c, d ‚àà ‚ü®X‚ü©, f, f' ‚àà K‚ü®X‚ü©$ y $Œ± = (a, b, c, d, f, f')$ una ambig√ºedad. Se define el S-polinomio de $Œ±$ como
  \[ \S(Œ±) = \frac{afb}{\lc_‚â§{(f)}} - \frac{cgd}{\lc_‚â§{(f')}} \text{.}\]
\end{definition}

Por ejemplo, si $f = 2 cba + 3 dbcda$ y $f' = b + bcd$, entonces una ambig√ºedad de inclusi√≥n ser√≠a

\[Œ± = (Œµ, Œµ, d, a, f, f') \text{.} \]

\noindent Siendo su S-polinomio

\[S(Œ±) = \frac{f}{3} - d f' a = \frac{2}{3} cba - dba  \text{.} \]

\noindent Y una ambig√ºedad de superposici√≥n ser√≠a

\[ Œ±' = (bc, Œµ, Œµ, bcda, f, f') \text{.} \]

\noindent Siendo su S-polinomio

\[ S(Œ±') = \frac{bc f}{3} - f' bcda = bbcda - \frac{2}{3} bccba \text{.} \]

\

Ahora probaremos que efectivamente los monomios principales se cancelan y despu√©s enunciaremos el teorema para decidir si un conjunto es una base de Gr√∂bner.

\begin{lemma}\label{lemma:lm ambs}
  Sean $Œ± = (a, b, c, d, f, g)$ una ambig√ºedad. Entonces:
  \[ \lm_‚â§{(afb)} = \lm_‚â§{(cgd)} \text{.}\]
\end{lemma}
\begin{proof}\
  Las siguientes igualdades siguen por la definici√≥n de ambig√ºedad tanto para monomios como para polinomios.
  \[ \lm_‚â§{(afb)} = a\lm_‚â§{(f)}b = c\lm_‚â§{(g)}d = \lm_‚â§{(cgd)} \text{.} \]
\end{proof}

Eso permite definir el monomio principal de una ambig√ºedad.

\begin{definition}
  Sean $Œ± = (a, b, c, d, f, g)$ una ambig√ºedad. Se define el monomio principal de $Œ±$ como

  \[ \lm_‚â§(Œ±) = \lm_‚â§(afb) \text{.}\]
\end{definition}

Notar que por el \cref{lemma:lm ambs} tambi√©n vale que $\lm_‚â§(Œ±) = \lm_‚â§(cgd)$.

Lo de que los monomios principales se cancelen produce el siguiente lema.

\begin{lemma}
  Sean $Œ± = (a, b, c, d, f, g)$ una ambig√ºedad. Entonces
  \[ \lm_‚â§(\S(Œ±)) < \lm_‚â§(Œ±) \text{.}\]
\end{lemma}
\begin{proof}
  Esto es porque en la resta $\frac{afb}{\lc_‚â§(f)} - \frac{cgd}{\lc_‚â§(g)}$ los monomios principales se cancelan.
\end{proof}

Otra propiedad importante es que estos S-polinomios son cerrados en el ideal, es decir, que el S-polinomio de dos elementos de un ideal es un elemento del ideal.

\begin{lemma}\label{lemma:S es cerrado en ideal}
  Sean $I ‚äÜ K‚ü®X‚ü©$ un ideal $f, g ‚àà I$ y $Œ± = (a, b, c, d, f, g)$ una ambig√ºedad. Entonces
  \[ \S(Œ±) ‚àà I \text{.}\]
\end{lemma}
\begin{proof}
  En la definici√≥n de $\S$ se ve que es una combinaci√≥n lineal de $f$ y $g$ con elementos de $K‚ü®X‚ü©$. M√°s precisamente, con los elementos $\frac{a}{\lc_‚â§{(f)}}$, $b$, $\frac{c}{\lc_‚â§{(g)}}$ y $d$. Como $f, g ‚àà I$ e $I$ es un ideal, esa combinaci√≥n pertenece a $I$.
\end{proof}

Ahora si enunciamos el teorema para decidir si un conjunto es una base de Gr√∂bner.

\begin{theorem}[Condici√≥n de Buchberger]\label{thm:condici√≥n de Buchberger}
  Sean $I$ un ideal de $K‚ü®X‚ü©$ y $G ‚äÜ K‚ü®X‚ü©$. Entonces son equivalentes:
  \begin{enumerate}
    \item $G$ es una base de Gr√∂bner de $I$.
    \item $‚àÄŒ± ‚àà \amb(G) : \S(Œ±) ‚Üí^*_{‚â§, G} 0$.
  \end{enumerate}
  \qed
\end{theorem}

La demostraci√≥n se puede encontrar por ejemplo en \cite{phdthesis:Hof23}, en donde algo similar a esto est√° enunciado en el Teorema 2.4.54. No lo demostramos ac√° porque requiere varios lemas adicionales que no son pertinentes para este trabajo.

Con esto ya se puede explicar la idea del algoritmo de Buchberger. Supongamos que tenemos un conjunto que no sabemos si es base de Gr√∂bner o no y estamos chequeando si lo es con el \cref{thm:condici√≥n de Buchberger}. Si nos encontramos con un S-polinomio $f$ que se reduce a un polinomio $g$ distinto de $0$ podemos agregar $g$ al conjunto y con eso $f$ pasa a s√≠ reducirse a $0$. Se podr√≠a pensar que agregar $g$ cambiar√≠a el ideal generado, pero por el \cref{lemma:S es cerrado en ideal} sabemos que $g$ es un elemento del ideal y por el \cref{thm:‚Üí mantiene pertenencia a ideal} eso implica que $f$ tambi√©n pertenece al ideal. Por ende por el \cref{lemma:gen G = gen G U a con a ‚àà gen G} se puede agregar al conjunto y que el ideal generado siga siendo el mismo. El problema de agregar un nuevo polinomio es que si bien hay un S-polinomio que pasa a s√≠ reducirse a $0$ tambi√©n aparecen nuevas ambig√ºedades. Eso sin embargo no es tanto problema porque lo que se hace es repetir hasta que en alg√∫n momento todas las ambig√ºedades se reducen a $0$. Si eso no pasa nunca simplemente el algoritmo no termina nunca, lo que refleja la no decidibilidad del problema de pertenencia a un ideal.

Ese proceso de agregar polinomios infinitamente lo definimos matem√°ticamente del siguiente modo.

\begin{definition}
  Sean $G ‚äÜ K‚ü®X‚ü©$ y $e_‚â§$ un reductor. Se definen:
  \begin{itemize}
    \item $\B_{e_‚â§}^0(G) = G$.
    \item $\B_{e_‚â§}^{i + 1}(G) = \B_{e_‚â§}^i(G) ‚à™ \{e_‚â§(\B_{e_‚â§}^i(G))(\S(Œ±)) : Œ± ‚àà \amb(\B_{e_‚â§}^i(G))\}$.
    \item $\B_{e_‚â§}(G) = ‚ãÉ_{i = 0}^‚àû \B_{e_‚â§}^i(G)$.
  \end{itemize}
  A $\B_{e_‚â§}(G)$ lo llamamos base de Buchberger de $(G)$.
\end{definition}

El nombre base de Buchberger es inventado para esta tesis, otros autores no le han dado ning√∫n nombre concreto a esos conjuntos.

Con el siguiente teorema se enuncia que la base de Buchberger es una base de Gr√∂bner y que si hay una base de Gr√∂bner finita entonces en alguna iteraci√≥n finita se llega, o sea, alg√∫n $B_{e_‚â§}^{i}(G)$ es igual a la base de Buchberger.

\begin{theorem}\label{thm:Buchberger correctitud}
  Sean $G ‚äÜ K‚ü®X‚ü©$ y $e_‚â§$ un reductor. Entonces
  \begin{enumerate}
    \item $\B_{e_‚â§}(G)$ es una base de Gr√∂bner de $(G)$. \label{thm:Buchberger correctitud:item:1}
    \item $(G)$ tiene una base de Gr√∂bner finita $‚áí ‚àÉi ‚àà ‚Ñï ‚à™ \{0\} : (\B_{e_‚â§}^i(G))$ es una base de Gr√∂bner. \label{thm:Buchberger correctitud:item:2}
  \end{enumerate}
\end{theorem}

Es esperable que \ref{thm:Buchberger correctitud:item:1} sea cierto por como definimos la base de Buchberger, mientras que \ref{thm:Buchberger correctitud:item:2} es m√°s sorprendente. Para demostrar ambos √≠tems primero probaremos algunos lemas en el contexto de este teorema, o sea con $G$ y $e_‚â§$ fijados.

\begin{lemma}\label{lemma:Buchberger correctitud:3}
  $‚àÄi ‚àà ‚Ñï ‚à™ \{0\} : \B_{e_‚â§}^{i}(G) ‚äÜ (G)$.
\end{lemma}
\begin{proof}
  Procedamos por inducci√≥n sobre $i$. El caso base se cumple porque $G ‚äÜ (G)$. Para el caso inductivo, supongamos que la afirmaci√≥n es cierta para $i$ y probemos que tambi√©n vale para $i + 1$. Para eso tomemos $f ‚àà \B_{e_‚â§}^{i + 1}(G)$ y probemos que $f ‚àà (G)$.

  Por la definici√≥n recursiva de $\B_{e_‚â§}^{i + 1}$ vale que $f ‚àà \B_{e_‚â§}^i(G) ‚à® ‚àÉŒ± ‚àà \amb(\B_{e_‚â§}^i(G)) : f = e_‚â§(\B_{e_‚â§}^i(G))(\S(Œ±))$. Dividamos en casos seg√∫n ese $‚à®$.

  \begin{description}
    \item[Caso $f ‚àà \B_{e_‚â§}^i(G)$:] Es v√°lido por ser exactamente la hip√≥tesis inductiva.
    \item[Caso $‚àÉŒ± ‚àà \amb(\B_{e_‚â§}^i(G)) : f = e_‚â§(\B_{e_‚â§}^i(G))(\S(Œ±))$:] En tal caso, por el \cref{lemma:e mantiene pertenencia a ideal} vale que $f ‚àà \B_{e_‚â§}^i(G)$ y por la hip√≥tesis inductiva que $f ‚àà (G)$.
  \end{description}

\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:4}
  $\B_{e_‚â§}(G) ‚äÜ (G)$.
\end{lemma}
\begin{proof}
  Esto es consecuencia directa del \cref{lemma:Buchberger correctitud:3} y la definici√≥n de $\B_{e_‚â§}$.
\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:5}
  $(\B_{e_‚â§}(G)) = (G)$.
\end{lemma}
\begin{proof}
  Por la definici√≥n de $\B_{e_‚â§}^i$ tenemos $G ‚äÜ \B_{e_‚â§}^i(G)$ y por ende $G ‚äÜ (\B_{e_‚â§}(G))$. Con el \cref{lemma:Buchberger correctitud:4} aplicando el \cref{lemma:sub gen y sub gen ‚áî eq} tenemos lo que queremos probar.
\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:6}
  $‚àÄŒ± ‚àà \amb(\B_{e_‚â§}(G)) : \S(Œ±) ‚Üí^*_{‚â§, \B_{e_‚â§}(G)} 0$.
\end{lemma}
\begin{proof}
  Tomemos $Œ± = (a, b, c, d, f, g) ‚àà \amb(\B_{e_‚â§}(G))$. Por definici√≥n de $\amb$ vale que $f, g ‚àà \B_{e_‚â§}(G)$, as√≠ que sean:
  \begin{itemize}
    \item $i ‚àà ‚Ñï$ el m√≠nimo tal que $f ‚àà \B_{e_‚â§}^i(G)$,
    \item $j ‚àà ‚Ñï$ el m√≠nimo tal que $g ‚àà \B_{e_‚â§}^j(G)$ y
    \item $k = \max(i, j)$.
  \end{itemize}

  \noindent Por definici√≥n de $\amb$ tiene que valer que
  \[ Œ± ‚àà \amb(\B_{e_‚â§}^k(G)) \]
  y entonces por definici√≥n de $\B_{e_‚â§}^i$ vale que
  \[ e_‚â§(\B_{e_‚â§}^k(G))(\S(Œ±)) ‚àà \B_{e_‚â§}^{k + 1}(G) \text{.} \]
  Esto implica que
  \[ e_‚â§(\B_{e_‚â§}^k(G))(\S(Œ±)) ‚Üí_{‚â§, \B_{e_‚â§}^{k + 1}(G)} 0\]
  y por ende que
  \[ e_‚â§(\B_{e_‚â§}^k(G))(\S(Œ±)) ‚Üí_{‚â§, \B_{e_‚â§}(G)} 0 \text{.} \]
  Llamemos (i) a esto √∫ltimo. Por otro lado, por definici√≥n de reductor tenemos que
  \[ \S(Œ±) ‚Üí^*_{‚â§, \B_{e_‚â§}^k(G)} e_‚â§(\B_{e_‚â§}^k(G))(\S(Œ±)) \]
  y por ende
  \[ \S(Œ±) ‚Üí^*_{‚â§, \B_{e_‚â§}(G)} e_‚â§(\B_{e_‚â§}^k(G))(\S(Œ±)) \text{.} \]
  Llamemos (ii) a esto √∫ltimo. Combinando (i) y (ii) vale que $\S(Œ±) ‚Üí^*_{‚â§, \B_{e_‚â§}(G)} 0$, que es lo que quer√≠amos probar.
\end{proof}

Con estos lemas ahora s√≠ hagamos la demostraci√≥n del \cref{thm:Buchberger correctitud}.

\begin{proof}[Demostraci√≥n del \cref{thm:Buchberger correctitud}]
  Por el \cref{lemma:Buchberger correctitud:5} y el \cref{lemma:Buchberger correctitud:6} vale la equivalencia de base de Gr√∂bner de la condici√≥n de Buchberger (\cref{thm:condici√≥n de Buchberger}), as√≠ que \ref{thm:Buchberger correctitud:item:1}, o sea, que $G$ es una base de Gr√∂bner queda probado.

  Para probar \ref{thm:Buchberger correctitud:item:2}, asumamos el antecedente, o sea, que $(G)$ tiene una base de Gr√∂bner finita, y tomemos una base finita $\{g_1, ‚Ä¶, g_n\}$. Ahora tenemos que probar el consecuente, o sea, que $‚àÉi ‚àà ‚Ñï ‚à™ \{0\} : (\B_{e_‚â§}^i(G))$ es una base de Gr√∂bner.  Para cada $i ‚àà \{1, ‚Ä¶, n\}$ sean:
  \begin{itemize}
    \item $g_{i, 1}, ‚Ä¶, g_{i, k_i} ‚àà \B_{e_‚â§}(G), a_{i, 1}, ‚Ä¶, a_{i, k_i}, b_{i, 1}, ‚Ä¶, b_{i, k_i} ‚àà ‚ü®X‚ü©$ con $\lm_‚â§(a_{i, j} g_{i, j} b_{i, j}) ‚â§ \lm_‚â§(g_i)$ tales que $g_i = ‚àë_{j = 1}^{k_i} a_{i, j} g_{i, j} b_{i, j}$. Los cuales existen por por \ref{thm:egb:5} del \cref{thm:equivalencias de base de Gr√∂bner}.

    \item $G' = \{g_{i, j} : i ‚àà \{1, ‚Ä¶, n\}, j ‚àà \{1, ‚Ä¶, k_i\}\}$.

    \item $k ‚àà ‚Ñï$ el m√≠nimo tal que $G' ‚äÜ \B_{e_‚â§}^k(G)$. Notar que $k$ est√° bien definido porque $G'$ es finito y los $g_{i, j}$ est√°n en $\B_{e_‚â§}(G)$.
  \end{itemize}

  Vamos a probar que $\B_{e_‚â§}^k(G)$ es una base de Gr√∂bner de $(G)$. Por \ref{thm:egb:5} del \cref{thm:equivalencias de base de Gr√∂bner} alcanza con probar:
  \[ ‚àÄf ‚àà (G) - \{0\} : ‚àÉg'_1, ‚Ä¶, g'_n ‚àà \B_{e_‚â§}^k(G), a_1, ‚Ä¶, a_n, b_1, ‚Ä¶, b_n ‚àà ‚ü®X‚ü© : \lm_‚â§(a_i g'_i b_i) ‚â§ \lm_‚â§(f) : f = ‚àë_{i = 1}^n a_i g'_i b_i \text{.}\]

  Tomemos $f ‚àà (G) - \{0\}$ y escrib√°moslo de esa forma. Por \ref{thm:egb:5} del \cref{thm:equivalencias de base de Gr√∂bner} y el hecho de que $\{g_1, ‚Ä¶, g_n\}$ es una base de Gr√∂bner, sean $i'_1, ‚Ä¶, i'_{n'} ‚àà \{1, ‚Ä¶, n\}, a'_1, ‚Ä¶, a'_{n'}, b'_1, ‚Ä¶, b'_{n'} ‚àà ‚ü®X‚ü©$ tales que:
  \begin{itemize}
    \item $\lm_‚â§(a'_i g_{i'_i} b'_i) ‚â§ \lm_‚â§(f)$ y
    \item $f = ‚àë_{i = 1}^{n'} a'_i g_{i'_i} b'_i$.
  \end{itemize}

  Con esto tenemos:

  \begin{DispWithArrows*}
    &f = ‚àë_{i = 1}^{n'} a'_i g_{i'_i} b'_i \Arrow{Condici√≥n de $g_{i, j}$} \\
    & = ‚àë_{i = 1}^{n'} a'_i (‚àë_{j = 1}^{k_{i'_i}} a_{i', j} g_{i, j} b_{i', j}) b'_i \\
    & = ‚àë_{i = 1}^{n'} ‚àë_{j = 1}^{k_i'} a'_i a_{i', j} g_{i, j} b_{i', j} b'_i \text{.}
  \end{DispWithArrows*}

  Sabemos adem√°s que $g_{i',j} ‚àà \B_{e_‚â§}^k(G)$ y que $g_{i', j} ‚â§ g_{i'_i} ‚â§ f$. As√≠ que queda $f$ escrito como quer√≠amos y la prueba queda completada.
\end{proof}

Con estos conjuntos podemos de forma directa dar un seudoc√≥digo que los calcula:

\begin{algorithm}[H] % La H es para que se quede ac√°, porque se iba a otra p√°gina. Estar√≠a bueno hacerlo global
  \caption{Algoritmo de Buchberger}\label{alg:Buchberger}
  \KwData{$G ‚äÜ K‚ü®X‚ü©$, $e_‚â§$ un reductor}
  \KwResult{$B ‚äÜ K‚ü®X‚ü©$ una base de Gr√∂bner de $(G)$ si es que termina}
  $B ‚Üê G$

  \Loop{} {
    $ambs ‚Üê \amb(B)$

    $B' ‚Üê B$

    \For{$Œ± ‚àà ambs$} {
      $f ‚Üê e_‚â§(B)(\S(Œ±))$

      \If{$f ‚â† 0$} {
        $B' ‚Üê B' ‚à™ \{f\}$
      }
    }

    \If{$B' = B$} {
      \Break
    }

    $B ‚Üê B'$
  }
  \Return{$B$}
\end{algorithm}

El algoritmo as√≠, si bien es una implementaci√≥n literal de la definici√≥n de los conjuntos $\B_{e_‚â§}^i$ que probamos que es correcta, es muy lento y necesita mejoras. Una mejora muy importante, probablemente la m√°s importante, consiste en usar tambi√©n los nuevos polinomios que ya fueron agregados para hacer las nuevas reducciones en el paso. Es decir, llamar a $e_‚â§$ con $B'$ en lugar de con $B$ en la l√≠nea 6. % Se podr√° hacer con un label esto?

Por lo visto antes el cambio tiene sentido que sea correcto y la prueba es similar a la del \cref{thm:Buchberger correctitud}. En la pr√°ctica esta mejora hace una diferencia inmensa en la eficiencia, pasa de no andar r√°pido casi nunca a andar r√°pido en una gran cantidad de casos. La justificaci√≥n te√≥rica de por qu√© hacer eso hace que pase a ser tanto m√°s r√°pido no la s√© ni la pude encontrar en la literatura.

Hay otras dos optimizaciones que se pueden hacer: una es para descartar algunas ambig√ºedades sin tener que reducirlas y la otra es para ir sacando algunos polinomios de la base. En la \cref{secton:optimizaciones} se aborda este tema.

\section{Algoritmo F4}

En esta secci√≥n se explica el algoritmo F4, que es otro m√©todo para calcular Bases de Gr√∂bner. La idea de F4 es considerar varias ambig√ºedades y reducir todos sus S-polinomios al mismo tiempo, reduciendo con los elementos que ya est√°n en la base y entre los propios S-polinomios que se est√°n considerando. Para esto se convierte el problema en una reducci√≥n por filas de una matriz, codificando cada monomio como una columna y cada polinomio como una fila. Para codificar los polinomios como filas de una matriz hacen falta algunas definiciones.

\begin{definition}
  Sea $F ‚äÜ K‚ü®X‚ü©$. Se define
  \[ \spn_K(F) = \{‚àë_{i = 1}^n c_i f_i : n ‚àà ‚Ñï, c_i ‚àà K, f_i ‚àà F\} \text{.} \]
\end{definition}

\begin{definition}
  Sean $M = \{m_1, ‚Ä¶, m_n\} ‚äÜ ‚ü®X‚ü©$ con $m_1 > ‚ãØ > m_n$. Se define la funci√≥n $\poli_M : K^n ‚Üí \spn_K(M)$ de la siguiente manera:
  \[ \poli_M(v) = ‚àë_{i = 1}^n v_i m_i \text{.} \]
\end{definition}

\begin{definition}
  Sean $M = \{m_1, ‚Ä¶, m_n\} ‚äÜ ‚ü®X‚ü©$ con $m_1 > ‚ãØ > m_n$. Se define $\mat_M : \spn_K(M) ‚Üí K^n$ como la inversa de $\poli_M$:
  \[ \mat_M(f) = \poli_M^{-1}(f) \text{.} \]
  Para una lista de polinomios se define que $\mat_M$ produzca una matriz:
  \[ \mat_M(f_1, ‚Ä¶, f_m) = \begin{pmatrix} \mat_M(f_1) \\ ‚ãÆ \\ \mat_M(f_m) \end{pmatrix} \text{.} \]
\end{definition}

Estas definiciones son un diccionario polinomios-matrices y matrices-polinomios en la que cada monomio se corresponde con una columna de la matriz.

Con esto, en la reducci√≥n, restar un polinomio multiplicado por un escalar y un monomio a cada lado a otro polinomio, o sea, hacer $f ‚Üê f - \frac{f_{\lm_‚â§(g)}}{\lc_‚â§(g)}a g b$ al reducir $f$ con $g$, la idea es que pase a ser restarle una fila multiplicada por un escalar a otra fila en la matriz, o sea, hacer $\text{fila}_i ‚Üê \text{fila}_i - c ¬∑ \text{fila}_j$.

Para poder hacer eso, al comenzar hay que tener en la matriz los polinomios a restar ya multiplicados por los monomios a cada lado, es decir, cuando va a hacer falta hacer $f ‚Üê f - \frac{f_{\lm_‚â§(g)}}{\lc_‚â§(g)}a g b$ hay que tener $agb$ en la matriz. Tener solo $g$ en la matriz no servir√≠a porque no coincidir√≠an los monomios y por ende no coincidir√≠an las columnas de la matriz.

Para eso definimos el algoritmo de preprocesamiento simb√≥lico que, dado el conjunto por el cual se reduce $G$ y el conjunto a reducir $F$, calcula todos los polinomios necesarios:

\begin{algorithm}[H] % La H es para que se quede ac√°, porque se iba a otra p√°gina. Estar√≠a bueno hacerlo global
  \caption{Preprocesamiento simb√≥lico}\label{alg:Preprocesamiento simb√≥lico}
  \KwData{$G, F ‚äÜ K‚ü®X‚ü©$ conjuntos finitos}
  \KwResult{$G' ‚äÜ \{agb : a, b ‚àà ‚ü®X‚ü©, g ‚àà G\}$}
  $G' ‚Üê ‚àÖ$

  $considerados ‚Üê ‚ãÉ_{g ‚àà P} \sop(g)$

  $T ‚Üê ‚ãÉ_{g ‚àà P} \sop(\tail_‚â§(g))$

  \While{$T ‚â† ‚àÖ$} {
    elegir $m ‚àà T$

    $T ‚Üê T - \{m\}$

    \For{$g ‚àà G$} {
      \If{$\lm_‚â§(g) | m$} {
        calcular $a$ y $b$ tales que $m = a \lm_‚â§(g) b$

        $G' ‚Üê G' ‚à™ {agb}$

        $nuevos ‚Üê \{m' ‚àà \sop(\tail_‚â§(agb)) : m' ‚àâ considerados\}$

        $T ‚Üê T ‚à™ nuevos$

        $considerados ‚Üê considerados ‚à™ nuevos$
      }
    }
  }

  \Return{$G'$}
\end{algorithm}

El seudoc√≥digo se puede entender como funciona analizandolo en detalle, pero lo importante es saber que calcula los polinomios que va a hacer falta que sean las filas de la matriz, y no importa demasiado entender como funciona por dentro. % ¬øEst√° "analizandolo" bien escrito?

Una vez que tenemos los monomios nesesarios, armamos la matriz correspondiente a $G$ y $F$ usando la funci√≥n $\mat_T$ y reducimos por fila esta matriz. Con la matriz no es obvio que hay que hacer, porque hay que solo considerar las filas que corresponden a los polinomios reducidos, pero no necesariamente son las mismas filas que eran antes los polinomios sin reducir porque la reducci√≥n por filas puede hacer cosas como intercambiar filas. Para saber cu√°les son esas filas lo que se hace es guardar cu√°les son los monomios principales de elementos del resultado del preprocesamiento simb√≥lico y despu√©s de hacer la reducci√≥n por filas agarrar solo las filas que tengan un uno principal en una columna que no corresponda a uno de esos monomios principales.

El siguiente seudoc√≥digo hace eso:

\begin{algorithm}[H] % La H es para que se quede ac√°, porque se iba a otra p√°gina. Estar√≠a bueno hacerlo global
  \caption{Multireducci√≥n}\label{alg:Multireducci√≥n}
  \KwData{$G, F ‚äÜ K‚ü®X‚ü©$ conjuntos finitos}
  \KwResult{$F' ‚äÜ K‚ü®X‚ü©$}
  $G' ‚Üê$ Preprocesamiento simb√≥lico$(G, F)$

  $monomios ‚Üê \{\lm_‚â§(g) : g ‚àà G'\}$

  $M ‚Üê \{m : m ‚àà \sop(g), g ‚àà G' ‚à™ F\}$

  $mat ‚Üê \mat_M(G' ‚à™ F)$

  reducir por filas $mat$

  $F' ‚Üê \{\poli_M(v) : v ‚àà \filas(mat) : v ‚â† 0 ‚àß \lm_‚â§(\poli_M(v)) ‚àâ monomios\}$

  \Return{$F'$}
\end{algorithm}

Con estos dos algoritmos ya podemos escribir el algoritmo F4:

\begin{algorithm}[H] % La H es para que se quede ac√°, porque se iba a otra p√°gina. Estar√≠a bueno hacerlo global
  \caption{F4}\label{alg:F4}
  \KwData{$G ‚äÜ K‚ü®X‚ü©$, $e_‚â§$ un reductor}
  \KwResult{$B ‚äÜ K‚ü®X‚ü©$ una base de Gr√∂bner de $(G)$ si es que termina}
  $B ‚Üê G$

  \Loop{} {
    $ambs ‚Üê \amb(B)$

    $B' ‚Üê B$

    \While{$ambs ‚â† ‚àÖ$} {
      elegir $Œë ‚äÜ ambs$

      $ambs ‚Üê ambs - Œë$

      $P ‚Üê \{\S(Œ±) : Œ± ‚àà Œë\}$

      $P ‚Üê$ Multireducci√≥n$(B', P)$

      $B' ‚Üê B' ‚à™ P$
    }

    \If{$B' = B$} {
      \Break
    }

    $B ‚Üê B'$
  }

  \Return{$B$}
\end{algorithm}

Este algoritmo no especifica cu√°les ambig√ºedades elegir, pero una buena estrategia es elegir todas las de menor grado. Otra opci√≥n es elegir todas, pero eso puede hacer que las matrices se vuelvan muy grandes r√°pidamente.

En \cite{thesis:Hof20} se da un algoritmo muy parecido a este (con una diferencia m√≠nima) y se demuestra que es correcto.

Las optimizaciones mencionadas en la secci√≥n de Buchberger para descartar ambig√ºedades y para quitar polinomios de la base tambi√©n se pueden hacer ac√°. Otra optimizaci√≥n que se puede hacer es usar un algoritmo de reducci√≥n de matrices que anda m√°s r√°pido en las matrices de este problema en particular, llamado eliminaci√≥n Faug√®re-Lachartre. Esto tambi√©n es abordado en la \cref{secton:optimizaciones}.

\chapter{Librer√≠a}\label{cap:Librer√≠a}

Como se dijo al principio, para esta tesis se implementaron los algoritmos de Buchberger y F4 en \cpp junto con estructuras para manejar polinomios no conmutativos en una librer√≠a llamada \texttt{ncgb}. La librer√≠a se encuentra disponible en el repositorio \href{https://github.com/IvanRenison/Non-commutative-Grobner-Bases}{\texttt{Non-commutative-Grobner-Bases}}. Este cap√≠tulo describe la estructura general de la librer√≠a y c√≥mo usarla en su versi√≥n actual (fecha de publicaci√≥n de esta tesis).

\section{Estructura de la librer√≠a}

El repositorio tiene varias carpetas, pero hay dos que son las m√°s relevantes para el o la usuaria. La primera es la carpeta \path{ncgb}, que es donde est√° alojada la librer√≠a en s√≠. Como la librer√≠a es gen√©rica sobre algunos par√°metros, se usan templates. Las clases y funciones gen√©ricas se definen en archivos \path{.hpp}, donde se incluye tanto su declaraci√≥n como su implementaci√≥n. La otra carpeta relevante es \path{mains}, que tiene varios archivos \path{.cpp} con funciones \texttt{main} que usan la librer√≠a. Estos archivos son √∫tiles para ver ejemplos de c√≥mo usar la librer√≠a.

Todo el c√≥digo de la librer√≠a est√° en el namespace \texttt{ncgb}. En todos los c√≥digos que veamos asumiremos que \texttt{ngcb} est√° abierto.

Los polinomios como los definimos en el \cref{cap:Preliminares} est√°n asociados a un cuerpo y un conjunto de variables; adem√°s muchas operaciones y m√©todos de los polinomios (y de otras definiciones) dependen de un orden monomial. Para que se puedan variar esas tres cosas se usan templates para hacer las funciones y estructuras de forma gen√©rica. Por ejemplo, la definici√≥n de polinomio es as√≠: % No se como reemplazar "cosas" ac√° porque son dos tipos y un orden

\begin{minted}{C++}
  template<typename K, typename X = __uint8_t, class ord = DegLexOrd<X>>
  struct Poly {
    // ‚Ä¶ Implementaci√≥n
  };
\end{minted}

El tipo \texttt{K} tiene que tener implementadas todas las operaciones de cuerpo. En particular, la librer√≠a asume que tiene definidas las siguientes operaciones y construcciones:

\begin{itemize}
  \item \texttt{+}, \texttt{-} (tanto unario como binario), \texttt{*} y \texttt{/} junto con sus versiones de asignaci√≥n \texttt{+=}, \texttt{-=}, \texttt{*=} y \texttt{/=}. De las versiones asignaci√≥n no se usa el resultado, solo el hecho de que modifican el operando izquierdo, as√≠ que pueden devolver \texttt{void}.
  % Miguel puso: No entiendo qu√© significa esto. ¬øEs relevante para que yo pueda definir un nuevo cuerpo?
  % Es relevante porque significa que pod√©s hacer que devuelvan void, y eso de hecho pasa en ModularArithmetic
  % No se como explicarlo de otra forma.
  \item \texttt{==} (y tambi√©n \texttt{!=}, pero a partir de \cppXX est√° autom√°ticamente con \texttt{==}).
  % Miguel sugiri√≥: (y tambi√©n !=. S√≥lo es necesario si se compila con un est√°ndar anterior a C++20 ).
  % No creo que compile con un C++ anterior al 20, pero, algo pasa es que si en C++ mayor o igual a 20 igual se define !=, se usa ese != definido a parte, no la negaci√≥n de ==. No me convence lo que sugiere Miguel por que no queda claro eso.
  \item \texttt{<<} para imprimir y \texttt{>>} para leer.
  \item Hacer \texttt{K(0)} y \texttt{K(1)} tiene que andar.
\end{itemize}

Y como es esperable, las operaciones tienen que cumplir todos los axiomas de cuerpos.

En este trabajo se usaron dos cuerpos distintos, los n√∫meros racionales, usando el tipo \texttt{mpq\_class} de la librer√≠a GMP que ya tiene todo lo que \texttt{K} tiene que tener (\cite{lib:gmp}) y la aritm√©tica modular con una implementaci√≥n propia en el archivo \path{extras/ModularArithmetic.hpp}, que sirve para ver un ejemplo de un cuerpo que anda con la librer√≠a (aunque tiene algunas operaciones extra).
% Lo de ModularArithmetic es gen√©rico para un n√∫mero, pero se rompe si el n√∫mero no es un primo

El tipo \texttt{X} se usa para representar las variables como n√∫meros y la idea es que se use alg√∫n tipo de n√∫meros sin signo. Usar otros tipos podr√≠a funcionar pero no est√° probado. Por defecto se usa \texttt{\_\_uint8\_t} que permite tener hasta 256 variables. Para usar m√°s variables hay que cambiarlo a un entero sin signo m√°s grande como \texttt{\_\_uint32\_t}.
% Miguel puso:
%   ¬øpor qu√© tienen que ser n√∫meros? ¬øes buena idea?
%   ¬øQu√© podr√≠a fallar? ¬øQu√© operaciones asum√≠s sobre X?
% Ni idea de que podr√≠a fallar, pero porque alguien querr√≠a usar otra cosa? O sea, el motivo para hacerlo gen√©rico es por si alguien lo quiere usar para m√°s de 256 variables, no para hacer cosas raras

Por √∫ltimo, \texttt{ord} es el orden monomial que se usa y est√° puesto por defecto \texttt{DegLexOrd} que es el orden lexicogr√°fico por grado y ya est√° definido junto con la definici√≥n de monomios. Para usar otro orden hay que definir una estructura que tenga un operador \texttt{()} que implemente el testeo del orden. Esta es la forma est√°ndar de definir √≥rdenes para usar en templates en \cpp. Algo as√≠ podr√≠a ser el c√≥digo si es una implementaci√≥n para un \texttt{X} gen√©rico:
% Miguel puso: ¬°Pero no d√°s la implementaci√≥n!
% Pero qu√© deber√≠a hacer?

\begin{minted}{C++}
  template<typename X>
  struct Orden {
    bool operator()(const Monomial<X>& a, const Monomial<X>& b) const {
      // ‚Ä¶ Implementaci√≥n
    }
  };
\end{minted}

Tanto para \texttt{X} como para \texttt{ord} los valores por defecto est√°n puestos solo en las estructuras de monomios y polinomios, porque en las otras funciones y estructuras no hace falta ya que para usarlas hay que ya tener un monomio o un polinomio (que se pase como argumento) y de ah√≠ \cpp infiere \texttt{X} y \texttt{ord} autom√°ticamente.
% Miguel puso: Esto puede ir antes.
% Pero no se donde podr√≠a ir antes

La librer√≠a tambi√©n tiene un Makefile con el que se pueden compilar los mains de la carpeta \path{mains} y correr los tests. Este Makefile puede servir de ejemplo de como se compila un archivo que usa la librer√≠a.

\section{Monomios}

Los monomios est√°n definidos en el archivo \path{ncgb/nc_monomial.hpp} y lo m√°s importante de su funcionalidad se puede resumir as√≠:

\begin{minted}{C++}
  template<typename X = __uint8_t>
  struct Monomial {
    Monomial();
    Monomial(const std::vector<X>& vals);

    bool operator==(const Monomial& m) const;
    Monomial operator*(const Monomial& m) const;
    void operator*=(const Monomial& m);
    size_t size() const;
    bool empty() const;

    // Returns the positions of m.vals where this monomial divides m
    std::vector<size_t> divide_indexes(const Monomial& m) const;

    // Does this monomial divides m?
    bool divides(const Monomial& m) const;

    // Make all possible divisions of m by this monomial
    std::vector<std::pair<Monomial, Monomial>> divide(const Monomial& m) const;

    friend std::ostream& operator<<(std::ostream& os, const Monomial& m);
    friend std::istream& operator>>(std::istream& is, Monomial& m);

    void nice_print(std::ostream& os = std::cout) const;
    static Monomial nice_read(std::istream& is = std::cin);
  };
\end{minted}

El √∫nico argumento del template es \texttt{X}, porque no hace falta nada del cuerpo ni tampoco un orden monomial (de hecho no tendr√≠a sentido que haga falta un orden monomial para definir monomios).

Relacionado a la divisi√≥n el m√©todo m√°s importante es \texttt{divide\_indexes} que se llama como \texttt{m0.divide\_indexes(m1)} y devuelve un vector de \texttt{size\_t} que indica las posiciones de \texttt{m1} donde empieza una sub-palabra igual a \texttt{m0}.

Respecto a la representaci√≥n como strings, hay dos pares de m√©todos. Por un lado est√°n \texttt{operator>>} y \texttt{operator<<} que leen y escriben en un formato num√©rico que es c√≥modo para usar en c√≥digo. Por otro lado \texttt{nice\_read} y \texttt{nice\_print} que leen y escriben en el formato que se suele usar al escribir a mano los monomios.

El formato num√©rico consiste en un n√∫mero entero no negativo $n$ seguido de $n$ n√∫meros $x_1$, ‚Ä¶, $x_n$ que son los n√∫meros de variables. Cuando $n = 0$ no hay ning√∫n $x_i$. Se puede representar as√≠ el formato:

$\begin{array}{llll} n & x_1 & ‚ãØ & x_n \end{array}$

Por ejemplo, ac√° hay un monomio en el formato como se suelen escribir a mano:

\begin{lstlisting}
  adbda
\end{lstlisting}

\noindent Y ac√° est√° el mismo monomio en el formato num√©rico:

\begin{lstlisting}
  5 0 3 1 3 0
\end{lstlisting}

Para declarar un monomio con \texttt{X = \_\_uint8\_t}, leerlo en formato num√©rico e imprimirlo en formato bonito se puede hacer as√≠:

\begin{minted}{C++}
  Monomial m;
  std::cin >> m;
  m.nice_print();
\end{minted}

En el mismo archivo \path{ncgb/nc_monomial.hpp} est√° definido el orden lexicogr√°fico por grado \texttt{DegLexOrd}.

\section{Polinomios}

Los polinomios est√°n definidos en el archivo \path{ncgb/nc_polynomial.hpp} y lo m√°s importante de su funcionalidad se puede resumir as√≠:

\begin{minted}{C++}
  template<typename K, typename X = __uint8_t, class ord = DegLexOrd<X>>
  struct Poly {
    Poly();
    Poly(const Monomial<X>& m, K c = K(1));
    Poly(std::vector<std::pair<Monomial<X>, K>> p);

    bool operator==(const Poly& p) const;

    Poly operator+(const Poly& p) const;
    Poly operator-(const Poly& p) const;
    Poly operator*(const Poly& p) const;
    Poly operator*(Monomial<X> m) const;
    Poly operator*(K c) const;
    Poly operator/(K c) const;
    Poly operator-() const;
    void operator+=(const Poly& p);
    void operator-=(const Poly& p);
    void operator*=(const Poly& p);
    void operator*=(Monomial<X> m);
    void operator*=(K c);

    K coeff(const Monomial<X>& m) const;

    const Monomial<X>& lm() const;
    K lc() const;
    Poly lt() const;
    bool monic() const;
    bool isZero() const;

    friend std::ostream& operator<<(std::ostream& os, const Poly& p);
    friend std::istream& operator>>(std::istream& is, Poly& p);

    void nice_print(std::ostream& os = std::cout) const;
    static Poly nice_read(std::istream& is = std::cin);
  };
\end{minted}

Para construir un polinomio hay tres constructores: el constructor vac√≠o que produce el polinomio $0$, un constructor que toma un monomio $m$ y un elemento del cuerpo $c$ y produce el polinomio $cm$, y un constructor que toma un vector de pares monomio-coeficiente y produce el polinomio que es la suma de cada coeficiente multiplicado con su monomio.

El tipo \texttt{Poly} tiene implementadas todas las operaciones entre polinomios (como la suma) con los operadores correspondientes (como \texttt{operator+} y \texttt{operator+=}, por ejemplo), m√©todos algunas de las cosas definidas en la \cref{def:cosas de polinomios} (\texttt{coeff}, \texttt{lm}, \texttt{lc} y \texttt{lt}) y m√©todos relacionados a la representaci√≥n de los polinomios como strings. % No se porque remplazar "cosas" ac√°

Al igual que con los monomios, para la representaci√≥n como strings, hay dos pares de m√©todos: \texttt{operator>>} y \texttt{operator<<} para formato num√©rico, y \texttt{nice\_print} y \texttt{nice\_read} para formato visualmente bonito.

El formato num√©rico consiste en, primero, un n√∫mero entero no negativo $k$ que es la cantidad de t√©rminos, seguido de la descripci√≥n de $k$ t√©rminos. La descripci√≥n de cada t√©rmino consiste en primero el coeficiente y despu√©s la descripci√≥n del monomio en el formato num√©rico de los monomios. Se puede representar as√≠ el formato:

$\begin{array}{llllll}
  k &&&& \\
  c_1 & n_1 & x_{1, 1} & ‚ãØ & x_{1, n_1} \\
  ‚ãÆ &&&& \\
  c_m & n_m & x_{k, 1} & ‚ãØ & x_{k, n_m}
\end{array}$

Por ejemplo, ac√° hay un polinomio en el formato como se suelen escribir a mano:

\begin{lstlisting}
  3 aaa - 5 bcc + adbda
\end{lstlisting}

\noindent Y ac√° est√° el mismo polinomio en el formato num√©rico:

\begin{lstlisting}
  3
  3 3 0 0 0
  -5 3 1 2 2
  1 5 0 3 1 3 0
\end{lstlisting}

Por ejemplo, para declarar un polinomio con \texttt{K = mpq\_class}, \texttt{X = \_\_uint8\_t} y \texttt{ord = DegLexOrd<X>}, leerlo en formato num√©rico e imprimirlo en formato bonito se puede hacer as√≠:

\begin{minted}{C++}
  Poly<mpq_class> p;
  std::cin >> p;
  p.nice_print();
\end{minted}

\section{Buchberger y F4}

Los algoritmos de Buchberger y F4 est√°n ambos hechos de una forma que se usan similar, as√≠ que por eso est√°n explicados juntos.

Como ambos algoritmos tienen el problema de que pueden no terminar, no conviene hacer directamente una funci√≥n que tome el conjunto generador y devuelva una base de Gr√∂bner porque podr√≠a no terminar. S√≠ tiene sentido tener una funci√≥n como esa para casos en los que se sabe que hay una base de Gr√∂bner finita, pero no conviene que sea la √∫nica forma de usar los algoritmos.

Se podr√≠a hacer una funci√≥n que adem√°s del conjunto generador tome un n√∫mero que sea la cantidad de pasos a ejecutar y que adem√°s de devolver un conjunto devuelva si se lleg√≥ a una base de Gr√∂bner o no. Esta opci√≥n tiene el problema de que una vez que la funci√≥n retorna no se puede seguir con el c√°lculo, lo cual en algunos casos podr√≠a ser deseable.

Para evitar esos problemas se defini√≥ una estructura que el constructor toma a los polinomios y tiene un m√©todo \texttt{next} que calcula un paso m√°s del c√°lculo de la base de Gr√∂bner y en caso de haber terminado lo dice y un m√©todo \texttt{fullBase} para usar solo en el caso de que se sepa que hay una base finita, que hace las llamadas a \texttt{next} hasta que termina y devuelve la base.

Para Buchberger la estructura est√° en el archivo \path{ncgb/Buchberger.hpp} y se llama \texttt{BuchbergerIncremental} y para F4 la estructura est√° en el archivo \path{ncgb/F4.hpp} y se llama \texttt{F4Incremental}. En el caso de Buchberger el m√©todo \texttt{next} devuelve un \texttt{std::optional<Poly<K, ord>>} que es vac√≠o solo en el caso de que ya se haya llegado a una base de Gr√∂bner y si no tiene un polinomio de la base de Gr√∂bner. En el caso de F4 el m√©todo \texttt{next} devuelve un \texttt{std::vector<Poly<K, ord>>} que es vac√≠o solo en el caso de que ya se haya llegado a una base de Gr√∂bner y si no tiene varios polinomios de la base de Gr√∂bner. En ambos casos devolver vac√≠o es la forma de decir que ya termin√≥ el algoritmo.

La interfaz de Buchberger podr√≠a describirse as√≠:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  struct BuchbergerIncremental {
    BuchbergerIncremental(const std::vector<Poly<K, X, ord>>& G);
    std::optional<Poly<K, X, ord>> next();
    std::vector<Poly<K, X, ord>> fullBase();
  };
\end{minted}

Y la de F4 as√≠:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  struct F4Incremental {
    F4Incremental(const std::vector<Poly<K, X, ord>>& G);
    std::vector<Poly<K, X, ord>> next();
    std::vector<Poly<K, X, ord>> fullBase();
  };
\end{minted}

En ambos casos el conjunto generador se toma como un vector porque usar un set de \cpp ser√≠a m√°s costoso innecesariamente.

Para ambos algoritmos hay adem√°s una funci√≥n \texttt{inIdeal} que toma un conjunto generador, un polinomio y una cantidad de pasos y trata de decir si el polinomio est√° en el ideal generado por el conjunto generador haciendo esa cantidad de llamadas a \texttt{next}. Esa funci√≥n devuelve un elemento del siguiente tipo (con los significados que est√°n comentados):

\begin{minted}{C++}
  enum IdealMembershipStatus {
    InIdeal,   // The element is definitely in the ideal
    NotInIdeal,// The element is definitely not in the ideal
    Unknown    // More steps are needed to determine if the element is in the ideal
  };
\end{minted}

\noindent Y est√° declarada as√≠:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  IdealMembershipStatus
  inIdeal(const std::vector<Poly<K, X, ord>>& G, Poly<K, X, ord> f, size_t st = 20);
\end{minted}

Esa funci√≥n b√°sicamente trata de responder el \cref{problem:principal} de si un polinomio est√° en el ideal generado por un conjunto generador.

\section{Representaci√≥n con cofactores}\label{section:representaci√≥n con cofactores (librer√≠a)}

La funci√≥n \texttt{inIdeal} solo decide la pertenencia al ideal generado, pero en caso afirmativo no da una forma de escribirlo como combinaci√≥n lineal de elementos del conjunto generador con polinomios como coeficientes.

Con las bases de Gr√∂bner pasa lo mismo, los algoritmos dan la base pero no dan una forma de escribir los elementos de la base usando los elementos del conjunto generador.

Sin embargo esa informaci√≥n se puede calcular y ese c√°lculo est√° implementado para Buchberger en el mismo archivo \path{ncgb/Buchberger.hpp} en unas funciones y estructuras con nombres que terminan en \texttt{Cofactor}. Esta terminaci√≥n es porque la forma de escribir un polinomio como combinaci√≥n lineal de otros se llama representaci√≥n con cofactores.

Estas funciones devuelven elementos del tipo \texttt{CofactorPoly} definido en el archivo \path{ncgb/nc_cofactorPolynomial.hpp}. Este tipo representa un polinomio como una combinaci√≥n lineal de elementos del conjunto generador. En particular, guarda un vector de elementos $m$, $i$, $m'$, $c$ de forma que, si los $g_i$ son el conjunto generador, el polinomio representado es $‚àë m g_i m' c$.

Para F4 esto no est√° implementado (en el siguiente cap√≠tulo se explica m√°s del por qu√©).


\section{Comparaci√≥n de bases de Gr√∂bner}\label{section:Comparaci√≥n de bases de Gr√∂bner (libreria)}

En el archivo \path{ncgb/cmpBases.hpp} est√° la funci√≥n \texttt{cmpBases} que toma dos conjuntos generadores y, asumiendo que son bases de Gr√∂bner, dice si generan el mismo ideal o no.

\section{Paralelismo} % O paralelizaci√≥n?

Como ya se dijo antes, uno de los objetivos del trabajo fue paralelizar el c√°lculo de bases de Gr√∂bner. Eso se hizo parcialmente para F4. O sea, se hizo solo para una parte del c√≥digo. En esta secci√≥n se explica c√≥mo hacer que la parte del c√≥digo que puede ejecutarse en paralelo lo haga.

La paralelizaci√≥n est√° hecha con OpenMP (\cite{lib:openmp}), que es una librer√≠a de \cpp de paralelizaci√≥n, as√≠ que para que corra en paralelo es igual que en cualquier otro c√≥digo paralelizado con OpenMP.

Para compilar para que se corra en paralelo hay que usar el flag \texttt{-fopenmp}. Este flag est√° puesto en la configuraci√≥n del Makefile para cuando se compilan los mains y los test. Solo con usar ese flag sigue igual corriendo con un solo hilo. Para que corra con varios hilos hay varias formas, la m√°s f√°cil es incluir a OpenMP con \texttt{\#include <omp.h>} y en el main llamar a la funci√≥n \texttt{omp\_set\_num\_threads} pas√°ndole la cantidad de hilos con los que se quiere correr.


\section{Ejemplo}

Ahora un peque√±o ejemplo de uso de la librer√≠a, con un ejemplo similar al del archivo \path{mains/base_Buchberger.cpp}:

\begin{minted}{C++}
  #include <bits/stdc++.h>
  #include <gmpxx.h>
  #include "ncgb/Buchberger.hpp"
  using namespace std;
  using namespace ncgb;

  typedef Poly<mpq_class> P;

  int main() {
    size_t n;
    cin >> n;
    vector<P> G(n);
    for (size_t i = 0; i < n; ++i) cin >> G[i];

    BuchbergerIncremental<P> bi(G);
    vector<P> base = bi.fullBase();

    cout << base.size() << endl;
    for (P& f : base) f.nice_print();
  }
\end{minted}

Este c√≥digo, que trabaja sobre los racionales, lee un conjunto generador en formato num√©rico, le calcula una base de Gr√∂bner, asumiendo que tiene una finita, y la imprime de forma bonita.


\chapter{Implementaci√≥n}\label{cap:Implementaci√≥n}

En este cap√≠tulo se explican los detalles de c√≥mo est√° hecha la implementaci√≥n en su versi√≥n actual (fecha de publicaci√≥n de esta tesis).

\section{Monomios}

Los monomios, o sea los elementos de $‚ü®X‚ü©$, como son palabras se implementaron usando vectores de \texttt{X}. La base de la implementaci√≥n es as√≠:

\begin{minted}{C++}
  template<typename X = __uint8_t>
  struct Monomial {
    std::vector<X> vals;
    // ‚Ä¶ M√©todos
  };
\end{minted}

Con esto, usando \texttt{X = \_\_uint8\_t}, que tiene 8 bits, se pueden tener hasta 256 variables. Cuando los monomios se imprimen o leen de forma bonita solo hay 26 variables, correspondiendo el 0 con la \texttt{a}. Si se quiere imprimir de forma bonita un monomio que usa variables mayores o iguales a 26 salta una aserci√≥n.

Esta estructura tiene implementadas las operaciones y m√©todos que se describieron en el cap√≠tulo anterior. La mayor√≠a tienen una implementaci√≥n directa. Las √∫nicas no directas son las relacionadas a la divisi√≥n, porque chequear divisibilidad es chequear si una palabra es sub-palabra de otra, para lo cual, la forma directa de hacerlo lleva tiempo cuadr√°tico en el largo de las palabras, pero se puede hacer en tiempo lineal.

Hay muchas formas de hacerlo en tiempo lineal, la que se us√≥ es la funci√≥n Z (que en el c√≥digo est√° en el archivo \path{ncgb/Zfunc.hpp}). En \cite{web:cp-algo:Zfunc} se explica la funci√≥n Z y c√≥mo usarla para chequear si una palabra es sub-palabra de otra.
% Tambi√©n quiz√°s tiene sentido aclarar que no es la misma que la funci√≥n Œ∂ de Riemann, que es lo primero que aparece al buscar en google "funci√≥n Z"

Junto con la implementaci√≥n de los monomios, en el archivo \path{ncgb/nc_monomial.hpp} est√° la implementaci√≥n del orden lexicogr√°fico por grado, que tambi√©n es directa.

\section{Polinomios}

Los polinomios, o sea los elementos de $K‚ü®X‚ü©$ est√°n implementados usando un vector de pares monomio-coeficiente que siempre se mantiene ordenado por el orden monomial. La base de la implementaci√≥n es as√≠:

\begin{minted}{C++}
  template<typename K, typename X = __uint8_t, class ord = DegLexOrd<X>>
  struct Poly {
    std::vector<std::pair<Monomial<X>, K>> terms;
    // ‚Ä¶ M√©todos
  };
\end{minted}

Con esta estructura para los polinomios todas las operaciones se hacen de forma directa.

El orden de los polinomios est√° definido como \texttt{template<typename K, typename X, class ord> struct PolyOrd}.

\section{Reducci√≥n}

La reducci√≥n est√° implementada en el archivo \path{ncgb/reductions.hpp}, en particular en la funci√≥n \texttt{reduce} que toma un polinomio y un vector de polinomios y reduce el polinomio con los polinomios del vector. La reducci√≥n se hace modificando el propio argumento. Esa funci√≥n ser√≠a una implementaci√≥n de un reductor concreto, o sea, de un $e_‚â§$ y trata siempre de reducir primero por los primeros elementos del vector y empezando por los monomios m√°s grandes del polinomio.

En el archivo tambi√©n hay una funci√≥n \texttt{reduce} que adem√°s toma un vector de booleanos que tiene que ser del mismo largo que el vector de polinomios (en \cpp se puede tener varias funciones con el mismo nombre si tienen argumentos de distinto tipo) y hace la reducci√≥n solo con los polinomios que tengan un \texttt{false} en la misma posici√≥n en el vector de booleanos. Esta funci√≥n est√° para poder implementar la optimizaci√≥n de ir eliminando algunos elementos de la base sin tener que estar modificando un vector.

\section{Ambig√ºedades}

Las ambig√ºedades, que son necesarias para el algoritmo de Buchberger, est√°n implementadas en el archivo \path{ncgb/ambiguities.hpp} y consisten en una estructura as√≠:

\begin{minted}{C++}
  template<typename X>
  struct Amb {
    const Monomial<X>& p, q;
    enum Type { Inclusion, Overlap };
    Type type;
    size_t pos; // position where q starts in p
    Monomial<X> a, b;

    size_t size() const;
    Monomial<X> lm() const;
  };
\end{minted}

Los campos de la ambig√ºedad son:

\begin{itemize}
  \item \texttt{p} y \texttt{q} son referencias a los monomios sobre los cuales es la ambig√ºedad. El motivo por el cual se guardan en la estructura es para poder implementar una de las optimizaciones.
  \item \texttt{type} indica si la ambig√ºedad es de inclusi√≥n o de superposici√≥n (recordar que todas las ambig√ºedades que se usan en el algoritmo de Buchberger son relevantes).
  \item \texttt{pos} es la posici√≥n de \texttt{p} donde empieza el pedazo que es en com√∫n con \texttt{q} y por la cual existe la ambig√ºedad.
  \item \texttt{a} y \texttt{b} son los monomios que hacen que en el caso de las de inclusi√≥n \texttt{p} sea igual a \texttt{aqb} y en el caso de las de superposici√≥n \texttt{ap} sea igual a \texttt{qb}. % El producto ac√° es medio raro, pero no se como hacerlo mejor
\end{itemize}

En el archivo tambi√©n est√° la funci√≥n \texttt{ambiguities} que toma dos monomios y devuelve un vector de \texttt{Amb} con todas las ambig√ºedades entre esos dos monomios. En esta funci√≥n, al igual que en la divisibilidad de monomios, se usa la funci√≥n Z para evitar tener que hacer algo cuadr√°tico en los largos de los monomios.

Despu√©s, en el archivo est√° la funci√≥n \texttt{S\_poly} que toma una ambig√ºedad y dos polinomios que deber√≠an ser los polinomios correspondientes y devuelve el S-polinomio correspondiente.

Y por √∫ltimo est√° la funci√≥n \texttt{checkDeletionCriteria} que implementa la optimizaci√≥n que permite descartar algunas ambig√ºedades sin tener que reducirlas.

\section{Buchberger}

Como ya se dijo antes, por el inconveniente de que el algoritmo puede no terminar, se usa una estructura con un m√©todo \texttt{next}. En esa estructura ya est√°n implementadas las optimizaciones antes mencionadas, pero en esta secci√≥n primero se explica c√≥mo ser√≠a la estructura sin esas optimizaciones y despu√©s en la secci√≥n \cref{secton:optimizaciones} se explica algo de c√≥mo se agregan.

La base de esa estructura es as√≠:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  struct BuchbergerIncremental {
    std::vector<Poly<K, X, ord>> G;
    std::queue<std::tuple<Amb<X>, size_t, size_t>> ambs;
    size_t t = 0;
    // ‚Ä¶ M√©todos
  };
\end{minted}

Los campos de esta estructura guardan lo siguiente:

\begin{itemize}
  \item \texttt{G} es la base de Gr√∂bner que se est√° construyendo. Al principio se inicializa con los polinomios con los que se llama al constructor.
  \item \texttt{ambs} son las ambig√ºedades que todav√≠a no se procesaron junto con los √≠ndices en \texttt{G} de los polinomios a los que corresponde la ambig√ºedad. Se usa una cola para procesar siempre la que hace m√°s tiempo est√° esperando.
  \item La variable \texttt{t} est√° porque como la base de Gr√∂bner incluye a los polinomios originales, las primeras llamadas a \texttt{next} tienen que devolver esos polinomios y \texttt{t} indica cu√°ntos de esos ya se devolvieron. Cuando \texttt{t} es igual al tama√±o de \texttt{G} es porque ya se devolvieron todos esos.
\end{itemize}

La estructura adem√°s de tener los m√©todos \texttt{next} y \texttt{fullBase} tiene varios m√©todos que se usan internamente. Entre todos los m√©todos son los siguientes: % Por todos los m√©todos me refiero a los ya mencionados y a los todav√≠a no mencionados

\begin{itemize}
  \item \texttt{add\_amb}: Este m√©todo toma una ambig√ºedad y dos √≠ndices, que son los √≠ndices en \texttt{G} de los polinomios a los que corresponde la ambig√ºedad, y los agrega a la cola de ambig√ºedades. Siempre que hay que agregar una ambig√ºedad se hace con este m√©todo. El motivo por el cual esto est√° en un m√©todo propio es para despu√©s, al implementar la optimizaci√≥n de descartar ambig√ºedades, poder hacerlo solo en este m√©todo.
  \item \texttt{add\_poly}: Este m√©todo agrega un polinomio a \texttt{G} agregando adem√°s todas las nuevas ambig√ºedades que aparecen (llamando a \texttt{add\_amb}). Cada vez que hay que agregar un nuevo polinomio se usa este m√©todo, tanto al comienzo cuando se agregan los polinomios iniciales como cuando se agrega un S-polinomio reducido.
  \item \texttt{next}: Este es el m√©todo que corre el algoritmo. Lo principal que hace (despu√©s de usar la variable \texttt{t} para ver si tiene que devolver un elemento de \texttt{G}) es sacar ambig√ºedades de la cola hasta encontrar una que no se reduzca a $0$ y cuando la encuentra la agrega a la base (con \texttt{add\_poly}) y la devuelve. Si se acaban las ambig√ºedades devuelve vac√≠o (recordar que devuelve \texttt{std::optional<Poly<K, ord>>}).
  \item \texttt{fullBase}: Simplemente llama a \texttt{next} en un ciclo hasta que devuelva vac√≠o y despu√©s devuelve la base.
\end{itemize}

Lo de las optimizaciones se explica m√°s adelante en la \cref{secton:optimizaciones}.


\section{F4}

F4 es un poco m√°s complejo que Buchberger y tiene m√°s partes, as√≠ que esta secci√≥n est√° dividida en varias subsecciones para las distintas partes.

\subsection{Reducci√≥n por filas de matrices}

Para F4 hace falta hacer la reducci√≥n por filas de una matriz. Para esto, en el archivo \path{ncgb/matrix.cpp} se defini√≥ un tipo matriz como un vector de vectores y una funci√≥n \texttt{rref} que hace una eliminaci√≥n gaussiana directamente y que funciona para cualquier \texttt{K}. Sin embargo, la reducci√≥n por filas de una matriz es un tema ya muy analizado y hay algunas librer√≠as que lo hacen para distintos tipos \texttt{K} mucho m√°s r√°pido.

Una librer√≠a que hace la reducci√≥n por filas es FLINT, que lo hace para el tipo \texttt{mpq\_class} de GMP que ya dijimos que son los n√∫meros racionales \cite{lib:flint, lib:gmp}. Para usarla, en el archivo \path{ncgb/matrix_mpq_class.hpp} hay una especializaci√≥n de \texttt{rref} para \texttt{mpq\_class} (en \cpp una especializaci√≥n es cuando hay c√≥digo definido con un template y se hace una definici√≥n aparte para alguna combinaci√≥n particular de par√°metros del template).

Algo malo que tiene esa especializaci√≥n es que las matrices de racionales con las que trabaja FLINT no est√°n definidas como vectores de vectores, sino que son su propio tipo \texttt{fmpq\_mat\_t}, as√≠ que la funci√≥n tiene que primero copiar la matriz a una matriz de FLINT, despu√©s hacer la reducci√≥n por filas y por √∫ltimo copiar el resultado de vuelta a la matriz original.

El motivo por el cual se hizo eso es que esas matrices de FLINT se usan de una forma muy particular y complicada. Por ejemplo, para asignarle un valor \texttt{x} de tipo \texttt{mpq\_class} a una posici√≥n de la matriz hay que hacer \texttt{fmpq\_set\_mpq(fmpq\_mat\_entry(mat, i, j), x.get\_mpq\_t());}. Esto hace que si se quisiera directamente en F4 trabajar con las matrices de FLINT no se podr√≠a hacer el c√≥digo gen√©rico para cualquier \texttt{K}. Se prob√≥ tambi√©n hacer que las matrices sean una estructura propia y hacer una especializaci√≥n de \texttt{Matrix<mpq\_class>} para que use \texttt{fmpq\_mat\_t} por dentro, pero andaba m√°s lento, as√≠ que se descart√≥.

\subsection{Preprocesamiento simb√≥lico}

El preprocesamiento simb√≥lico (\cref{alg:Preprocesamiento simb√≥lico}) est√° implementado en el propio archivo \path{ncgb/F4.hpp} en la funci√≥n \texttt{symbolicPreprocessing}. La implementaci√≥n es directa, as√≠ que no hay mucho para comentar.

\subsection{Reducci√≥n}

Como en F4 se reducen varios polinomios al mismo tiempo, se implement√≥ una funci√≥n \texttt{multiReduction} que toma dos vectores de polinomios, la base actual y los polinomios a reducir y los reduce todos a la vez.

En el \cref{alg:F4} esto se hizo dentro del propio algoritmo de F4 pero en la implementaci√≥n se hizo aparte porque es bastante lo que tiene que hacer el c√≥digo.

La implementaci√≥n lo que hace es construir la matriz con una funci√≥n llamada \texttt{toMatrix}, despu√©s llamar a la funci√≥n \texttt{rref} que ya se explic√≥, despu√©s marcar qu√© columnas corresponden a monomios principales del vector por el cual se est√° reduciendo (esto para poder saber cu√°les polinomios son los reducidos) y por √∫ltimo convertir a polinomios las filas que su coeficiente principal (el primero no nulo de izquierda a derecha) no est√° marcada como que es un monomio principal del vector por el cual se est√° reduciendo.

\subsection{El propio F4}

La primera diferencia tiene que ver con la selecci√≥n de ambig√ºedades. En Buchberger solo hab√≠a que elegir una ambig√ºedad, pero ac√° hay que elegir varias. Podr√≠a haber muchas formas de elegir, pero, como ya se dijo antes, una estrategia que funciona bien es elegir siempre todas las de menor grado. Para eso se hizo que las ambig√ºedades est√©n guardadas por grado en un vector, as√≠:

\begin{minted}{C++}
  std::vector<std::vector<std::tuple<Amb<X>, size_t, size_t>>> ambs_per_deg;
\end{minted}

El otro lugar en el que hay diferencia, y mucha, es en \texttt{next}. En F4 este m√©todo lo que hace es, agarrar todas las ambig√ºedades de menor grado, poner todos los S-polinomios correspondientes en un vector, hacer la reducci√≥n de esos polinomios con la funci√≥n \texttt{multiReduction} y, si hay alguno que queda no nulo, agregar los polinomios reducidos a la base, agregando tambi√©n las nuevas ambig√ºedades que aparecen y devolver esos nuevos polinomios, y si quedan todos nulos pasar a las ambig√ºedades de grado siguiente. Si no quedan m√°s grados de ambig√ºedades se devuelve vac√≠o.

\section{Optimizaciones}\label{secton:optimizaciones}

Como ya se dijo varias veces, hay algunas optimizaciones que se pueden hacer en los algoritmos de Buchberger y F4, que est√°n explicadas en la Secci√≥n 4.5 de \cite{thesis:Hof20}. Ac√° solo se explican por arriba las optimizaciones y se explican c√≥mo est√°n implementadas.

\subsection{Descartar ambig√ºedades}

La primera optimizaci√≥n consiste en que se pueden descartar algunas ambig√ºedades, sin tener que reducir su S-polinomio, seg√∫n si se cumplen ciertas propiedades con otros polinomios que ya est√°n en la base.

En particular algunos teoremas de \cite{thesis:Hof20} permiten definir una funci√≥n con la siguiente signatura:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  bool
  checkDeletionCriteria(
    std::vector<Poly<K, X, ord>>& G, Amb<X>& amb, size_t i, size_t j);
\end{minted}

Que toma la base, la ambig√ºedad y a que polinomios corresponde y devuelve \texttt{true} si y solo si esa ambig√ºedad se puede descartar sin reducirla.

Usando esa funci√≥n, en el m√©todo \texttt{add\_amb} tanto de Buchberger como de F4, antes de agregar la ambig√ºedad, se agreg√≥ una llamada a \texttt{checkDeletionCriteria} para solo agregar la ambig√ºedad si da \texttt{false}.

\subsection{Eliminaci√≥n de polinomios}

La segunda optimizaci√≥n consiste en que cuando se procesa una ambig√ºedad de inclusi√≥n se puede borrar de la base al polinomio grande de la ambig√ºedad.

Para recordar, una ambig√ºedad de inclusi√≥n entre los polinomio $f$ y $g$ es cuando se tiene que $\lm_‚â§(f) = a \lm_‚â§(g) b$ con $a, b ‚àà ‚ü®X‚ü©$. Esta optimizaci√≥n permite en esas ambig√ºedades borrar $f$ de la base.

Esta optimizaci√≥n se implement√≥ en Buchberger pero no en F4, porque por alg√∫n motivo cuando se prob√≥ en F4 anduvo m√°s lento. No se investig√≥ por qu√© pas√≥ eso.

Para implementar esta optimizaci√≥n en Buchberger lo que se hizo no es directamente borrar el polinomio de \texttt{G}, porque para eso habr√≠a que tambi√©n cambiar los √≠ndices que est√°n guardados junto con las ambig√ºedades, sino que se agreg√≥ un vector de booleanos \texttt{removed} a la estructura, que tiene siempre el mismo largo que \texttt{G} y vale \texttt{true} solo en las posiciones de polinomios que se borraron. O sea que m√°s bien se est√° marcando como borrados los polinomios.

A las funciones que se hab√≠an explicado, que toman a \texttt{G} como par√°metro y se usan en Buchberger, se les agreg√≥ un par√°metro extra que es el vector de booleanos y se hizo que solo trabajen con los polinomios de posiciones que no est√°n en \texttt{true}.

\subsection{Reducci√≥n m√°s eficiente en F4}\label{subsection:Reducci√≥n m√°s eficiente en F4}

Como ya se dijo antes, para F4 tambi√©n hay otra optimizaci√≥n que consiste en hacer la reducci√≥n por filas de la matriz de forma m√°s eficiente aprovechando la estructura particular que tienen las matrices de F4. Esta reducci√≥n se llama reducci√≥n Faug√®re-Lachartre y est√° explicada en \cite{thesis:Hof20}.

Esta optimizaci√≥n no se implement√≥ principalmente por el poco soporte para trabajar con matrices de un cuerpo arbitrario, o de una implementaci√≥n espec√≠fica de $‚Ñö$, que hay en \cpp. Sin embargo, queda como trabajo futuro en la \cref{section:trabajos futuros}.

\section{Representaci√≥n con cofactores}

Como se dijo en el cap√≠tulo anterior, la representaci√≥n con cofactores se implement√≥ solo para Buchberger, y no para F4. El motivo es que, como para F4 de cualquier manera no est√° implementada la optimizaci√≥n de hacer la reducci√≥n m√°s eficiente, se hay que seguir trabajando en la parte de la reducci√≥n y cuando se tenga lista la versi√≥n m√°s eficiente es el momento de implementar la representaci√≥n con cofactores.

Como se explic√≥ en la \cref{section:representaci√≥n con cofactores (librer√≠a)}, para la representaci√≥n con cofactores se usa el tipo \texttt{CofactorPoly} que guarda polinomios de un ideal como combinaci√≥n lineal de elementos de la base.

La estructura de la implementaci√≥n de este tipo es as√≠:

\begin{minted}{C++}
  template<typename K, typename X = __uint8_t, class ord = DegLexOrd<X>>
  struct CofactorPoly {
    std::vector<std::tuple<Monomial<X>, size_t, Monomial<X>, K>> terms;
    // ‚Ä¶ M√©todos
  };
\end{minted}

Y tiene definidas las operaciones de suma, resta y producto entre polinomios, al igual que con los polinomios normales. Adem√°s tiene un m√©todo \texttt{add} para agregar una tupla monomio, √≠ndice, monomio, coeficiente al polinomio.

A diferencia de los polinomios comunes, ac√° \texttt{terms} no se mantiene ordenado de ninguna manera.

Con \texttt{CofactorPoly} se hizo la estructura \texttt{BuchbergerIncrementalCofactor}, que es muy parecida a \texttt{BuchbergerIncremental} pero con algunos agregados, y se hicieron versiones \texttt{Cofactor} de las funciones que se usan.

Para las reducciones se implement√≥ una funci√≥n que toma, por referencia, un polinomio $f$, reduce in place a su forma normal $f^*$ y devuelve la diferencia $f - f^*$ como un \texttt{CofactorPoly}. La signatura es:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  CofactorPoly<K, X, ord>
  reduceCofactor(
    Poly<K, X, ord>& f, const std::vector<Poly<K, X, ord>>& G,
    const std::vector<CofactorPoly<K, X, ord>>& g_rec);
\end{minted}

Tambi√©n se hizo una versi√≥n de la funci√≥n de los S-polinomios, que toma la ambig√ºedad y los polinomios correspondientes $f$ y $g$ y devuelve, adem√°s del S-polinomio $p$, los los monomios $a$, $b$, $a'$ y $b'$ y los elementos del cuerpo $c$ y $c'$, que hacen que $p = c a f b + c' a' f b'$.

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  std::tuple<
    Poly<K, X, ord>,
    std::tuple<Monomial<X>, Monomial<X>, K>,
    std::tuple<Monomial<X>, Monomial<X>, K>>
  S_polyCofactor(
    const Amb<X>& amb, const Poly<K, X, ord>& f, const Poly<K, X, ord>& g);
\end{minted}

Con esto, en la estructura \texttt{BuchbergerIncrementalCofactor} se agreg√≥ (con respecto a \texttt{BuchbergerIncremental}) un campo \texttt{std::vector<CofactorPoly<K, ord>> G\_rec} que guarda la representaci√≥n con cofactores de cada polinomio de \texttt{G}.

En este campo \texttt{G\_rec}, a los elementos iniciales simplemente se los agrega como \texttt{{Monomial(), i, Monomial(), K(1)}} y a los elementos que vienen de un S-polinomio se les construye el \texttt{CofactorPoly} con los \texttt{CofactorPoly} de los polinomios que forman la ambig√ºedad multiplicados por los monomios y coeficientes que devuelve \texttt{S\_polyCofactor} y con el \texttt{CofactorPoly} de la reducci√≥n que devuelve la funci√≥n \texttt{reduceCofactor}.

\section{Comparaci√≥n de bases de Gr√∂bner}

La funci√≥n \texttt{cmpBases} que se mencion√≥ en la \cref{section:Comparaci√≥n de bases de Gr√∂bner (libreria)} que toma dos conjuntos generadores y asumiendo que son bases de Gr√∂bner dice si generan el mismo ideal o no est√° implementada usando tal cual el \cref{col:(G) = (G') cond}.

\section{Paralelismo}

Cuando se paraleliza siempre es importante primero tratar de optimizar la versi√≥n no paralela lo m√°s posible. En este caso lo mejor no paralelo es el algoritmo F4, pero como no est√° implementada la optimizaci√≥n de la reducci√≥n eficiente, no est√° todav√≠a optimizado al m√°ximo. De cualquier manera, como la reducci√≥n de matrices es solo una parte del algoritmo, se puede pensar c√≥mo se podr√≠a paralelizar el resto.

El m√©todo \texttt{add\_poly} que ya se explic√≥ que agrega un polinomio a la base y las nuevas ambig√ºedades correspondientes, sin paralelizar se implement√≥ as√≠:

\begin{minted}{C++}
  void add_poly(const Poly<K, X, ord>& f) {
    G.push_back(f);
    for (size_t k = 0; k < G.size() - 1; k++) {
      for (auto& amb : ambiguities(G[k].lm(), f.lm())) {
        add_amb(amb, k, G.size() - 1);
      }
      for (auto& amb : ambiguities(f.lm(), G[k].lm())) {
        add_amb(amb, G.size() - 1, k);
      }
    }
  }
\end{minted}

Y el m√©todo \texttt{add\_amb} se implement√≥ as√≠:

\begin{minted}{C++}
  void add_amb(Amb<X>& amb, size_t i, size_t j) {
    if (checkDeletionCriteria(G, amb, i, j)) {
      return;
    }
    ambs.push({amb, i, j});
  }
\end{minted}

El primer \texttt{for} de \texttt{add\_poly} as√≠ como est√° casi que se podr√≠a paralelizar. Lo √∫nico que lo impide es que \texttt{add\_amb} hace un \texttt{ambs.push} que ser√≠a problem√°tico si se llega a ejecutar al mismo tiempo por m√°s de un hilo. Para solucionar eso lo que se hizo es guardar las ambig√ºedades en varios vectores, uno por cada polinomio de \texttt{G} y despu√©s al final de la funci√≥n agregar todas las ambig√ºedades a \texttt{ambs}. As√≠:

\begin{minted}{C++}
  void add_poly(Poly<K, X, ord>& f) {
    G.push_back(f);
    size_t lim = G.size() - 1;
    std::vector<std::vector<std::tuple<Amb<X>, size_t, size_t>>> to_add(lim);

    for (size_t k = 0; k < lim; k++) {
      for (auto& amb : ambiguities(G[k].lm(), G.back().lm())) {
        if (!checkDeletionCriteria(G, amb, k, lim)) {
          to_add[k].push_back({amb, k, lim});
        }
      }
      for (auto& amb : ambiguities(G.back().lm(), G[k].lm())) {
        if (!checkDeletionCriteria(G, amb, lim, k)) {
          to_add[k].push_back({amb, lim, k});
        }
      }
    }

    for (size_t k = 0; k < lim; k++) {
      for (auto& [amb, i, j] : to_add[k]) {
        size_t d = amb.size();
        while (ambs_per_deg.size() <= d) {
          ambs_per_deg.push_back({});
        }
        ambs_per_deg[d].push_back({amb, i, j});
      }
    }
  }
\end{minted}

Con esto el primer \texttt{for} se puede paralelizar directamente.

\subsection{Uso de OpenMP para paralelizar}

Para paralelizar se us√≥ la librer√≠a OpenMP \cite{lib:openmp}. Con OpenMP para que un \texttt{for} como el de \texttt{add\_poly} se corra en paralelo solo hace falta agregar en la l√≠nea anterior \texttt{\#pragma omp parallel for}, as√≠ que en el primer \texttt{for} de \texttt{add\_poly} se agreg√≥ eso en la l√≠nea anterior. En el \cref{cap:Benchmarks} se dan los datos de qu√© tal anda.


\chapter{Tests}\label{cap:Tests}

Siempre que se programa, para que salga bien hay que testear todo, y este trabajo no fue una excepci√≥n. A medida que se fue escribiendo el c√≥digo se fueron haciendo tests del c√≥digo para eliminar los bugs. Adem√°s, con algunos de los tests se hizo que hagan mediciones de tiempo para ver qu√© tan r√°pido andaba el c√≥digo. Esto √∫ltimo se llama benchmarking. En esta secci√≥n se explican los tests y en el siguiente cap√≠tulo los benchmarks que se hicieron.

Todos los tests est√°n en la carpeta \path{test}, la cual est√° dividida en varias subcarpetas con varios tests cada una. Para correr todos los tests se puede usar el comando \texttt{make test}. En la carpeta \path{.github/workflows} est√° configurado para que al subir los cambios al repositorio se corran los tests autom√°ticamente, aunque eso no siempre funciona porque cuando se corren los tests en GitHub se tiene que instalar SageMath y a veces falla la instalaci√≥n.

Algunos tests corren el c√≥digo de la librer√≠a y el c√≥digo de \texttt{operator\_gb}, que es la librer√≠a hecha por Clemens Hofstadler en su tesis de m√°ster \cite{thesis:Hof20} usando SageMath, y comparan los resultados, y otros corren solo c√≥digo de la librer√≠a.

Tambi√©n, algunos tests corren los mains de ejemplo de la carpeta \path{mains} y otros directamente incluyen a los archivos de la librer√≠a y los testean directamente.

A continuaci√≥n una lista de lo m√°s importante de los tests:

\begin{itemize}
  \item Hay tests de las operaciones b√°sicas de monomios, polinomios, reducci√≥n, etc. en la carpeta \path{test/internal_tests}.
  \item Para algunos conjuntos generadores que se sabe que sus ideales generados tienen bases de Gr√∂bner finitas hay un test que calcula una base de Gr√∂bner con Buchberger, una con F4 y una con \texttt{operator\_gb} y chequea que los resultados sean equivalentes usando \path{mains/compare_bases.cpp}. Este archivo lo que hace es leer dos conjuntos generadores y, asumiendo que son bases de Gr√∂bner, dice si generan el mismo ideal o no usando la funci√≥n \texttt{cmpBases} explicada en la \cref{section:Comparaci√≥n de bases de Gr√∂bner (libreria)}. Este test est√° en la carpeta \path{test/base_tests}.
  \item Para algunos conjuntos generadores construidos al azar se construye otro polinomio tambi√©n al azar y tanto con Buchberger como con F4 y con \texttt{operator\_gb} se ejecutan algunos pasos del c√°lculo de la base de Gr√∂bner para ver si est√° el polinomio en el ideal o no. Si alguno(s) de los tres da que s√≠ est√° en el ideal y otro(s) no, se ejecutan los que no con much√≠simos m√°s pasos, para que tenga que terminar s√≠ o s√≠ porque por los que dieron que s√≠ sabemos que (si no hay bugs) s√≠ est√°. Esto est√° en la carpeta \path{test/InIdeal_tests}. % Esto me parece que no se entiende nada, pero no se como explicarlo.
  \item Con respecto a la representaci√≥n con cofactores, hay un test que corre los algoritmos con y sin representaci√≥n con cofactores y se fija que el resultado de con cofactores despu√©s de convertir los \texttt{CofactorPoly} en \texttt{Poly} sea igual al resultado sin cofactores. Este test est√° en la carpeta \path{test/cofactor_tests}.
  \item Por √∫ltimo hay un test que corre F4 no paralelo y paralelo con distintas cantidades de hilos y se fija que siempre d√© el mismo resultado. Esto est√° en la carpeta \path{test/parallelism_tests}.
\end{itemize}

\chapter{Benchmarks}\label{cap:Benchmarks}

En este cap√≠tulo se presentan los resultados obtenidos tras correr los tests que incluyen benchmarks. Las corridas se hicieron en la computadora `atom' de FAMAF que tiene las siguientes caracter√≠sticas:

\begin{itemize}
  \item Procesador: AMD EPYC 7643 48-Core Processor
  \item RAM: 126 GB
\end{itemize}

De cualquier manera esos datos no son muy importantes porque lo importante son las relaciones entre los distintos tiempos.

Los tests que tienen benchmarks son, todos salvo uno, tests que usan los mains de la carpeta \path{mains} y mains hechos en Python con \texttt{operator\_gb} y son corridos con distintas entradas desde un archivo de Python. Los tiempos en casi todos se miden desde el programa de Python, as√≠ que incluyen el tiempo hasta que se inicializa el programa y lee la entrada y el tiempo de impresi√≥n de la salida, pero como son siempre entradas y salidas relativamente chicas eso no deber√≠a ser problema.

Todos los tests que tienen benchmarks, salvo uno, funcionan tomando como input un conjunto generador que se sabe que el ideal generado tiene una base de Gr√∂bner finita. Para estos benchmarks se usaron los siguientes conjuntos generadores:

\begin{itemize}
  \item FK2 $ = \{a^2\}$
  \item FK3 $ = \{a^2,\ b^2,\ c^2,\ ac + ba + cb,\ ab + bc + ca\}$
  \item FK4 $ = \{a^2,\ b^2,\ c^2,\ d^2,\ e^2,\ f^2,\ ac + ba + cb,\ ae + da + ed,\ bf + db + fd,\ cf + ec + fe,\ ab + bc + ca,\ ad + de + ea,\ bd + df + fb,\ ce + ef + fc,\ cd + dc,\ be + eb,\ af + fa\}$
  \item tri1 $ = \{a^2 - 1,\ b^3 - 1,\ {(ababab^2ab^2)}^2 - 1\}$
  \item tri2 $ = \{a^2 - 1,\ b^3 - 1,\ {(ababab^2)}^3 - 1\}$
  \item tri3 $ = \{a^3 - 1,\ b^3 - 1,\ {(abab^2)}^2 - 1\}$
  \item tri4 $ = \{a^3 - 1,\ b^3 - 1,\ {(abaab^2)}^2 - 1\}$
  \item tri5 $ = \{a^2 - 1,\ b^5 - 1,\ {(abab^2)}^2 - 1\}$
  \item tri6 $ = \{a^2 - 1,\ b^5 - 1,\ {(ababab^4)}^2 - 1\}$
  \item tri7 $ = \{a^2 - 1,\ b^5 - 1,\ {(abab^2ab^4)}^2 - 1\}$
  \item tri8 $ = \{a^2 - 1,\ b^2 - 1,\ {(ababab^3)}^2 - 1\}$
  \item tri9 $ = \{a^2 - 1,\ b^3 - 1,\ {(abab^2)}^2 - 1\}$
  \item tri10 $ = \{a^2 - 1,\ b^3 - 1,\ {(ababab^2)}^2 - 1\}$
  \item tri11 $ = \{a^2 - 1,\ b^3 - 1,\ {(abababab^2)}^2 - 1\}$
  \item tri12 $ = \{a^2 - 1,\ b^3 - 1,\ {(ababab^2abab^2)}^2 - 1\}$
  \item tri13 $ = \{a^2 - 1,\ b^3 - 1,\ {(babababab^2ab^2)}^2 - 1\}$
  \item trit3 $ = \{a^3 - 1,\ b^3 - 1,\ c^3 - 1,\ {(ab)}^2 - 1,\ {(ac)}^2 - 1,\ {(bc)}^2 - 1\}$
  \item trit4 $ = \{a^3 - 1,\ b^3 - 1,\ c^4 - 1,\ {(ab)}^2 - 1,\ {(ac)}^2 - 1,\ {(bc)}^2 - 1\}$
  \item trit5 $ = \{a^3 - 1,\ b^3 - 1,\ c^5 - 1,\ {(ab)}^2 - 1,\ {(ac)}^2 - 1,\ {(bc)}^2 - 1\}$
\end{itemize}

Los FK provienen de la teor√≠a de √°lgebras de Nichols, las cuales son de inter√©s para Cristian Vay, el director de esta tesis, y otros investigadores de FAMAF. Los FK definen algo que se llama √°lgebras de Fomin-Kirillov y son una familia infinita parametrizada por un $n ‚àà ‚Ñï$, que fijando el $n$ se describe a continuaci√≥n.

\begin{itemize}
  \item El cuerpo es $‚Ñö$.
  \item El alfabeto es $\{x_{ij} : i, j ‚àà \{1, ‚Ä¶, n\} : i ‚â† j\}$, donde los $_{ij}$ son un par no ordenado.
  \item El conjunto generador es:
  \begin{align*}
    & \{ x_{ij}¬≤ : i, j ‚àà \{1, ‚Ä¶, n\} : i ‚â† j \} \\
    & ‚à™ \{ x_{ij} x_{ik} + x_{ik} x_{jk} + x_{jk} x_{ij} : i, j, k ‚àà \{1, ‚Ä¶, n\} : i ‚â† j ‚â† k ‚â† i \} \\
    & ‚à™ \{ x_{ik} x_{ij} + x_{jk} x_{ik} + x_{ij} x_{jk} : i, j, k ‚àà \{1, ‚Ä¶, n\} : i ‚â† j ‚â† k ‚â† i \} \\
    & ‚à™ \{ x_{ij} x_{kl} + x_{kl} x_{ij} : i, j, k, l ‚àà \{1, ‚Ä¶, n\} : i ‚â† j ‚àß k ‚â† l \} \text{.}
  \end{align*}
\end{itemize}

\noindent Se sabe que para $n ‚â§ 5$ los ideales generados por FK$n$ tienen bases de Gr√∂bner finitas, pero para $n > 5$ no se sabe. En \cite{web:Nichols} y \cite{book:introNichols} se puede encontrar m√°s informaci√≥n sobre las √°lgebras de Nichols.

Los tri est√°n porque \cite{thesis:Hof20} los usa, con ese mismo nombre, y √©l los sac√≥ del Teorema 2.12 de \cite{book:class-tri}. Los trit son directamente tomados de la Proposici√≥n 1.9 de \cite{book:class-tri}.

En todos los benchmarks que usan estos conjuntos se trabaja sobre los racionales, porque es para los racionales que se sabe que tienen bases finitas.

En las siguientes subsecciones se presentan los resultados de cada uno de los benchmarks.

\section{Ideales con bases de Gr√∂bner finitas}\label{section:Ideales con bases de Gr√∂bner finitas}

El test que usa los distintos algoritmos para calcular bases de Gr√∂bner de ideales que se sabe que tienen bases de Gr√∂bner finitas incluye mediciones de los tiempos y usa los casos que vimos reci√©n.

En el siguiente gr√°fico se muestran los tiempos de ejecuci√≥n de Buchberger de esta tesis (\texttt{Buchberger}), de F4 de esta tesis (\texttt{F4}) y de \texttt{operator\_gb} (que usa F4) para esos casos.

\noindent \begin{tikzpicture}
  \begin{axis}[
      ybar = 0.5pt, % Tipo de gr√°fico: barras verticales
      width = \textwidth,
      height = 0.4\textwidth,
      bar width = 0.01\textwidth, % Ancho de cada barra
      symbolic x coords = {FK2, FK3, FK4, tri1, tri2, tri3, tri4, tri5, tri6, tri7, tri8, tri9, tri10, tri11, tri12, tri13, trit3, trit4, trit5}, % Etiquetas en el eje x
      xtick = data, % Mostrar marcas en el eje x para cada dato
      ylabel = {Tiempo en segundos}, % Etiqueta del eje y
      %xlabel = {Categor√≠as}, % Etiqueta del eje x
      xticklabel style = {rotate = 45}, % Rotar etiquetas
      ymin = 0, % M√≠nimo del eje y
      ymax = 215,
      enlarge x limits = 0.03, % Espaciado en los bordes
      legend style = {at = {(0.024, 0.94)}, anchor = north west}, % Estilo de la leyenda
      legend entries = {\texttt{Buchberger}, \texttt{F4}, \texttt{operator\_gb}}, % Entradas de la leyenda
      cycle list = {{brown,fill = brown!30}, {red,fill = red!30}, {blue,fill = blue!30}}, % Colores
  ]
    % Datos para cada conjunto
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.01) (tri1, 0.26) (tri10, 0.01) (tri11, 0.03) (tri12, 3.27) (tri13, 0.01) (tri2, 6.01) (tri3, 0.02) (tri4, 0.04) (tri5, 0.01) (tri6, 6.53) (tri7, 33.33) (tri8, 0.09) (tri9, 0.00) (trit3, 0.01) (trit4, 0.14) (trit5, 77.16)};
    \addplot coordinates {(FK2, 0.01) (FK3, 0.01) (FK4, 0.08) (tri1, 0.08) (tri10, 0.01) (tri11, 0.02) (tri12, 0.21) (tri13, 0.01) (tri2, 0.29) (tri3, 0.04) (tri4, 0.07) (tri5, 0.02) (tri6, 1.78) (tri7, 1.81) (tri8, 0.06) (tri9, 0.01) (trit3, 0.05) (trit4, 0.49) (trit5, 207.84)};
    \addplot coordinates {(FK2, 1.70) (FK3, 0.80) (FK4, 0.87) (tri1, 0.98) (tri10, 0.85) (tri11, 0.88) (tri12, 1.04) (tri13, 0.83) (tri2, 1.16) (tri3, 0.90) (tri4, 0.94) (tri5, 0.87) (tri6, 1.27) (tri7, 1.45) (tri8, 0.91) (tri9, 0.82) (trit3, 0.87) (trit4, 1.04) (trit5, 5.21)};
  \end{axis}
\end{tikzpicture}

A simple vista se puede ver que para los casos en los que se distingue algo \texttt{operator\_gb} es mucho m√°s r√°pido, pero solo se ven los casos que demoran mucho tiempo, los otros no. As√≠ que a continuaci√≥n est√° el gr√°fico de vuelta pero solo con la parte de m√°s abajo y dejando que las barras muy largas se salgan del gr√°fico.

\noindent \begin{tikzpicture}
  \begin{axis}[
      ybar = 0.5pt, % Tipo de gr√°fico: barras verticales
      width = \textwidth,
      height = 0.4\textwidth,
      bar width = 0.01\textwidth, % Ancho de cada barra
      symbolic x coords = {FK2, FK3, FK4, tri1, tri2, tri3, tri4, tri5, tri6, tri7, tri8, tri9, tri10, tri11, tri12, tri13, trit3, trit4, trit5}, % Etiquetas en el eje x
      xtick = data, % Mostrar marcas en el eje x para cada dato
      ylabel = {Tiempo en segundos}, % Etiqueta del eje y
      %xlabel = {Categor√≠as}, % Etiqueta del eje x
      xticklabel style = {rotate = 45}, % Rotar etiquetas
      ymin = 0, % M√≠nimo del eje y
      ymax = 10,
      enlarge x limits = 0.03, % Espaciado en los bordes
      legend style = {at = {(0.024, 0.94)}, anchor = north west}, % Estilo de la leyenda
      legend entries = {\texttt{Buchberger}, \texttt{F4}, \texttt{operator\_gb}}, % Entradas de la leyenda
      cycle list = {{brown,fill = brown!30}, {red,fill=red!30}, {blue,fill=blue!30}}, % Colores
  ]
  ]
    % Datos para cada conjunto
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.01) (tri1, 0.26) (tri10, 0.01) (tri11, 0.03) (tri12, 3.27) (tri13, 0.01) (tri2, 6.01) (tri3, 0.02) (tri4, 0.04) (tri5, 0.01) (tri6, 6.53) (tri7, 33.33) (tri8, 0.09) (tri9, 0.00) (trit3, 0.01) (trit4, 0.14) (trit5, 77.16)};
    \addplot coordinates {(FK2, 0.01) (FK3, 0.01) (FK4, 0.08) (tri1, 0.08) (tri10, 0.01) (tri11, 0.02) (tri12, 0.21) (tri13, 0.01) (tri2, 0.29) (tri3, 0.04) (tri4, 0.07) (tri5, 0.02) (tri6, 1.78) (tri7, 1.81) (tri8, 0.06) (tri9, 0.01) (trit3, 0.05) (trit4, 0.49) (trit5, 207.84)};
    \addplot coordinates {(FK2, 1.70) (FK3, 0.80) (FK4, 0.87) (tri1, 0.98) (tri10, 0.85) (tri11, 0.88) (tri12, 1.04) (tri13, 0.83) (tri2, 1.16) (tri3, 0.90) (tri4, 0.94) (tri5, 0.87) (tri6, 1.27) (tri7, 1.45) (tri8, 0.91) (tri9, 0.82) (trit3, 0.87) (trit4, 1.04) (trit5, 5.21)};
  \end{axis}
\end{tikzpicture}

Ac√° se puede ver que en los casos m√°s chiquitos si pasa que \texttt{Buchberger} y \texttt{F4} le ganan a \texttt{operator\_gb}. Que en los grandes gane \texttt{operator\_gb} tiene sentido por el hecho de que tiene implementada la optimizaci√≥n de reducir las matrices mas eficientemente. Que en los chicos \texttt{Buchberger} y \texttt{F4} sean m√°s r√°pido tambi√©n tiene sentido por el hecho de que \cpp es mucho m√°s r√°pido que Python.

\section{Paralelismo}

El test que prueba que de el mismo resultado correr con distintas cantidades de hilos tambi√©n usa los mismos casos y mide los tiempos. En el siguiente gr√°fico se pueden ver los resultados.

\noindent \begin{tikzpicture}
  \begin{axis}[
      ybar = 0.5pt, % Tipo de gr√°fico: barras verticales
      width = \textwidth,
      height = 0.4\textwidth,
      bar width = 0.003\textwidth,
      symbolic x coords = {FK2, FK3, FK4, tri1, tri2, tri3, tri4, tri5, tri6, tri7, tri8, tri9, tri10, tri11, tri12, tri13, trit3, trit4, trit5}, % Etiquetas en el eje x
      xtick = data, % Mostrar marcas en el eje x para cada dato
      ylabel = {Tiempo en segundos}, % Etiqueta del eje y
      %xlabel = {Cantidad de hilos}, % Etiqueta del eje x
      xticklabel style = {rotate = 45}, % Rotar etiquetas
      ymin = 0, % M√≠nimo del eje y
      ymax = 215, % M√°ximo del eje y
      enlarge x limits = 0.03, % Espaciado en los bordes
      legend style = {at = {(0.024, 0.94)}, anchor = north west}, % Estilo de la leyenda
      legend entries = {1, 2, 4, 6, 8, 16}, % Entradas de la leyenda
  ]
    % Datos para cada conjunto
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.10) (tri10, 0.01) (tri11, 0.02) (tri12, 0.32) (tri13, 0.01) (tri2, 0.53) (tri3, 0.03) (tri4, 0.07) (tri5, 0.01) (tri6, 2.20) (tri7, 2.19) (tri8, 0.07) (tri9, 0.00) (trit3, 0.04) (trit4, 0.47) (trit5, 213.58)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.08) (tri10, 0.01) (tri11, 0.02) (tri12, 0.28) (tri13, 0.00) (tri2, 0.42) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.98) (tri7, 2.02) (tri8, 0.06) (tri9, 0.00) (trit3, 0.04) (trit4, 0.47) (trit5, 212.76)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.07) (tri10, 0.01) (tri11, 0.01) (tri12, 0.22) (tri13, 0.00) (tri2, 0.36) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.82) (tri7, 1.92) (tri8, 0.06) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45) (trit5, 209.93)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.22) (tri13, 0.01) (tri2, 0.32) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.86) (tri7, 1.84) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45) (trit5, 212.14)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.20) (tri13, 0.00) (tri2, 0.31) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.83) (tri7, 1.81) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45) (trit5, 208.28)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.20) (tri13, 0.00) (tri2, 0.29) (tri3, 0.03) (tri4, 0.05) (tri5, 0.01) (tri6, 1.79) (tri7, 1.80) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.46) (trit5, 208.62)};
  \end{axis}
\end{tikzpicture}

De vuelta a simple vista no se ve casi nada, salvo que en trit5 es casi lo mismo con m√°s hilos. Para poder ver en m√°s detalle, a continuaci√≥n un gr√°fico de lo mismo pero sin trit5.

\noindent \begin{tikzpicture}
  \begin{axis}[
      ybar = 0.5pt, % Tipo de gr√°fico: barras verticales
      width = \textwidth,
      height = 0.4\textwidth,
      bar width = 0.003\textwidth,
      symbolic x coords = {FK2, FK3, FK4, tri1, tri2, tri3, tri4, tri5, tri6, tri7, tri8, tri9, tri10, tri11, tri12, tri13, trit3, trit4}, % Etiquetas en el eje x
      xtick = data, % Mostrar marcas en el eje x para cada dato
      ylabel = {Tiempo en segundos}, % Etiqueta del eje y
      %xlabel = {Cantidad de hilos}, % Etiqueta del eje x
      xticklabel style = {rotate = 45}, % Rotar etiquetas
      ymin = 0, % M√≠nimo del eje y
      ymax = 2.5, % M√°ximo del eje y
      enlarge x limits = 0.03, % Espaciado en los bordes
      legend style = {at = {(0.024, 0.94)}, anchor = north west}, % Estilo de la leyenda
      legend entries = {1, 2, 4, 6, 8, 16}, % Entradas de la leyenda
  ]
    % Datos para cada conjunto
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.10) (tri10, 0.01) (tri11, 0.02) (tri12, 0.32) (tri13, 0.01) (tri2, 0.53) (tri3, 0.03) (tri4, 0.07) (tri5, 0.01) (tri6, 2.20) (tri7, 2.19) (tri8, 0.07) (tri9, 0.00) (trit3, 0.04) (trit4, 0.47)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.08) (tri10, 0.01) (tri11, 0.02) (tri12, 0.28) (tri13, 0.00) (tri2, 0.42) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.98) (tri7, 2.02) (tri8, 0.06) (tri9, 0.00) (trit3, 0.04) (trit4, 0.47)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.07) (tri10, 0.01) (tri11, 0.01) (tri12, 0.22) (tri13, 0.00) (tri2, 0.36) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.82) (tri7, 1.92) (tri8, 0.06) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.22) (tri13, 0.01) (tri2, 0.32) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.86) (tri7, 1.84) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.20) (tri13, 0.00) (tri2, 0.31) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.83) (tri7, 1.81) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.20) (tri13, 0.00) (tri2, 0.29) (tri3, 0.03) (tri4, 0.05) (tri5, 0.01) (tri6, 1.79) (tri7, 1.80) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.46)};
  \end{axis}
\end{tikzpicture}

Se puede ver que aumentar los hilos hace que sea un poco m√°s r√°pido, pero muy poco. Esto tiene sentido por el hecho de que solo la parte de agregar ambig√ºedades est√° paralelizada.

\section{Representaci√≥n con cofactores}

El test que compara ejecutar Buchberger con y sin representaci√≥n con cofactores tambi√©n usa los mismos casos y mide los tiempos. Este es el √∫nico benchmark que no funciona con mains de la carpeta \path{mains} sino que usa sus propios archivos, y adem√°s este benchmark mide los tiempos desde \cpp. En el siguiente gr√°fico se pueden ver los resultados.

\noindent \begin{tikzpicture}
  \begin{axis}[
      ybar = 0.5pt, % Tipo de gr√°fico: barras verticales
      width = \textwidth,
      height = 0.4\textwidth,
      bar width = 0.015\textwidth, % Ancho de cada barra
      symbolic x coords = {FK2, FK3, FK4, tri1, tri2, tri3, tri4, tri5, tri6, tri7, tri8, tri9, tri10, tri11, tri12, tri13, trit3, trit4, trit5}, % Etiquetas en el eje x
      xtick = data, % Mostrar marcas en el eje x para cada dato
      ylabel = {Tiempo en segundos}, % Etiqueta del eje y
      %xlabel = {Categor√≠as}, % Etiqueta del eje x
      xticklabel style = {rotate = 45}, % Rotar etiquetas
      ymin = 0, % M√≠nimo del eje y
      %ymax = 215,
      enlarge x limits = 0.03, % Espaciado en los bordes
      legend style = {at = {(0.024, 0.94)}, anchor = north west}, % Estilo de la leyenda
      legend entries = {Normal, Representaci√≥n con cofactores}, % Entradas de la leyenda
  ]
    % Datos para cada conjunto
    \addplot coordinates {(FK2, 0.0) (FK3, 0.0) (FK4, 0.007) (tri1, 0.238) (tri10, 0.006) (tri11, 0.026) (tri12, 2.99) (tri13, 0.005) (tri2, 5.497) (tri3, 0.016) (tri4, 0.03) (tri5, 0.006) (tri6, 5.929) (tri7, 30.415) (tri8, 0.083) (tri9, 0.0) (trit3, 0.008) (trit4, 0.126) (trit5, 70.421)};
    \addplot coordinates {(FK2, 0.0) (FK3, 0.0) (FK4, 0.011) (tri1, 0.383) (tri10, 0.007) (tri11, 0.035) (tri12, 4.26) (tri13, 0.016) (tri2, 8.544) (tri3, 0.022) (tri4, 0.052) (tri5, 0.009) (tri6, 7.749) (tri7, 101.729) (tri8, 0.113) (tri9, 0.001) (trit3, 0.011) (trit4, 0.173) (trit5, 94.521)};
  \end{axis}
\end{tikzpicture}

Se puede ver que la representaci√≥n con cofactores lleva m√°s tiempo, pero en general no tanto m√°s. Ac√° no hay demasiado m√°s para ver mirando solo la parte de abajo, as√≠ que no se hace un gr√°fico con la parte de m√°s abajo.

\section{Pertenencia a ideales}

El test que para conjuntos generadores construidos al azar y polinomios construidos al azar ve con los distintos algoritmos si el polinomio est√° en el ideal generado o no, tambi√©n mide los tiempos. Estos corren tanto para los racionales como para la aritm√©tica modular, pero para los racionales incluyen la comparaci√≥n con \texttt{operator\_gb} y para la aritm√©tica modular no, porque \texttt{operator\_gb} es solo para racionales. Este benchmark imprime los tiempos promedios sobre todos los conjuntos generadores construidos al azar y polinomios construidos al azar y tambi√©n los tiempos m√°ximos. Estos son los resultados para los racionales (tal cual los imprime el test, \texttt{Buch} es \texttt{Buchberger} y \texttt{GB} es \texttt{operator\_gb}):

\begin{minted}{text}
  Average times:
  Buch: 0.0041429424s
  F4: 0.0105502963s
  GB: 0.8995876765s
  Max times:
  Buch: 0.1320753098s
  F4: 0.0925185680s
  GB: 4.6477575302s
\end{minted}

Y estos para la aritm√©tica modular (tambi√©n tal cual los imprime el test):

\begin{minted}{text}
  Average times:
  Buch_Zp: 0.0028817248s
  F4_Zp: 0.0072190428s
  Max times:
  Buch_Zp: 0.0779249668s
  F4_Zp: 0.0799708366s
\end{minted}

Estos datos igualmente mucho no dicen, porque como buscan por una cierta cantidad de pasos, y los pasos son distintos en los distintos algoritmos, no se puede comparar. En particular, un paso de \texttt{F4} puede corresponder a muchos pasos de \texttt{Buchberger}.

Este benchmark se us√≥ principalmente para tenerlo como comparaci√≥n cuando se hac√≠an cambios en el c√≥digo. Como se corr√≠an siempre todos los tests y benchmarks antes y despu√©s del cambio, este serv√≠a para comparar el antes y el despu√©s.

\chapter{Conclusiones}\label{cap:Conclusiones}

El tema de este trabajo fue propuesto por el director Cristian Vay por su inter√©s ya mencionado de usarlo para las √°lgebras de Nichols. Para m√≠ este era un tema completamente nuevo, as√≠ que empec√© por estudiar el tema. Primero leyendo \cite{book:ideals-varieties-algorithms} que trata sobre bases de Gr√∂bner conmutativas, mientras le√≠a ese libro hice tambi√©n una implementaci√≥n as√≠ nom√°s de bases de Gr√∂bner conmutativas en \cpp. Esto fue bueno porque me sirvi√≥ de pr√°ctica para despu√©s hacer la implementaci√≥n de bases de Gr√∂bner no conmutativas. Despu√©s de eso fui leyendo \cite{thesis:Hof20} y \cite{phdthesis:Hof23}, que son sobre bases de Gr√∂bner no conmutativas, e implementando lo explicado.

A continuaci√≥n menciono algunas cosas positivas y despu√©s algunos posibles trabajos futuros.

\section{Cosas positivas de este trabajo}

Es la primer implementaci√≥n de bases de Gr√∂bner no conmutativas en \cpp (que yo sepa). Esto es muy bueno porque \cpp es un lenguaje particularmente r√°pido y en el que es f√°cil paralelizar. Esto es √∫til si se quieren correr casos que se demoran mucho.

Es la primer implementaci√≥n de F4 que funciona para un cuerpo arbitrario (que yo sepa). Esto est√° bueno para que si en alg√∫n momento alguien lo quiere usar para alg√∫n cuerpo distinto lo pueda hacer.

La implementaci√≥n de Buchberger incluye la parte de la representaci√≥n con cofactores, que si bien es algo muy f√°cil, la √∫nica otra implementaci√≥n que lo hace es \texttt{operator\_gb} (que yo sepa).

\section{Trabajos futuros}\label{section:trabajos futuros}

Como ya se dijo varias veces, falta usar la reducci√≥n por filas de Faug√®re-Lachartre que es m√°s eficiente, y esa es una de las cosas m√°s importantes para hacer.

Del algoritmo F4 (y de Buchberger) para el caso s√≠ conmutativo hay varias implementaciones en \cpp, por ejemplo \cite{lib:openf4, lib:mathic, lib:M4GB}, inclusive en paralelo, como \cite{DBLP:journals/jsc/Reeves98, lib:parallelGBC}. Muchas son solo para los enteros m√≥dulo un primo, pero hay algunas que tambi√©n para los racionales. Es muy probable que analizando esas implementaciones se puedan sacar muchas cosas √∫tiles, en particular, podr√≠a ser que ya alguien haya hecho la implementaci√≥n de la reducci√≥n por filas de Faug√®re-Lachartre, ya que posiblemente sirva tambi√©n para el caso no conmutativo.

Cuando se fue haciendo la librer√≠a, muchas veces pasaba que hab√≠a cambios que parec√≠an optimizaciones pero al hacerlos el c√≥digo resultaba andar m√°s lento, as√≠ que se descartaban esos cambios. Ser√≠a bueno agregar m√°s tests y probar hacer cambios para ver si mejoran o no los tiempos teniendo m√°s tests.

Se podr√≠a analizar cu√°nto tiempo se consume en las distintas partes de los algoritmos, porque eso podr√≠a ayudar a saber en qu√© partes se pueden realizar optimizaciones.

En la librer√≠a hay una especializaci√≥n de \texttt{rref} para hacer que para \texttt{mpq\_class} sea m√°s r√°pido, pero para aritm√©tica modular se est√° usando un tipo propio definido en el archivo \path{extras/ModularArithmetic.hpp} y se usa la versi√≥n gen√©rica de \texttt{rref}. Es posible que ya haya librer√≠as que tengan tipos de aritm√©tica modular m√°s r√°pidos que el que se implement√≥ y con una reducci√≥n por filas m√°s r√°pida.

Actualmente la librer√≠a no viene con nada para instalarla autom√°ticamente porque en \cpp eso no es f√°cil de hacer. Esto significa que si alguien quiere usar la librer√≠a tiene que arregl√°rselas y probablemente hacer algo medio feo como poner los archivos en alguna carpeta particular. Otras librer√≠as de \cpp s√≠ vienen con algo para eso, as√≠ que ser√≠a bueno hacerlo para esta librer√≠a tambi√©n.

Adem√°s de los ideales de la \cref{def:ideal} existen los ideales a izquierda que se definen de la siguiente manera.
\begin{definition}
  Sean $R$ un anillo e $I ‚äÜ R$. Se define que $I$ es un ideal a izquierda de $R$ si y solo si:
  \begin{enumerate}
    \item $I ‚â† ‚àÖ$.
    \item $‚àÄa, b ‚àà I : a + b ‚àà I$.
    \item $‚àÄa ‚àà I, r ‚àà R : r a ‚àà I$.
  \end{enumerate}
\end{definition}
\noindent Con los ideales a izquierda sobre polinomios no conmutativos tambi√©n hay toda una teor√≠a de bases de Gr√∂bner. En \cite{phdthesis:Hof23} se puede encontrar una explicaci√≥n sobre esta teor√≠a. Implementar el c√°lculo de bases de Gr√∂bner de la teor√≠a de ideales a izquierda en \cpp es otro trabajo que se podr√≠a hacer. An√°logamente, tambi√©n se pueden considerar ideales a derecha.

Como ya se mencion√≥ en el \cref{cap:Benchmarks}, los FK$n$ no se sabe para $n ‚â• 6$ si tienen una base finita o no. Cuando se tenga una versi√≥n muy buena de F4 algo que se podr√≠a hacer es correrla por mucho tiempo para FK6 u otros FK para ver si llega en alg√∫n momento a una base finita.

Actualmente para estudiar el tema de bases de Gr√∂bner, tanto conmutativas como no conmutativas, hay libros y art√≠culos sobre el tema, en particular \cite{book:ideals-varieties-algorithms} para conmutativas y \cite{thesis:Hof20} para no conmutativas, pero para practicar las implementaciones no hay mucha ayuda. Por ejemplo, cuando implement√© las bases de Gr√∂bner conmutativas para practicar tuve que hacer mi propio testing. Para que estudiar el tema sea m√°s f√°cil algo que ser√≠a √∫til es preparar problemas del estilo de programaci√≥n competitiva sobre el tema. Estos problemas se podr√≠an poner en, por ejemplo, \href{https://judge.yosupo.jp}{Library Checker}, o en un grupo de \href{https://codeforces.com}{Codeforces}.

Por √∫ltimo, otra cosa que se podr√≠a hacer es implementar el c√°lculo de bases de Gr√∂bner no conmutativas en otros lenguajes como por ejemplo Rust.

\chapter{Bibliograf√≠a}

\printbibliography[heading=none]

\end{document}
