\documentclass[12pt]{report}

\usepackage{polyglossia}
\setdefaultlanguage{spanish}

\usepackage{ccicons}

\usepackage{amsthm}
\usepackage{fontspec}
\usepackage{enumitem}
\usepackage[bookmarks]{hyperref}
\defaultfontfeatures{Renderer=Basic,Ligatures={TeX}}
\usepackage[math-style=ISO,bold-style=ISO]{unicode-math}
\setmathfont{Asana Math}
\usepackage{witharrows}
\WithArrowsOptions{displaystyle,i,tikz={font={\small\normalfont}},ygap=0.5em,wrap-lines} % Agregar fleqn para que se ponga a la izquierda

\usepackage{titlesec}
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries}  % Estilo del tÃ­tulo
  {CapÃ­tulo \thechapter}                 % NÃºmero del capÃ­tulo
  {20pt}                        % Espacio entre el nÃºmero y el tÃ­tulo
  {}                            % Formato del tÃ­tulo
\titlespacing*{\chapter}{0pt}{-15pt}{25pt}  % Ajusta los mÃ¡rgenes

\DeclareEmphSequence{\bfseries}

\hfuzz=50pt % Elimina warnings de "Overfull \hbox"

\usepackage[margin=2cm, top=1cm, bottom=1cm]{geometry} % Adjust the margin values as desired

\usepackage{float}
\usepackage[ruled, vlined, linesnumbered, spanish]{algorithm2e}
\SetKw{Break}{break}
\SetKwFor{Loop}{loop}{}{end loop}

\usepackage{listings}
\lstset{basicstyle=\ttfamily} % Cambia la fuente a monospace
\usepackage{minted}
\setminted{autogobble}

\usepackage[capitalise]{cleveref}
\crefname{section}{SecciÃ³n}{Secciones} % Para que use "SecciÃ³n" en vez de "Apartado"
\crefname{subsection}{SubsecciÃ³n}{Subsecciones} % Para que use "SubsecciÃ³n" en vez de "Subapartado"

\usepackage[backend=biber, autolang=hyphen, bibencoding=inputenc, isbn=false, uniquename=false, style=alphabetic]{biblatex}
\addbibresource{biblio.bib}
% PÃ¡gina para buscar citas: zbmath.org

\setlist[enumerate,1]{label={\em{(\arabic*)}}}

\usepackage{fancyhdr}
\setlength{\footskip}{0.6cm} % Evita que los nÃºmeros de pÃ¡gina se salgan de la pÃ¡gina

\usepackage{pgfplots} % Para los grÃ¡ficos

\newtheoremstyle{customstyle} % <name>
{} % <Space above>
{} % <Space below>
{\slshape} % <Body font> % Preguntar que opinan, y porque hay un warning
{} % <Indent amount>
{\bfseries} % <Theorem head font>
{.} % <Punctuation after theorem head>
{.5em} % <Space after theorem head>
{} % <Theorem head spec (can be left empty, meaning `normal`)

\theoremstyle{customstyle}
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{definition}[theorem]{DefiniciÃ³n}
\newtheorem{lemma}[theorem]{Lema}
\newtheorem{colorary}[theorem]{Colorario}
\newtheorem{problem}{Problema}
\newtheorem{observation}[theorem]{ObservaciÃ³n}
\addto\captionsspanish{\renewcommand{\proofname}{DemostraciÃ³n}}
\renewenvironment{proof}[1][\proofname]{{\noindent \bfseries #1: }}{\qed} % Cambiar estilo del tÃ­tulo de la demostraciÃ³n

\newtheoremstyle{factstyle} % <name>
{} % <Space above>
{} % <Space below>
{\normalfont} % <Body font> % Preguntar que opinan, y porque hay un warning
{1.5em} % <Indent amount>
{\bfseries} % <Theorem head font>
{.} % <Punctuation after theorem head>
{.5em} % <Space after theorem head>
{} % <Theorem head spec (can be left empty, meaning `normal`)

\theoremstyle{factstyle}
\newtheorem{fact}{AfirmaciÃ³n}[theorem]


\newcommand\cpp{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\relsize{-3}{\textbf{++}}}\xspace}
\newcommand\cppXX{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\relsize{-3}{\textbf{++}}}20\xspace}

\DeclareMathOperator{\sop}{sop}
\DeclareMathOperator{\lm}{lm}
\DeclareMathOperator{\lc}{lc}
\DeclareMathOperator{\lt}{lt}
\DeclareMathOperator{\tail}{tail}
\DeclareMathOperator{\amb}{amb}
\renewcommand{\S}{\text{S}}
\DeclareMathOperator{\B}{B}
\DeclareMathOperator{\spn}{span} % span estÃ¡ ocupado y re rompe todo si lo re-declaro
\DeclareMathOperator{\mat}{mat}
\DeclareMathOperator{\poli}{poli}
\DeclareMathOperator{\filas}{filas}

% Convenciones de uso de letras:
% X: Alfabeto
% K: Cuerpo
% R: Anillo
% I: Ideal
% G: Conjunto generador
% F: Conjunto de polinomios (que no sea un conjunto generador)
% f, g: Polinomios
% m: Monomios
% M: Conjunto de monomios
% c, k: Coeficiente de K
% a, b, c, d: Coeficientes de monomios
% Î±: AmbigÃ¼edades
% n: LÃ­mite de sumatorias
% i, j: Ãndices

\begin{document}

\def\tituloTesis{ImplementaciÃ³n de bases de GrÃ¶bner no conmutativas en \cpp con un poquito de paralelismo}
\input{CarÃ¡tula}


\tableofcontents

\chapter{IntroducciÃ³n}

En este capÃ­tulo se explica informalmente de quÃ© se trata la tesis.

Usted posiblemente haya escuchado hablar de los polinomios de varias variables, esos como $5 + 3 y - 2 x y + x^3 y^5$, y que todo el conjunto de los polinomios con, por ejemplo, variables $x, y$ sobre un cuerpo $K$ se denota como $K[x, y]$. En esos polinomios el producto entre las variables conmuta; por ejemplo, el polinomio $x y$ es igual al polinomio $y x$. Se puede considerar que el producto entre las variables no conmuta, asÃ­ que por ejemplo, $x y â‰  y x$; pero el producto de las variables con los coeficientes sÃ­ sigue conmutando, por ejemplo $x 3 y = 3 x y$. AsÃ­ se obtiene algo como los polinomios, pero en el que los monomios son palabras. A esos nuevos polinomios se los llama polinomios no conmutativos y, por ejemplo, para las variables $x, y$ con coeficientes en un cuerpo $K$ se denotan $KâŸ¨x, yâŸ©$. En general si $X$ es un alfabeto, $KâŸ¨XâŸ©$ es el conjunto de los polinomios no conmutativos sobre $X$.

Un problema de decisiÃ³n que existe sobre los polinomios no conmutativos es: dado un conjunto $G$ de polinomios no conmutativos y un polinomio no conmutativo $f$, decidir si $f$ se puede escribir como combinaciÃ³n lineal de elementos de $G$ con coeficientes en $KâŸ¨XâŸ©$, o escrito formalmente:

\begin{problem}\label{problem:principal}
  Dados $G$ un conjunto de polinomios no conmutativos y $f$ un polinomio no conmutativo, determinar si vale que
  \[ âˆƒn âˆˆ â„•, g_1, â€¦, g_n âˆˆ G, f_1, â€¦, f_n, f'_1, â€¦, f'_n âˆˆ KâŸ¨XâŸ© : f = âˆ‘_{i = 1}^n f_i g_i f'_i \text{.}\]
\end{problem}

AcÃ¡ los $f_i$ y $f'_i$ se llaman cofactores. Este problema asÃ­ planteado no es decidible, pero sÃ­ es semi-decidible. Esto significa que no hay un algoritmo que dice si vale la expresiÃ³n o no, pero sÃ­ hay un algoritmo que en los casos en los que sÃ­ vale termina diciendo que sÃ­ y los casos en los que no vale puede no terminar.

El motivo por el cual no es decidible es que el problema de la palabra se reduce a esto. Ver \cite{web:wiki:WordPproblem} para informaciÃ³n del problema de la palabra y la SecciÃ³n 1.3 de \cite{article:MORA1994131} para saber como es la reducciÃ³n.

Para trabajar en algoritmos para ese problema se considera el conjunto $(G)$ (que asÃ­ se denota) de todos los polinomios no conmutativos que satisfacen ese $âˆƒ$ y se calcula algo que se llama una base de GrÃ¶bner de $(G)$, que puede ser finita o infinita computacionalmente enumerable. Son estos Ãºltimos casos los que hacen que el problema no sea computable. % Pongo computacionalmente enumerable y no solo enumerable porque enumerable no dice nada

Para calcular esas bases de GrÃ¶bner hay dos algoritmos destacados, llamados el algoritmo de Buchberger y el algoritmo F4. Estos algoritmos, al igual que mucha de la teorÃ­a, estÃ¡n inspirados en la teorÃ­a para resolver el problema anÃ¡logo para los polinomios conmutativos. De hecho, muchos de los nombres de las cosas se usaron primero para el caso conmutativo y despuÃ©s se usÃ³ el mismo nombre para el caso no conmutativo. Por ejemplo, ``algoritmo de Buchberger'' en otros contextos se puede estar refiriendo al algoritmo para el caso conmutativo. En esta tesis siempre se va a estar hablando del caso no conmutativo. Para una explicaciÃ³n del caso conmutativo ver \cite{book:ideals-varieties-algorithms}.

De antes de esta tesis existen varias implementaciones del algoritmo de Buchberger en el caso no conmutativo, por ejemplo \cite{lib:GBNP, lib:DGPS, lib:NCAlgebra}. El algoritmo F4 para el caso no conmutativo fue primero adaptado por Xiu Xingqiang en \cite{phdthesis:XiuXingqiang12} y estÃ¡ implementada en MAGMA. Luego, Clemens Hofstadler hizo en \cite{thesis:Hof20} su propia implementaciÃ³n en SAGEMATH (su elecciÃ³n de sage la justifica en la SecciÃ³n 6.2). Que yo sepa esas son las Ãºnicas dos implementaciones de F4 para el caso no conmutativo.

La parte de implementar en \cpp esos algoritmos se logrÃ³, pero hay una optimizaciÃ³n que ayuda bastante y no se hizo. La parte de hacerlo correr en paralelo se hizo, pero solo para una parte y para la parte de la optimizaciÃ³n que no se hizo tampoco se hizo nada en paralelo. Por lo tanto, la implementaciÃ³n que se logrÃ³ en los casos muy grandes no le logra ganar a la implementaciÃ³n en SAGEMATH. Esto no significa que todo el trabajo no haya servido para nada, porque se podrÃ­a continuar con el desarrollo del cÃ³digo y lograr mejorar suficiente la implementaciÃ³n para que sea al menos igual de buena que la de SAGEMATH.

Alguien podrÃ­a preguntar para quÃ© sirve tratar de resolver ese problema y calcular bases de GrÃ¶bner no conmutativas. En el caso conmutativo hay un montÃ³n de aplicaciones prÃ¡cticas importantes, por ejemplo en robÃ³tica porque el caso conmutativo tiene mucho significado geomÃ©trico. En el caso no conmutativo en cambio las aplicaciones son mÃ¡s limitadas, pero existen.

Algo para lo que las bases de GrÃ¶bner no conmutativas son muy Ãºtiles es para trabajar con Ã¡lgebras presentadas por generadores y relaciones. En este contexto, los generadores son las variables y las relaciones estÃ¡n dadas por los polinomios generadores del ideal. Un problema que ayuda a resolver las bases de Grobner es el cÃ¡lculo de la dimensiÃ³n de este tipo de Ã¡lgebras. Por ejemplo, algunos investigadores de FAMAF (incluido Cristian Vay, el director de este trabajo) se enfrentan a este problema trabajando con (las que llaman) Ã¡lgebras de Nichols, que estÃ¡n explicadas en \cite{book:introNichols}. Usaremos algunos ejemplos de estas en el \cref{cap:Benchmarks}.

TambiÃ©n hay algunas aplicaciones de bases de GrÃ¶bner no conmutativas (y tambiÃ©n de conmutativas) en criptografÃ­a. En \cite{article:crypto_gb} se habla de eso.

Toda esta exposiciÃ³n es autocontenida para facilitar su lectura, asÃ­ que se incluyen algunas cosas que no son estrictamente del tema de la tesis, si no que son necesarias para los temas de la tesis. % No se con que remplazar "cosas" acÃ¡

\chapter{Preliminares}\label{cap:Preliminares}

En este capÃ­tulo se desarrolla toda la parte matemÃ¡tica, basada principalmente en la exposiciÃ³n de \cite{thesis:Hof20}. Primero se explican sistemas de re-escritura, despuÃ©s se introduce el Ã¡lgebra libre, se prueba que es un anillo, se dan algunas definiciones y propiedades de anillos y se definen las bases de GrÃ¶bner. Por Ãºltimo se explican y dan seudocÃ³digos para los algoritmos de Buchberger y F4, que son los dos algoritmos importantes para calcular bases de GrÃ¶bner no conmutativas.

El capÃ­tulo incluye demostraciones de muchos de los resultados expuestos pero quienes tengan interÃ©s principalmente en la implementaciÃ³n de los algoritmos pueden obviar su lectura o leerlas solo por encima.

\section{Sistemas de re-escritura}

Sistemas de re-escritura trata bÃ¡sicamente sobre el estudio de relaciones entre objetos con la idea de usar las relaciones para convertir un objeto en otro. En general vamos a usar relaciones denotadas con algÃºn sÃ­mbolo con forma de flecha porque se tiene la idea de que se \textsl{usa} la relaciÃ³n para convertir el objeto de la base de la flecha en el objeto de la punta de la flecha. Como recordatorio, una relaciÃ³n entre $A$ y $B$ es un subconjunto de $A Ã— B$ y una relaciÃ³n sobre $A$ un subconjunto de $A^2$.

Para toda esta secciÃ³n fijemos un conjunto $A$. Primero recordamos algunas operaciones muy comunes sobre relaciones.

\begin{definition}\label{def:operaciones relaciones}
  Dadas relaciones $â†’$ y $âŸ¿$ sobre $A$ se define:
  \begin{itemize}
    \item $â†’ âˆ˜ âŸ¿\ = \{(x, z) âˆˆ A^2 : âˆƒy âˆˆ A : x â†’ y âˆ§ y âŸ¿ z\}$.
    \item $â†’^0\ = \{(x, x) : x âˆˆ A\}$.
    \item $â†’^{i + 1}\ =\ â†’^i âˆ˜ â†’$.
    \item $â†’^*\ = â‹ƒ_{i = 0}^âˆ â†’^i$.
    \item $â†\ = \{(y, x) âˆˆ A^2 : (x, y) âˆˆ\ â†’\}$.
    \item $â†”\ =\ â†’ âˆª â†$.
  \end{itemize}

  Con estÃ¡ definiciÃ³n se define automÃ¡ticamente tambiÃ©n $â†”^*$ que se llama la clausura reflexo-transitiva de $â†’$.
\end{definition}

Con $â†$ y $â†”$ podrÃ­a haber problema para usarlas con una relaciÃ³n denotada por un sÃ­mbolo que no tenga forma de flecha, pero en esta tesis las relaciones que se usan siempre se denotan con un sÃ­mbolo con forma de flecha.

Para el resto de la secciÃ³n fijemos una relaciÃ³n $â†’$ sobre $A$. Tenemos los siguientes dos lemas.

\begin{lemma}\label{lemma:â†’* como âˆƒ}
  Sean $a, b âˆˆ A$. Entonces
  \[ a â†’^* b â‡” âˆƒn âˆˆ â„• âˆª \{0\}, x_0, â€¦, x_n âˆˆ A : x_0 = a âˆ§ x_n = b âˆ§ âˆ€i âˆˆ {1, â€¦, n} : x_{i-1} â†’ x_i \text{.}\]
  \qed
\end{lemma}

\begin{lemma}\label{lemma:â†”* min equiv que contiene a â†’}
  $â†”^*$ es la mÃ­nima relaciÃ³n de equivalencia que contiene a $â†’$.
  \qed
\end{lemma}

Como vamos a hablar de usar $â†’$ para transformar un objeto en otro, es Ãºtil la proxima definiciÃ³n que permite hablar de la forma normal de un objeto como el elemento al que se llega aplicando $â†’$ hasta que no se pueda mÃ¡s.

\begin{definition}\label{def:forma normal}
  Dados $a, b âˆˆ A$ se define:
  \begin{itemize}
    \item $a$ estÃ¡ en forma normal $â‡” âˆ„x âˆˆ A : a â†’ x$.
    \item $b$ es forma normal de $a â‡” a â†’^* b âˆ§ b$ estÃ¡ en forma normal.
    \item $a$ tiene forma normal $â‡” âˆƒx âˆˆ A : x$ es forma normal de $a$.
    \item $a â†“ b â‡” âˆƒx âˆˆ A : a â†’^* x âˆ§ b â†’^* x$.
  \end{itemize}
\end{definition}

Con $â†“$ pasa lo mismo que con $â†$ y $â†”$ de que podrÃ­a ser problemÃ¡tico usarla para una relaciÃ³n denotada con un sÃ­mbolo que no tenga forma de flecha, pero en esta tesis eso no pasa.

TambiÃ©n necesitamos definir las siguientes propiedades de las relaciones.

\begin{definition} Se define que
  \begin{itemize}
    \item $â†’$ es confluente $â‡” âˆ€x, y, z âˆˆ A : x â†’^* y âˆ§ x â†’^* z â‡’ y â†“ z$.
    \item $â†’$ es Church-Rosser $â‡” âˆ€x, y âˆˆ A : x â†”^* y â‡” x â†“ y$.
    \item $â†’$ es normalizante $â‡” âˆ€x âˆˆ A : x$ tiene forma normal.
    \item $â†’$ es terminante $â‡” âˆ„X âˆˆ A^â„• : âˆ€i âˆˆ â„• : X_i â†’ X_{i + 1}$.
  \end{itemize}
\end{definition}

Las siguientes propiedades referidas a relaciones serÃ¡n de utilidad.

\begin{theorem}\label{thm:terminante â‡’ normalizante}
  $â†’$ es terminante $â‡’Â â†’$ es normalizante.
  \qed
\end{theorem}

\begin{theorem}\label{thm:confluente â‡” Church-Rosser}
  $â†’$ es confluente $â‡”Â â†’$ es Church-Rosser.
  \qed
\end{theorem}

Si $â†’$ es confluente y normalizante entonces todos los elementos tienen una Ãºnica forma normal, y si ademÃ¡s es terminante tenemos la siguiente observaciÃ³n.

\begin{observation}\label{obs:â†’ confluente y terminante}
  Si $â†’$ es confluente y terminante entonces calcular la forma normal de $a$ y de $b$ permite decidir si $a â†” ^* b$.
  \qed
\end{observation}

\section{Ãlgebra libre}

El Ã¡lgebra libre es bÃ¡sicamente el conjunto de los polinomios no conmutativos con sus operaciones. En los polinomios no conmutativos los monomios son palabras y la Ãºnica operaciÃ³n interna de los monomios (entre monomios y que devuelve monomios) es la multiplicaciÃ³n, que equivale a la concatenaciÃ³n de palabras.

\begin{definition}
  Sea $X$ un alfabeto finito. Se define la estructura $(âŸ¨XâŸ©, Â·)$ de la siguiente manera:
  \begin{itemize}
    \item $âŸ¨XâŸ©$ es el conjunto palabras finitas sobre $X$.
    \item $Â· : âŸ¨XâŸ©^2 â†’ âŸ¨XâŸ©$ es la concatenaciÃ³n.
  \end{itemize}
  Al par $(âŸ¨XâŸ©, Â·)$ se lo llama el monoide libre sobre $X$, a los elementos de $âŸ¨XâŸ©$ se los llama monomios libres sobre $X$ y a $Â·$ el producto de $âŸ¨XâŸ©$.

  Si $X = \{x_1, â€¦, x_n\}$ escribimos $âŸ¨x_1, â€¦, x_nâŸ©$ un lugar de $âŸ¨XâŸ©$.
\end{definition}

Por ejemplo, si $X = \{a, b, c\}$, algunos monomios son:

\begin{align*}
  m_0 &= abbcb \text{,} \\
  m_1 &= bbc \text{,} \\
  m_2 &= bcb \text{,} \\
  m_3 &= Îµ \text{,} \\
  m_1 Â· m_2 &= bccbcb \text{.}
\end{align*}

El $Îµ$ de $m_3$ es la palabra vacÃ­a. Notar que $m_1 â‰  m_2$ ya que el producto es no conmutativo.

\

Para todo el resto de la tesis fijemos un alfabeto finito $X$.

\

En estos monomios, al igual que en los conmutativos, se puede hablar de que un monomio divida a otro, pero acÃ¡ que un monomio divida a otro es equivalente a que sea una sub-palabra.

\begin{definition}
  Sean $m, m' âˆˆ âŸ¨XâŸ©$. Se define que $m$ divida a $m'$, denotado como $m | m'$ de la siguiente forma:
  \begin{itemize}
    \item $m | m' â‡” âˆƒa , b âˆˆ âŸ¨XâŸ© : m' = a m b$.
  \end{itemize}
\end{definition}

En el ejemplo de antes tenemos que $m_1 | m_0$ ya que $m_0 = a m_1 b$.

Hablar del resultado de la divisiÃ³n es un poco mÃ¡s complicado acÃ¡ porque tendrÃ­a que haber dos resultados, el $a$ y el $b$ de la definiciÃ³n, asÃ­ que no vamos a hablar de dividir un monomio en otro ni escribir divisiones entre monomios.

Mas adelante harÃ¡ falta tener un orden entre los elementos de $âŸ¨XâŸ©$. Se podrÃ­a fijar uno concreto definiendo directamente $â‰¤$ para $âŸ¨XâŸ©$, pero es mejor enunciar las mÃ­nimas propiedades que harÃ¡n falta y trabajar con cualquier orden que las satisfaga. Eso se logra con la siguiente definiciÃ³n.

\begin{definition}\label{def:buen orden monomial}
  Sea $â‰¤$ un orden total sobre $âŸ¨XâŸ©$. Se define que $â‰¤$ es un buen orden monomial si y solo si:
  \begin{enumerate}
    \item $âˆ€m, m', a, b âˆˆ âŸ¨XâŸ© : m â‰¤ m' â‡’ a m b â‰¤ a m' b$.
    \item $âˆ€S âŠ† âŸ¨XâŸ© : S â‰  âˆ… â‡’ S$ tiene mÃ­nimo elemento con respecto a $â‰¤$.
  \end{enumerate}
\end{definition}

Un ejemplo de orden que cumple con esta definiciÃ³n es el siguiente.

\begin{definition}
  Fijemos $X = \{x_1, â€¦, x_n\}$ y un orden total sobre $X$: $x_1 â‰¤ â€¦ â‰¤ x_n$, el cual se extiende (como es usual) de forma lexicogrÃ¡fica a $âŸ¨XâŸ©$. El orden lexicogrÃ¡fico por grado $ â‰¤_{deglex}$ sobre $âŸ¨XâŸ©$ se define asÃ­:
  \[ m â‰¤_{deglex} m' â‡” |m| < |m'| âˆ¨ (|m| = |m'| âˆ§ m â‰¤ m') \text{.}\]
\end{definition}

O sea, el orden lexicogrÃ¡fico por grado ordena primero por cardinalidad, tambiÃ©n llamado grado, y desempata con el orden lexicogrÃ¡fico. Por ejemplo, tenemos que $bc â‰¤_{deglex} abb$, $aabbc â‰¤_{deglex} abbcc$ y $Îµ â‰¤_{deglex} a$. Se puede probar fÃ¡cilmente que este orden es un buen orden monomial.

\

A partir de ahora fijamos un buen orden monomial $â‰¤$ y vamos a usar $<$, $â‰¥$ y $>$ como se usan habitualmente.

La siguiente propiedad es consecuencia directa de la definiciÃ³n de buen orden monomial.

\begin{theorem}\label{thm:â‰¤ no sucesiones dec inf}
  La relaciÃ³n $â‰¤$ no tiene sucesiones estrictamente decrecientes infinitas.
  \qed
\end{theorem}

Ahora pasemos a hablar de sumar monomios entre sÃ­ para tener polinomios no conmutativos.

\begin{definition}
  Sea $R$ un anillo conmutativo. Se define la $R$-Ã¡lgebra libre sobre $X$ como el conjunto
  \[ RâŸ¨XâŸ© = \{âˆ‘_{i = 1}^n c_i m_i : c_1, â€¦, c_n âˆˆ R, m_1, â€¦, m_n âˆˆ âŸ¨XâŸ©\}\]
  con las siguientes operaciones: la suma de los elementos de $RâŸ¨XâŸ©$ como definido unir las $âˆ‘$, el producto por escalares definido como
  \[ c (âˆ‘_{i = 1}^n c_i m_i) = (âˆ‘_{i = 1}^n c c_i m_i) \text{,}\]
  y el producto entre elementos de $RâŸ¨XâŸ©$ definido como
  \[ (âˆ‘_{i = 1}^n c_i m_i) Â· (âˆ‘_{i = 1}^m c'_i m'_i) = âˆ‘_{i = 1}^n âˆ‘_{j = 1}^m c_i c'_j m_i m'_j \text{.}\]

  A los elementos de $RâŸ¨XâŸ©$ se los llama polinomios no conmutativos. Cuando tengamos una lista de variables $x_1, â€¦, x_n$ escribimos $RâŸ¨x_1, â€¦, x_nâŸ©$ en lugar de $RâŸ¨\{x_1, â€¦, x_n\}âŸ©$.
\end{definition}

Algunos ejemplos de polinomios no conmutativos en $â„šâŸ¨a, b, câŸ©$ son los siguientes:
\begin{align*}
  f_0 &= a \text{,} \\
  f_1 &= ab + cb \text{,} \\
  f_2 &= 3 abb + 4 bcca - 2 acab \text{.}
\end{align*}

\noindent Notar que $f_1 â‰  ab + bc$ ya que el producto es no conmutativo.

Sobre los polinomios no conmutativos se hacen las siguientes definiciones.

\begin{definition}\label{def:cosas de polinomios}
  Sean $R$ un anillo conmutativo, $f âˆˆ RâŸ¨XâŸ©$, $c_1, â€¦, c_n âˆˆ R - \{0\}$, $m_1, â€¦, m_n, m âˆˆ âŸ¨XâŸ©$, $f = âˆ‘_{i = 1}^n c_i m_i$ y $â‰¤$ un buen orden monomial. Se definen:
  \begin{itemize}
    \item el coeficiente de $m$ en $f$ es $f_m = \begin{cases} c_0&\text{si }m = m_0 \\ â‹® & \\ c_n&\text{si }m = m_n \\ 0&\text{en otro caso} \end{cases} $.
    \item el soporte de $f$ es el conjunto $\sop(f) = \{m_1, â€¦, m_n\}$.
    \item el monomio principal de $f$ es $\lm_â‰¤(f) = \max_â‰¤(\sop(f))$.
    \item el coeficiente principal de $f$ es $\lc_â‰¤(f) = f_{\lm(f)}$.
    \item el tÃ©rmino principal de $f$ es $\lt_â‰¤(f) = \lc_â‰¤(f) Â· \lm_â‰¤(f)$.
    \item $\tail_â‰¤(f) = f - \lt_â‰¤(f)$.
    \item $f$ es mÃ³nico $â‡” \lc_â‰¤(f) = 1$.
  \end{itemize}

  Los nombres lm, lc, lt y tail vienen del inglÃ©s leading monomial, leading coefficient, leading term y tail respectivamente.
\end{definition}

Sobre estas definiciones valen muchas propiedades fÃ¡ciles de probar, como por ejemplo $\lm(f) \lm(f') = \lm(f f')$, que durante el resto de la tesis vamos a usar mucho, pero no las vamos a probar una por una porque serÃ­a tedioso y aburrido.

Mas adelante va a ser necesario comparar no solo monomios sino tambiÃ©n polinomios, asÃ­ que el orden $â‰¤$ se extiende a $KâŸ¨XâŸ©$ asÃ­:

\begin{definition}
  Sean $f, g âˆˆ KâŸ¨XâŸ©$. Se define que $f < g$ si y solo si vale alguna de las siguientes:
  \begin{enumerate}
    \item $f = 0 âˆ§ g â‰  0$.
    \item $\lm_â‰¤(f) < \lm_â‰¤(g)$.
    \item $\lm(f) = \lm(g) âˆ§ \tail(f) < \tail(g)$.
  \end{enumerate}
  Y como es usual definimos $f â‰¤ g$ si y solo si $f < g âˆ¨ f = g$.
\end{definition}

Dicho en palabras, el orden en los polinomios es orden lexicogrÃ¡fico con el polinomio visto como una lista de monomios, sin coeficientes, ordenada de mayor a menor. Por ejemplo, tenemos estas desigualdades en $KâŸ¨XâŸ©$:
\begin{align*}
  a &< ab \text{,} \\
  bcc + c &< bcc + abb \text{,} \\
  ac &< ac + aa \text{.}
\end{align*}

Si bien a este $<$ lo estamos llamando (y lo vamos a seguir llamando) orden, en realidad no es un orden sino un preorden porque cuando solo cambian los coeficientes entre un polinomio y otro, ninguno de los polinomios es menor que el otro.

\begin{theorem}
  La relaciÃ³n $<$ en $KâŸ¨XâŸ©$ es un preorden parcial.
  \qed
\end{theorem}

AdemÃ¡s, el polinomio $0$ es el mÃ­nimo.

\begin{lemma}\label{lemma:0 es mÃ­nimo}
  $0$ es el mÃ­nimo de $<$.
  \qed
\end{lemma}

En este orden, al igual que para los monomios, vale que no hay sucesiones estrictamente decrecientes infinitas.

\begin{lemma}\label{lemma:â‰¤ en KX no sucesiones dec inf}
  La relaciÃ³n $â‰¤$ en $KâŸ¨XâŸ©$ no tiene sucesiones estrictamente decrecientes infinitas.
\end{lemma}
\begin{proof}
  Supongamos que existen sucesiones estrictamente decrecientes infinitas. Tomemos una sucesiÃ³n estrictamente decreciente infinita $P$, o sea que valga $P_1 > P_2 > P_3 > â€¦$, que minimice $\lm(P_1)$. Tomar este mÃ­nimo es posible por el \cref{thm:â‰¤ no sucesiones dec inf} que dice que no hay sucesiones estrictamente decrecientes infinitas en los monomios.

  Notemos que:

  \begin{fact}\label{fact:â‰¤ en KX no sucesiones dec inf:1}
    $âˆ€i âˆˆ â„• : \lm(P_i) = \lm(P_1)$.
  \end{fact}
  En efecto, no puede ser $\lm(P_i) < \lm(P_1)$ porque entonces $P_i, P_{i + 1}, â€¦$ serÃ­a una sucesiÃ³n estrictamente decreciente infinita que romperÃ­a la minimalidad de $\lm(P_1)$ y no puede ser $\lm(P_i) > \lm(P_1)$ porque eso implicarÃ­a $P_i > P_1$ y eso contradice que $P$ sea decreciente.

  \begin{fact}\label{fact:â‰¤ en KX no sucesiones dec inf:2}
    $\tail(P_1), \tail(P_2), â€¦$ es una sucesiÃ³n estrictamente decreciente infinita.
  \end{fact}
  Esto vale porque al aplicar la definiciÃ³n del orden polinomial sobre $P_1 > P_2 > P_3 > â€¦$ y usar la \cref{fact:â‰¤ en KX no sucesiones dec inf:1} queda $\tail(P_1) > \tail(P_2) > \tail(P_3) > â€¦$

  Como por el \cref{lemma:0 es mÃ­nimo} $0$ es un mÃ­nimo:

  \begin{fact}\label{fact:â‰¤ en KX no sucesiones dec inf:3}
    $P_1 â‰  0$.
  \end{fact}

  Sin embargo, la \cref{fact:â‰¤ en KX no sucesiones dec inf:2} contradice la minimalidad de $\lm(P_1)$ ya que por la \cref{fact:â‰¤ en KX no sucesiones dec inf:3} vale que $\lm(\tail(P_1)) < \lm(P_1)$.

\end{proof}

La estructura del Ã¡lgebra libre es un anillo, lo cual nos va a ser muy Ãºtil por muchas definiciones y teoremas que ya existen sobre los anillos.

\begin{theorem}
  Sea $R$ un anillo conmutativo. Entonces
  \[ (RâŸ¨XâŸ©, +, Â·)\text{ es un anillo} \text{.}\]
  \qed
\end{theorem}
% TendrÃ­a que decir algo de que no se incluye la demostraciÃ³n porque es fÃ¡cil?

Las definiciones y teoremas sobre anillos que vamos a usar las recordaremos a continuaciÃ³n para no tener que estar buscÃ¡ndolos en otro lado.

\begin{definition}\label{def:ideal}
  Sean $R$ un anillo e $I âŠ† R$. Se define que $I$ es un ideal de $R$ si y solo si:
  \begin{enumerate}
    \item $I â‰  âˆ…$.
    \item $âˆ€a, b âˆˆ I : a + b âˆˆ I$.
    \item $âˆ€a âˆˆ I, r, r' âˆˆ R : r a r' âˆˆ I$.
  \end{enumerate}
\end{definition}

Los ideales son bÃ¡sicamente conjuntos cerrados por la suma y por el producto por cualquier elemento del anillo. Si se tiene un conjunto que no es un ideal se puede agregar todo lo mÃ­nimo necesario para convertirlo en un ideal. La siguiente definiciÃ³n define eso y el siguiente teorema dice que efectivamente se obtiene un ideal.

\begin{definition}\label{def:ideal gen}
  Sean $R$ un anillo y $G âŠ† R$. Se define el ideal generado por $G$, denotado $(G)$, como
  \[ (G) = \{âˆ‘_{i = 1}^n c_i g_i c_i' : n âˆˆ â„• âˆª \{0\}, g_1, â€¦, g_n âˆˆ G, c_1, â€¦, c_n, c_1', â€¦, c_n' âˆˆ R\} \text{.}\]
  A los $c_i, c'_i$ se los llama cofactores. % Â¿EstÃ¡ bien poner esto asÃ­?
\end{definition}

\begin{theorem}
  Sean $R$ un anillo y $G âŠ† R$. Entonces
  \[ (G)\text{ es un ideal de }R \text{.}\]
  \qed
\end{theorem}

Sobre los ideales generados por un conjunto valen los siguientes dos lemas bÃ¡sicos.

\begin{lemma}\label{lemma:gen G = gen G U a con a âˆˆ gen G}
  Sean $R$ un anillo, $G âŠ† R$ y $a âˆˆ (G)$. Entonces
  \[ (G) = (G âˆª \{a\}) \text{.}\]
  \qed
\end{lemma}

\begin{lemma}\label{lemma:sub gen y sub gen â‡’ eq}
  Sean $R$ un anillo y $G, G' âŠ† R$. Entonces
  \[ G âŠ† (G') âˆ§ G' âŠ† (G) â‡’ (G) = (G') \text{.}\]
  \qed
\end{lemma}


Cada ideal define una clase de equivalencia en el anillo, la cual se llama congruencia mÃ³dulo el ideal.

\begin{definition}\label{def:congruencia mod ideal}
  Sean $R$ un anillo e $I âŠ† R$. Se define la relaciÃ³n $â‰¡_I$ en $R$ asÃ­:
  \[ a â‰¡_I b â‡” a - b âˆˆ I \text{.}\]
\end{definition}

\begin{theorem}\label{thm:congruencia mod ideal es equivalencia}
  Sean $R$ un anillo e $I âŠ† R$ un ideal. Entonces
  \[ â‰¡_I \text{es una relaciÃ³n de equivalencia} \text{.}\]
  \qed
\end{theorem}

Esta congruencia es parecida a la de los enteros mÃ³dulo un natural (de hecho, la congruencia de los enteros mÃ³dulo un natural es un subcaso de esta tomando como ideal a todos los mÃºltiplos del mÃ³dulo). Vale que la clase de equivalencia del $0$ es el propio ideal:

\begin{lemma}\label{lemma:en ideal â‡” congruente 0}
  Sean $R$ un anillo, $I âŠ† R$ un ideal y $a âˆˆ R$. Entonces
  \[ a âˆˆ I â‡” a â‰¡_I 0 \text{.}\]
  \qed
\end{lemma}

Ahora volvemos al Ã¡lgebra libre y a partir de ahora fijamos un cuerpo $K$.

\begin{observation}
  Con las definiciones que tenemos ahora el \cref{problem:principal} se puede escribir como: dado un conjunto finito $G âŠ† KâŸ¨XâŸ©$ y un elemento $f âˆˆ KâŸ¨XâŸ©$, determinar si $f âˆˆ (G)$.
\end{observation}

Si bien $(G)$ para un anillo general estÃ¡ definido usando combinaciones lineales con coeficientes en el anillo, para el Ã¡lgebra libre va a ser Ãºtil la siguiente equivalencia que dice que alcanza con considerar solo monomios y elementos del cuerpo como cofactores.

\begin{lemma}\label{lemma:(G) equiv}
  Sea $G âŠ† KâŸ¨XâŸ©$. Entonces
  \[ (G) = \{âˆ‘_{i = 0}^n c_i m_i g_i m'_i : n âˆˆ â„• âˆª \{0\}, c_1, â€¦, c_n âˆˆ K, m_1, â€¦, m_n, m'_1, â€¦, m'_n âˆˆ âŸ¨XâŸ©, g_1,â€ˆâ€¦, g_n âˆˆ G\} \text{.}\]
\end{lemma}
\begin{proof} Probemos que $f$ esta en uno si y solo si estÃ¡ en el otro.
  \begin{description}
    \item[Ida ($â‡’$):] Supongamos $f âˆˆ (G)$. Sean:

    \begin{itemize}
      \item $g_1, â€¦, g_n âˆˆ G, f_1, â€¦, f_n, f'_1, â€¦, f'_n âˆˆ KâŸ¨XâŸ©$ tales que $f = âˆ‘_{i = 1}^n f_i g_i f'_i$, los cuales existen por que estamos suponiendo $f âˆˆ (G)$ y por la definiciÃ³n de $(G)$.
      \item Para cada $i âˆˆ\{1, â€¦, n\}$:
      \begin{itemize}
        \item $c_{i, 1}, â€¦, c_{i, n_i} âˆˆ K, m_{i, 1}, â€¦, m_{i, n_i} âˆˆ âŸ¨XâŸ©$ tales que $f_i = âˆ‘_{j = 1}^{n_i} c_{i, j} m_{i, j}$.
        \item $c'_{i, 1}, â€¦, c'_{i, n'_i} âˆˆ K, m'_{i, 1}, â€¦, m'_{i, n'_i} âˆˆ âŸ¨XâŸ©$ tales que $f'_i = âˆ‘_{j = 1}^{n'_i} c'_{i, j} m'_{i, j}$.
      \end{itemize}
    \end{itemize}

    Con esto tenemos:
    \begin{DispWithArrows*}
      f &= âˆ‘_{i = 1}^n f_i g_i f'_i \\
        &= âˆ‘_{i = 1}^n (âˆ‘_{j = 1}^{n_i} c_{i, j} m_{i, j}) g_i (âˆ‘_{j = 1}^{n'_i} c'_{i, j} m'_{i, j}) \\
        &= âˆ‘_{i = 1}^n âˆ‘_{j = 1}^{n_i} âˆ‘_{j' = 1}^{n'_i} c_{i, j} c'_{i, j'} m_{i, j} g_i m'_{i, j'} \text{.}
    \end{DispWithArrows*}

    Esto Ãºltimo es una expresiÃ³n que se transforma a la forma que queremos. % Â¿EstÃ¡ bien esto?

    \item[Vuelta ($â‡$):] La vuelta es cierta porque, como $c_i m_i, m'_i âˆˆ KâŸ¨XâŸ©$, es un caso particular de la definiciÃ³n.
  \end{description}
\end{proof}

\section{ReducciÃ³n de polinomios}

Ahora definiremos una relaciÃ³n de reducciÃ³n en los polinomios no conmutativos la cual depende del orden monomial y de un conjunto generador $G$, cuya clausura reflexo-transitiva es igual a $â‰¡_{(G)}$. La relaciÃ³n siempre va a ser terminante, pero no siempre confluente (cuando no sea confluente vamos a tratar de hacerla confluente). Para los casos en los que si sea confluente la \cref{obs:â†’ confluente y terminante} nos va a permitir chequear si dos polinomios son equivalentes y en particular, por el \cref{lemma:en ideal â‡” congruente 0}, si un polinomio estÃ¡ en $(G)$.

\begin{definition}\label{def:reducciones}
  Sean $G âŠ† KâŸ¨XâŸ©$ y $f, f' âˆˆ KâŸ¨XâŸ©$. Se define la relaciÃ³n $â†’_{â‰¤, G}$ del siguiente modo:
  \[ f â†’_{â‰¤, G} f' â‡” âˆƒa, b âˆˆ âŸ¨XâŸ©, g âˆˆ G : \lm_â‰¤(agb) âˆˆ \sop(f) âˆ§ f' = f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb \text{.} \]
  Cuando vale $f â†’_{â‰¤, G}f'$ se dice que $f$ se reduce a $f'$ (via $G$).
\end{definition}

Por ejemplo, si tenemos $f = 2 cba + 3 dbcda$, $g_0 = a - bcd$ y $G = \{g_0\}$ tenemos:

\[f â†’_{â‰¤, G} f + 3d g_0 a = 3 daa + 2 cba \text{.}\]

\

Como tenÃ­amos la \cref{def:operaciones relaciones} y la \cref{def:forma normal} quedan definidas automÃ¡ticamente las relaciones $â†’^*_{â‰¤, G}$, $â†”^*_{â‰¤, G}$ y $â†“_{â‰¤, G}$.

A continuaciÃ³n la prueba de que esta relaciÃ³n efectivamente achica.

\begin{theorem}\label{thm:â†’ achican}
  Sean $G âŠ† KâŸ¨XâŸ©$ y $f, f' âˆˆ KâŸ¨XâŸ©$. Entonces
  \[ f â†’_{â‰¤, G} f' â‡’ f' < f \text{.} \]
\end{theorem}
\begin{proof}
  Supongamos el antecedente. Por definiciÃ³n de reducciones tomemos $a, b âˆˆ âŸ¨XâŸ©, g âˆˆ G$ tales que:
  \begin{enumerate}[label=(\roman*)]
    \item $\lm_â‰¤(agb) âˆˆ \sop(f)$.
    \item $f' = f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb$.
  \end{enumerate}

  Sean:
  \begin{itemize}
    \item $c_1, â€¦, c_n âˆˆ K, m_1, â€¦, m_n âˆˆ âŸ¨XâŸ©$ con $m_1 > m_2 > â‹¯ > m_n$ tales que $f = âˆ‘_{i = 1}^n c_i m_i$.
    \item $i$ tal que $m_i = \lm_â‰¤(agb)$, el cual existe por (i).
  \end{itemize}

  Notar tambiÃ©n que:

  \begin{enumerate}[label=(\roman*)]
    \setcounter{enumi}{2}
    \item $m_i = \lm_â‰¤(\frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb)$.
  \end{enumerate}

  (iii) implica que los tÃ©rminos $c_1 m_1, c_2 m_2, â€¦, c_{i-1}, m_{i-1}$ son iguales en $f$ y en $f'$ y no hay nada mÃ¡s en el medio, porque $f'$ es $f$ con tÃ©rminos menores o iguales a $\lm_â‰¤(\frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb)$ restadas (por (ii)).

  AdemÃ¡s, por (iii) y (ii) vale que $f'_{m_i} = 0$, por ende, el tÃ©rmino que sigue despuÃ©s de $m_{i-1}$ (si es que hay) es menor que $m_i$.

  Combinando que los primeros $i - 1$ tÃ©rminos son iguales y el $i$ es menor en $f'$ que en $f$, por la definiciÃ³n de $<$ para polinomios vale que $f' < f$.

\end{proof}

La relaciÃ³n $â†’_{â‰¤, G}$ tiene varias propiedades Ãºtiles que se prueban a continuaciÃ³n.

\begin{lemma}\label{lemma:suma â†’â†“}
  Sean $G âŠ† KâŸ¨XâŸ©$ y $f_0, f_1, f âˆˆ KâŸ¨XâŸ©$. Entonces
  \[ f_0 â†’_{â‰¤, G} f_1 â‡’ f_0 + f â†“_{â‰¤, G} f_1 + f \text{.}\]
\end{lemma}
\begin{proof}
  Supongamos el antecedente $f_0 â†’_{â‰¤, G} f_1$.

  Sean $g âˆˆ G, a, b âˆˆ KâŸ¨XâŸ©$ tales que $f_1 = f_0 - \frac{{f_0}_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb $, los cuales existen por definiciÃ³n de $â†’_{â‰¤, G}$.

  Dividamos la demostraciÃ³n en casos segÃºn la pertenencia de $\lm_â‰¤(agb)$ a $\sop(f)$:

  \begin{description}
    \item[Caso $\lm_â‰¤(agb) âˆ‰ \sop(f)$:] Partiendo de la condiciÃ³n de $a, g, b$ hacemos lo siguiente:
    \begin{DispWithArrows*}
      &f_1 = f_0 - \frac{{f_0}_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} \\
      & â‡’ f_1 + f = f_0 - \frac{{f_0}_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} + f \Arrow{DefiniciÃ³n de $â†’_{â‰¤, a, g, b}$}\\
      & â‡’ f_0 + f â†’_{â‰¤, a, g, b} f_1 + f \\
      & â‡’ f_0 + f â†’_{â‰¤, G} f_1 + f \Arrow{DefiniciÃ³n de $â†“$, ambos se reducen a $f_1 + f$}\\
      & â‡’ f_0 + f â†“_{â‰¤, G} f_1 + f \text{.}
    \end{DispWithArrows*}

    \item[Caso $\lm_â‰¤(agb) âˆˆ \sop(f)$:]\
    \begin{description}
      \item[Subcaso $f_{\lm_â‰¤(agb)} = -{f_0}_{\lm_â‰¤(agb)}$]

      En este caso $\lm_â‰¤(agb)$ se cancela en la suma $f_0 + f$. Y como ademÃ¡s $\lm_â‰¤(agb) âˆ‰ \sop(f_1)$ por el antecedente, tenemos:
      \begin{DispWithArrows*}
        &f_1 + f â†’_{â‰¤, G} f_1 + f - \frac{f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \Arrow{Subcaso} \\
        & â‡’ f_1 + f â†’_{â‰¤, G} f_1 + f + \frac{{f_0}_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \Arrow{CondiciÃ³n de $g$, $a$ y $b$} \\
        & â‡’ f_1 + f â†’_{â‰¤, G} f_0 + f \\
        & â‡’ f_1 + f â†“_{â‰¤, G} f_0 + f \text{.}
      \end{DispWithArrows*}

      \item[Subcaso $f_{\lm_â‰¤(agb)} â‰  -{f_0}_{\lm_â‰¤(agb)}$:] En este caso $\lm_â‰¤(agb)$ no se cancela en la suma $f_0 + f$, asÃ­ que podemos aplicar $â†’_{â‰¤, G}$:
      \begin{DispWithArrows*}
        &f_0 + f â†’_{â‰¤, G} f_0 + f - \frac{(f_0 + f)_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \\
        & â‡’ f_0 + f â†’_{â‰¤, G} f_0 + f - \frac{{f_0}_{\lm_â‰¤(agb)} + f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \\
        & â‡’ f_0 + f â†’_{â‰¤, G} f_0 + f - \frac{{f_0}_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb - \frac{f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \Arrow{CondiciÃ³n de $g$, $a$ y $b$}\\
        & â‡’ f_0 + f â†’_{â‰¤, G} f_1 + f - \frac{f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb  \text{.}
      \end{DispWithArrows*}
      Â Â Llamemos (i) a este Ãºltimo resultado.

      AdemÃ¡s por el caso y el hecho de que $lm_â‰¤(agb) âˆ‰ \sop(f_1)$ tambiÃ©n tenemos $\lm_â‰¤(agb) âˆˆ \sop(f_1 + f)$, entonces:
      \begin{DispWithArrows*}
        &f_1 + f â†’_{â‰¤, G} f_1 + f - \frac{(f_1 + f)_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \\
        & â‡’ f_1 + f â†’_{â‰¤, G} f_1 + f - \frac{{f_1}_{\lm_â‰¤(agb)} + f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \Arrow{$\lm_â‰¤(agb) âˆ‰ \sop(f_1)$ porque $f_0 â†’_{â‰¤, G} f_1$ y definiciÃ³n de $â†’_{â‰¤, G}$}\\
        & â‡’ f_1 + f â†’_{â‰¤, G} f_1 + f - \frac{0 + f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \\
        & â‡’ f_1 + f â†’_{â‰¤, G} f_1 + f - \frac{f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \text{.}
      \end{DispWithArrows*}
      Â Â Llamemos (ii) a este Ãºltimo resultado.

      Por (i) e (ii) tenemos $f_0 + f â†“_{â‰¤, G} f_0' + f$.
    \end{description}
  \end{description}
\end{proof}

\begin{lemma}\label{lemma:prod mon â†’}
  Sean $G âŠ† KâŸ¨XâŸ©$, $f, f' âˆˆ KâŸ¨XâŸ©$, $c âˆˆ K$ y $m, m' âˆˆ âŸ¨XâŸ©$. Entonces
  \[ f â†’_{â‰¤, G} f' â‡’ c m f m' â†’_{â‰¤, G} c m f' m' \text{.}\]
\end{lemma}
\begin{proof} Supongamos el antecedente.

  Sean $g âˆˆ G$ y $a, b âˆˆ âŸ¨XâŸ©$ tales que $f' = f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb$, los cuales existen por definiciÃ³n de $â†’_{â‰¤, G}$. Tenemos:
  \begin{DispWithArrows*}
    &f' = f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb \\
    & â‡’ c m f' m' = c m (f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb) m \\
    & â‡’ c m f' m' = c m f m' - \frac{{(c m f m')}_{\lm_â‰¤(c ma g bm')}}{\lc_â‰¤(g)}c ma g bm'  \Arrow{DefiniciÃ³n $â†’_{â‰¤, G}$} \\
    & â‡’ c m f' m' â†’_{â‰¤, G} c m f m' \text{.}
  \end{DispWithArrows*}

\end{proof}

Ahora el ya anunciado teorema de que la clausura reflexo transitiva de $â†’_{â‰¤, G}$ es una congruencia.

\begin{theorem}\label{theorem:â†’^* = â‰¡}
  Sea $G âŠ† KâŸ¨XâŸ©$. Entonces
  \[ â†”^*_{â‰¤, G}\ =\ â‰¡_{(G)} \text{.}\]
\end{theorem}
\begin{proof} Probemos las dos inclusiones.
  \begin{description}
    \item[Prueba de $â†”^*_{â‰¤, G}\ âŠ†\ â‰¡_{(G)}$:] Como $â†”^*_{â‰¤, G}$ y $â‰¡_{(G)}$ son relaciones de equivalencia y ademÃ¡s por el \cref{lemma:â†”* min equiv que contiene a â†’} $â†”^*_{â‰¤, G}$ es la mÃ­nima relaciÃ³n de equivalencia que contiene a $â†’_{â‰¤, G}$, alcanza con probar $â†’_{â‰¤, G}\ âŠ†\ â‰¡_{(G)}$. Para eso supongamos $f â†’_{â‰¤, G} f'$ y probemos $f â‰¡_{(G)} f'$.

    Sean $g âˆˆ G, a, b âˆˆ KâŸ¨XâŸ©$ tales que $\lm(agb) âˆˆ f$ y $f' = f - \frac{f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb$, los cuales existen por definiciÃ³n de $â†’_{â‰¤, G}$. Tenemos:
    \begin{DispWithArrows*}
      &f â‰¡_{(G)} f' \\
      & â‡” f - f' âˆˆ (G) \\
      & â‡” f - (f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb) âˆˆ (G) \\
      & â‡” \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb âˆˆ (G) \text{.}
    \end{DispWithArrows*}
    Y esto Ãºltimo es claramente cierto por la definiciÃ³n de (G) (\cref{def:ideal gen}).

    \item[Prueba de $â‰¡_{(G)}\ âŠ†\ â†”^*_{â‰¤, G}$:] Supongamos $f â‰¡_{(G)} f'$ y probemos $f â†”^*_{â‰¤, G} f'$. Sean:
    \begin{itemize}
      \item $g = f - f'$.
      \item $c_1, â€¦, c_n âˆˆ K, m_1, â€¦, m_n, m_1', â€¦, m_n' âˆˆ âŸ¨XâŸ©$, $g_1, â€¦, g_n âˆˆ G$ tales que $g = âˆ‘_{i = 1}^n c_i m_i g_i m_i'$, los cuales existen porque por definiciÃ³n de $â‰¡_G$ tenemos $g âˆˆ (G)$ y por el \cref{lemma:(G) equiv}.
      \item $f_0 = f$.
      \item Para cada $i âˆˆ \{1, â€¦, n\}$: $f_i = f_{i - 1} - c_i m_i g_i m_i'$.
    \end{itemize}

    Tenemos entonces:
    \begin{DispWithArrows*}
      &âˆ€i âˆˆ \{1, â€¦, n\} : g_i â†’_{â‰¤, G} 0 \Arrow{\cref{lemma:prod mon â†’}} \\
      & â‡’ âˆ€i âˆˆ \{1, â€¦, n\} : c_i m_i g_i m_i' â†’_{â‰¤, G} 0 \Arrow{\cref{lemma:suma â†’â†“}} \\
      & â‡’ âˆ€i âˆˆ \{1, â€¦, n\} : c_i m_i g_i m_i' + f_i â†“_{â‰¤, G} 0 + f_i \Arrow{DefiniciÃ³n de los $f_i$}\\
      & â‡’ âˆ€i âˆˆ \{1, â€¦, n\} : f_{i - 1} â†“_{â‰¤, G} f_i \\
      & â‡’ âˆ€i âˆˆ \{1, â€¦, n\} : f_{i - 1} â†”^*_{â‰¤, G} f_i \\
      & â‡’ f_0 â†”^*_{â‰¤, G} f_n \Arrow{$f_n = f - g = f'$} \\
      & â‡’ f â†”^*_{â‰¤, G} f_n \text{.}
    \end{DispWithArrows*}

  \end{description}
\end{proof}

\begin{lemma}\label{thm:â†’ mantiene pertenencia a ideal}
  Sean $G âŠ† KâŸ¨XâŸ©, f, f' âˆˆ KâŸ¨XâŸ©$. Entonces
  \[ f â†’^*_{â‰¤, G} f' â‡’ (f âˆˆ (G) â‡” f' âˆˆ (G)) \text{.}\]
\end{lemma}
\begin{proof}
  Si asumimos $f â†’^*_{â‰¤, G} f'$, tenemos por el \cref{theorem:â†’^* = â‰¡} que $f â‰¡_{(G)} f'$ y entonces por el \cref{lemma:en ideal â‡” congruente 0} vale que $f âˆˆ (G) â‡” f' âˆˆ (G)$.
\end{proof}

\begin{theorem}
  Sea $G âŠ† KâŸ¨XâŸ©$. Entonces
  \[ â†’_{â‰¤, G} \text{ es terminante.} \]
\end{theorem}
\begin{proof}
  Lo vamos a demostrar por contradicciÃ³n. Supongamos que $â†’_{â‰¤, G}$ no es terminante. Por definiciÃ³n podemos tomar una sucesiÃ³n $P âˆˆ KâŸ¨XâŸ©^â„•$ tal que:

  \[ âˆ€i âˆˆ â„• : P_i â†’_{â‰¤, G} P_{i+1}. \]

  \noindent Por el \cref{thm:â†’ achican} tenemos que:

  \[ âˆ€i âˆˆ â„• : P_i > P_{i+1}. \]

  \noindent Pero esto contradice el \cref{lemma:â‰¤ en KX no sucesiones dec inf} que dice que no hay sucesiones estrictamente decrecientes infinitas en $KâŸ¨XâŸ©$.
\end{proof}

El siguiente teorema caracteriza las formas normales de $â†’$.

\begin{theorem}
  Sean $G âŠ† KâŸ¨XâŸ©, f âˆˆ KâŸ¨XâŸ©$. Entonces
  \[ f\text{ estÃ¡ en forma normal con respecto a} â†’_{â‰¤, G} â‡” âˆ„g âˆˆ G, m âˆˆ \sop(f) : \lm(g) | m \text{.}\]
\end{theorem}
\begin{proof} Probemos ida y vuelta por separado
  \begin{description}
    \item[Ida ($â‡’$):] por contradicciÃ³n, supongamos el antecedente y que tenemos $g âˆˆ G, m âˆˆ \sop(f)$ tales que $\lm(g) | m$.

    \noindent Sean $a, b âˆˆ âŸ¨XâŸ©$ tales que $m = agb$, los cuales existen por la definiciÃ³n de divisibilidad.

    \noindent Entonces tenemos $f â†’_{â‰¤, G} f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb$ y por ende $f$ no estÃ¡ en forma normal.

    \item[Vuelta ($â‡$):] por contrareciproca, supongamos que $f$ no estÃ¡ en forma normal con respecto a $â†’_{â‰¤, G}$ y probemos existe $g$ que satisface el $âˆƒ$. Sean:
    \begin{itemize}
      \item $f' âˆˆ KâŸ¨XâŸ©$ tal que $f â†’_{â‰¤, G} f'$, el cual existe por el antecedente.
      \item $a, b âˆˆ âŸ¨XâŸ©, g âˆˆ G$ tales que $\lm(agb) âˆˆ \sop(f)$ y $f' = f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb$, los cuales existen por la definiciÃ³n de $â†’_{â‰¤, G}$.
    \end{itemize}

    Con esto es claro que $g$ satisface el $âˆƒ$.
  \end{description}
\end{proof}

Probamos que $â†’_{â‰¤, G}$ es terminante, pero no que sea confluente, ya que no siempre lo es. Por ejemplo, siguiendo con el mismo ejemplo de antes en el que ya tenÃ­amos $f = 2 cba + 3 dbcda$, $g_0 = a - bcd$, si ahora agregamos $g_1 = b - cda$ y $G = \{g_0, g_1\}$ tenemos, como antes:

\[f â†’_{â‰¤, G} f + 3d g_0 a = 3 daa + 2 cba = f' \text{.}\]

\noindent Y tambiÃ©n:

\[f â†’_{â‰¤, G} f - 3db g_1 = 3 dbb + 2 cba = f'' \text{.}\]

\noindent Pero ninguno monomio principal de $G$ divide a ninguno monomio de $f'$ o $f''$ asÃ­ que $f'$ y $f''$ no se pueden reducir mÃ¡s.

Como en algunos casos $â†’_{â‰¤, G}$ no es confluente, la siguiente definiciÃ³n nos permite hablar mÃ¡s cÃ³modamente de una forma normal de un elemento (tanto en las definiciones y teoremas como en los algoritmos).

\begin{definition}\label{def:reductor}
  Sea $e_â‰¤ : ğ’«(KâŸ¨XâŸ©) â†’ KâŸ¨XâŸ© â†’ KâŸ¨XâŸ©$. Se define que
  \[ e_â‰¤\text{ es un reductor }â‡” âˆ€G âŠ† KâŸ¨XâŸ©, f âˆˆ KâŸ¨XâŸ© : e_â‰¤(G)(f)\text{ es forma normal de }f\text{ con respecto a }â†’_{â‰¤, G} \text{.} \]
\end{definition}

Un ejemplo de reductor podrÃ­a calcularse con el siguiente seudocÃ³digo.

\begin{algorithm}[H] % La H es para que se quede acÃ¡, porque se iba a otra pÃ¡gina. EstarÃ­a bueno hacerlo global
  \caption{Ejemplo de reductor}\label{alg:reductor}
  \KwData{$G = \{g_1, â€¦, g_n\} âŠ† KâŸ¨XâŸ©, f âˆˆ KâŸ¨XâŸ©$}
  \KwResult{$f' âˆˆ KâŸ¨XâŸ©$}
  $f' â† f$

  $i â† 1$

  \While{$i â‰¤ n$} {
    \While{$i â‰¤ n$} {
      \If{$g_i âˆˆ \sop(f')$} {
        $f' â† f' - \frac{f'_{\lm(g_i)}}{\lc(g_i)}g_i$

        $i â† 1$

        \Break
      }
      \Else{
        $i â† i + 1$
      }
    }
  }
  \Return{$f'$}
\end{algorithm}

Este algoritmo consiste bÃ¡sicamente en siempre buscar entre los elementos de $G$ si hay alguno con el cual reducir, y parar cuando ya no hay ninguno.

Una propiedad sobre los reductores que vamos a necesitar es que mantienen la pertenencia a ideales (lo cual tiene mucho sentido por la definiciÃ³n).

\begin{lemma}\label{lemma:e mantiene pertenencia a ideal}
  Sean $e_â‰¤$ un reductor, $G âŠ† KâŸ¨XâŸ©$ y $f âˆˆ (G)$. Entonces
  \[ e_â‰¤(G)(f) âˆˆ (G) \text{.}\]
\end{lemma}
\begin{proof}
  Es consecuencia directa de la definiciÃ³n y del \cref{thm:â†’ mantiene pertenencia a ideal}.
\end{proof}

\section{Bases de GrÃ¶bner}

Que $â†’_{â‰¤, G}$ fuera confluente siempre serÃ­a muy Ãºtil porque significarÃ­a que para cualquier clase de equivalencia de $â‰¡_{(G)}$ podrÃ­amos siempre llegar a una misma forma normal y asÃ­ determinar si dos elementos son equivalentes. En particular podrÃ­amos determinar si un elemento estÃ¡ en el ideal viendo si se llega a $0$ como la forma normal. Los casos en los que sÃ­ es confluente se llaman bases de GrÃ¶bner y despuÃ©s algo que vamos a hacer es calcular una base de GrÃ¶bner de un ideal generado por un conjunto que no es base de GrÃ¶bner.

\begin{definition}\label{def:base de GrÃ¶bner}
  Sean $I$ un ideal de $KâŸ¨XâŸ©$ y $G âŠ† KâŸ¨XâŸ©$. Se define que
  \[G\text{ es una base de GrÃ¶bner de }I â‡” (G) = IÂ âˆ§ â†’_{â‰¤, G}\text{ es confluente} \text{.} \]
  AdemÃ¡s se dice que ``$G$ es una base de GrÃ¶bner'' si lo es de algÃºn ideal.
\end{definition}

Una consecuencia directa de la definiciÃ³n es el siguiente lema.

\begin{lemma}\label{lemma:â†’ grÃ¶bner es Church-Rosser}
  Sea $G$ una base de GrÃ¶bner. Entonces
  \[â†’_{â‰¤, G}\text{ es Church-Rosser.}\]
\end{lemma}
\begin{proof}
  Es una aplicaciÃ³n directa del \cref{thm:confluente â‡” Church-Rosser}.
\end{proof}

Las bases de GrÃ¶bner se definieron por la propiedad mÃ¡s importante que queremos que tengan, pero van a ser mucho mÃ¡s cÃ³modas de trabajar usando las siguientes equivalencias.

\begin{theorem}\label{thm:equivalencias de base de GrÃ¶bner}
  Sean $I$ un ideal de $KâŸ¨XâŸ©$ y $G âŠ† KâŸ¨XâŸ©$. Las siguientes afirmaciones son equivalentes:
  \begin{enumerate}
    \item $G$ es una base de GrÃ¶bner de $I$.

    \item $âˆ€f âˆˆ KâŸ¨XâŸ© : f âˆˆ I â‡” f â†’^*_{â‰¤, G} 0$.

    \item $(G) = I âˆ§ âˆ€f âˆˆ KâŸ¨XâŸ© : f âˆˆ I â‡’ f â†’^*_{â‰¤, G} 0$.

    \item $(G) = I âˆ§ âˆ€f âˆˆ I - \{0\} : âˆƒg âˆˆ G : \lm(g) | \lm(f)$.

    \item $âˆ€f âˆˆ I - \{0\} : âˆƒc_1, â€¦, c_n âˆˆ K g_1, â€¦, g_n âˆˆ G, a_1, â€¦, a_n, b_1, â€¦, b_n âˆˆ âŸ¨XâŸ© : \lm(a_i g_i b_i) â‰¤ \lm(f) âˆ§ f = âˆ‘_{i = 1}^n c_i a_i g_i b_i$.
  \end{enumerate}
\end{theorem}
\begin{proof} Vamos a probar (1) $â‡’$ (2), (2) $â‡’$ (3), (3) $â‡’$ (1), (3) $â‡’$ (2), (4) $â‡’$ (3), (2) $â‡’$ (5) y (5) $â‡’$ (4).
  \begin{description}

    \item[(1) $â‡’$ (2):] Supongamos que $G$ es una base de GrÃ¶bner de $I$ y tomemos $f âˆˆ KâŸ¨XâŸ©$. Tenemos que probar $f âˆˆ I â‡” f â†’^*_{â‰¤, G} 0$. Vamos de un lado para el otro:
    \begin{DispWithArrows*}
      &f âˆˆ I \Arrow{\cref{lemma:en ideal â‡” congruente 0}} \\
      & â‡” f â‰¡_I 0 \Arrow{\cref{theorem:â†’^* = â‰¡}} \\
      & â‡” f â†”^*_{â‰¤, G} 0 \Arrow{Por el \cref{lemma:â†’ grÃ¶bner es Church-Rosser}, $â†’_{â‰¤, G}$ es Church-Rosser, definiciÃ³n de Church-Rosser} \\
      & â‡” f â†“_{â‰¤, G} 0 \Arrow{DefiniciÃ³n de $â†“$} \\
      & â‡” âˆƒf' âˆˆ KâŸ¨XâŸ© : f â†’^*_{â‰¤, G} f' âˆ§ 0 â†’^*_{â‰¤, G} f' \Arrow{\cref{thm:â†’ achican}} \\
      & â‡” âˆƒf' âˆˆ KâŸ¨XâŸ© : f â†’^*_{â‰¤, G} f' âˆ§ f' â‰¤ 0 \Arrow{\cref{lemma:0 es mÃ­nimo}} \\
      & â‡” âˆƒf' âˆˆ KâŸ¨XâŸ© : f â†’^*_{â‰¤, G} f' âˆ§ f' = 0 \\
      & â‡” f â†’^*_{â‰¤, G} 0 \text{.}
    \end{DispWithArrows*}

    % \item[(2) $â‡’$ (1):]
    % Supongamos (2), o sea $âˆ€f âˆˆ KâŸ¨XâŸ© : f âˆˆ I â‡” f â†’^*_{â‰¤, G} 0$. Tenemos que probar que $G$ es una base de GrÃ¶bner de $I$, es decir $(G) = IÂ âˆ§ â†’_{â‰¤, G}$ es confluente.

    % Probemos cada tÃ©rmino del $âˆ§$ por separado:

    % \begin{description}
    %   \item[Prueba de $(G) = I$:] Tomemos $f âˆˆ KâŸ¨XâŸ©$ y probemos $f âˆˆ (G) â‡” f âˆˆ I$, probando ida y vuelta por separado:

    %   \begin{description}
    %     \item[Ida ($â‡’$):] Supongamos antecedente $f âˆˆ (G)$.

    %     Sean $c_1, â€¦, c_n, c_1', â€¦, c_n' âˆˆ KâŸ¨XâŸ©$, $g_1, â€¦, g_n âˆˆ G$ tales que $f = âˆ‘_{i = 1}^n c_i g_i c_i'$, los cuales existen por la definiciÃ³n de $(\ Â·\ )$.

    %     Definamos $f_0 = f$ y para $i âˆˆ \{1, â€¦, n\}$ $f_i = f_{i-1} - c_i g_i c_i'$.

    %     Notar que tenemos $âˆ€i âˆˆ \{1, â€¦, n\} : f_{i-1} â†’_{â‰¤, G} f_i$ y que $f_n = 0$.

    %     Esto significa que $f â†’^*_{â‰¤, G} 0$ y por ende por (2) vale $f âˆˆ I$.

    %     \item[Vuelta ($â‡$):] Supongamos el antecedente $f âˆˆ I$.

    %     Por (2) tenemos que $f â†’^*_{â‰¤, G} 0$.

    %     AsÃ­ que sean $f_0, f_1, â€¦, f_n âˆˆ KâŸ¨XâŸ©$ tales que $f_0 = f$, $f_n = 0$ y $âˆ€i âˆˆ \{1, â€¦, n\} : f_{i-1} â†’_{â‰¤, G} f_i$, los cuales existen por la definiciÃ³n de $^*$.

    %     AdemÃ¡s, para cada $i âˆˆ \{1, â€¦, n\}$ sean $c_i, c_i' âˆˆ KâŸ¨XâŸ©, g_i âˆˆ G$ tales que $f_i = f_{i-1} - c_i g_i c_i'$, los cuales existen por definiciÃ³n de $â†’_{â‰¤, G}$.

    %     Notar que en particular $f_{i-1} = f_i + c_i g_i c_i'$ y por ende $f = âˆ‘_{i = 1}^n c_i g_i c_i'$, lo cual prueba que $f âˆˆ (G)$.

    %   \end{description}

    %   \item[Prueba de $â†’_{â‰¤, G}\text{ es confluente}$:]\

    %   Por definiciÃ³n de confluencia alcanza que probar $âˆ€f, f_0, f_1 âˆˆ KâŸ¨XâŸ© : f â†’^*_{â‰¤, G} f_0 âˆ§ f â†’^*_{â‰¤, G} f_1 â‡’ f_0 â†“_{â‰¤, G} f_1$. En tal caso, vale por lo siguiente:

    %   \begin{DispWithArrows*}
    %     &f â†’^*_{â‰¤, G} f_0 âˆ§ f â†’^*_{â‰¤, G} f_1 \\
    %     & â‡’ f_0 â†”^*_{â‰¤, G} f_1 \Arrow{\cref{theorem:â†’^* = â‰¡}} \\
    %     & â‡’ f_0 â‰¡_{(G)} f_1 \Arrow{DefiniciÃ³n $â‰¡_{\ Â·\ }$} \\
    %     & â‡’ f_0 - f_1 âˆˆ (G) \Arrow{(6), ya probamos que $(G) = I$} \\
    %     & â‡’ f_0 - f_1 â†’^*_{â‰¤, G} 0 \Arrow{\cref{lemma:suma â†’â†“}} \\
    %     & â‡’ (f_0 - f_1) + f_1 â†“_{â‰¤, G} 0 + f_1 \\
    %     & â‡’ f_0 â†“_{â‰¤, G} f_1 \text{.}
    %   \end{DispWithArrows*}
    % \end{description}

    \item[(2) $â‡’$ (3):] Supongamos el antecedente $âˆ€f âˆˆ KâŸ¨XâŸ© : f âˆˆ I â‡” f â†’^*_{â‰¤, G} 0$. Tenemos que probar que $(G) = I âˆ§ âˆ€f âˆˆ KâŸ¨XâŸ© : f âˆˆ I â‡’ f â†’^*_{â‰¤, G} 0$. Probemos cada termino del $âˆ§$ por separado:

    \begin{description}
      \item[Prueba de $(G) = I$:] Es cierto porque (2) $â‡’$ (1) y $(G) = I$ es parte de la definiciÃ³n de base de GrÃ¶bner.
      \item[Prueba de $âˆ€f âˆˆ KâŸ¨XâŸ© : f âˆˆ I â‡’ f â†’^*_{â‰¤, G} 0$:] Es cierto por (2).
    \end{description}

    \item[(3) $â‡’$ (1):] Supongamos el antecedente $(G) = I âˆ§ âˆ€f âˆˆ KâŸ¨XâŸ© : f âˆˆ I â‡’ f â†’^*_{â‰¤, G} 0$. Tenemos que probar que $G$ es una base de GrÃ¶bner de $I$, es decir $(G) = IÂ âˆ§ â†’_{â‰¤, G}$ es confluente. La parte de $(G) = I$ es valida porque es parte de (3).

    Para la otra parte, por definiciÃ³n de confluente, alcanza con probar $âˆ€f, f_0, f_1 âˆˆ KâŸ¨XâŸ© : f â†’^*_{â‰¤, G} f_0 âˆ§ f â†’^*_{â‰¤, G} f_1 â‡’ f_0 â†“_{â‰¤, G} f_1$. En tal caso, vale por lo siguiente:
    \begin{DispWithArrows*}
      &f â†’^*_{â‰¤, G} f_0 âˆ§ f â†’^*_{â‰¤, G} f_1 \\
      & â‡’ f_0 â†”^*_{â‰¤, G} f_1 \Arrow{\cref{theorem:â†’^* = â‰¡}} \\
      & â‡’ f_0 â‰¡_{(G)} f_1 \Arrow{DefiniciÃ³n $â‰¡_{\ Â·\ }$} \\
      & â‡’ f_0 - f_1 âˆˆ (G) \Arrow{Antecedente} \\
      & â‡’ f_0 - f_1 â†’^*_{â‰¤, G} 0 \Arrow{\cref{lemma:suma â†’â†“}} \\
      & â‡’ (f_0 - f_1) + f_1 â†“_{â‰¤, G} 0 + f_1 \\
      & â‡’ f_0 â†“_{â‰¤, G} f_1 \text{.}
    \end{DispWithArrows*}

    % \item[(2) $â‡’$ (4):] Supongamos (2).

    % La parte de $(G) = I$ es valida porque (2) $â‡’$ (1) y $(G) = I$ es parte de la definiciÃ³n de base de GrÃ¶bner.

    % Para la parte de $âˆ€f âˆˆ I : âˆƒg âˆˆ G : \lm(g) | \lm(f)$ tomemos $f âˆˆ I$ y mostremos un $g$ que cumple el $âˆƒ$:

    % Por (2) tenemos $f â†’^*_{â‰¤, G} 0$, esto significa que en alguno de los pasos de el $â†’^*_{â‰¤, G}$ se tiene que reducir el monomio principal de $f$, o sea, uno de los pasos es de la forma $â†’_{â‰¤, a, g, b}$ tal que $a \lm(g) b = \lm(f)$ con $g âˆˆ G, a, b âˆˆ âŸ¨XâŸ©$, por lo tanto, tenemos que $\lm(g) | \lm(f)$.

    \item[(4) $â‡’$ (3):] Supongamos el antecedente $(G) = I âˆ§ âˆ€f âˆˆ I - \{0\} : âˆƒg âˆˆ G : \lm(g) | \lm(f)$. Tenemos que probar $(G) = I âˆ§ âˆ€f âˆˆ KâŸ¨XâŸ© : f âˆˆ I â‡’ f â†’^*_{â‰¤, G} 0$. La parte de $(G) = I$ es valida porque es parte de (4). Para la otra parte probemoslo por contradicciÃ³n. En particular tomemos el mÃ­nimo $f$ tal que $f âˆˆ I$ pero no se cumple que $f â†’^*_{â‰¤, G} 0$.

    Por (4) sea $g âˆˆ G$ tal que $\lm(g) | \lm(f)$ y sean tambiÃ©n:
    \begin{itemize}
      \item $a, b âˆˆ âŸ¨XâŸ©$ tales que $a \lm(g) b = \lm(f)$.
      \item $f' = f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb$.
    \end{itemize}

    Notar que:

    \begin{itemize}
      \item $f' âˆˆ I$ ya que $f âˆˆ I$ y $g âˆˆ (G) = I$,
      \item $f â†’_{â‰¤, G} f'$ por definiciÃ³n de $â†’_{â‰¤, G}$ y
      \item $f' < f$ por el \cref{thm:â†’ achican}.
    \end{itemize}

    \noindent Ahora como no vale $f â†’^*_{â‰¤, G} 0$, tampoco puede valer $f' â†’^*_{â‰¤, G} 0$. Sin embargo, esto contradice que $f$ sea mÃ­nimo.

    \item[(2) $â‡’$ (5):] Supongamos (2) y tomemos $f âˆˆ I - \{0\}$.

    Por (2) tenemos que $f â†’^*_{â‰¤, G} 0$.

    Sean:
    \begin{itemize}
      \item $n âˆˆ â„•, f_0, â€¦, f_n âˆˆ KâŸ¨XâŸ©$ tales que $f_0 = f$, $f_n = 0$ y $f_0 â†’_{â‰¤, G} f_1 â†’_{â‰¤, G} â€¦ â†’_{â‰¤, G} f_n$, los cuales existen porque $f â†’^*_{â‰¤, G} 0$ y por el \cref{lemma:â†’* como âˆƒ}.
      \item Para cada $i âˆˆ {1, â€¦, n}$, $g_i âˆˆ G, a_i, b_i âˆˆ X$ tales que $\lm_â‰¤(a_i g_i b_i) âˆˆ \sop(f_{i-1})$ y $f_i = f_{i-1} - \frac{(f_{i-1})_{\lm_â‰¤(a_i g_i b_i)}}{\lc_â‰¤(g_i)}a_i g_i b_i$ los cuales existen por definiciÃ³n de $â†’_{â‰¤, G}$.
    \end{itemize}

    Vamos a probar que el $âˆƒ$ de (5), se satisface de la forma $\lm(a_i g_i b_i) â‰¤ \lm(f)$ y $f = âˆ‘_{i = 1}^n \frac{(f_{i-1})_{\lm_â‰¤(a_i g_i b_i)}}{\lc_â‰¤(g_i)} a_i g_i b_i$.

    \begin{description}
      \item[Prueba de $\lm(a_i g_i b_i) â‰¤ \lm(f)$ fijando $i$:] Por el \cref{thm:â†’ achican} y por transitividad de $<$ tenemos $f_{i-1} â‰¤ f$. AdemÃ¡s tenemos $a_i g_i b_i â‰¤ f_{i-1}$ porque $\lm_â‰¤(a_i g_i b_i) âˆˆ \sop(f_{i-1})$, asÃ­ que por transitividad de $â‰¤$ vale $\lm(a_i g_i b_i) â‰¤ \lm(f)$.
      \item[Prueba de $f = âˆ‘_{i = 1}^n \frac{(f_{i-1})_{\lm_â‰¤(a_i g_i b_i)}}{\lc_â‰¤(g_i)} a_i g_i b_i$:] Es consecuencia directa de como se eligieron los $g_i, a_i, b_i$.
    \end{description}

    \item[(5) $â‡’$ (4):] Supongamos (5) y probemos (4). Para eso tenemos que probar $(G) = I$ y $âˆ€f âˆˆ I : âˆƒg âˆˆ G - \{0\} : \lm(g) | \lm(f)$.

    \begin{description}
      \item[Prueba de $(G) = I$:] Tomemos $f âˆˆ I$ y probemos $f âˆˆ (G)$.

      Por (5) tenemos que $f = âˆ‘_{i = 1}^n c_i a_i g_i b_i$ con $c_i âˆˆ K$, $a_i, b_i âˆˆ âŸ¨XâŸ©$ y $g_i âˆˆ G$.

      Esto encaja exactamente con la definiciÃ³n de $(G)$, asÃ­ que queda probado $f âˆˆ (G)$.

      \item[Prueba de $âˆ€f âˆˆ I - \{0\} : âˆƒg âˆˆ G : \lm(g) | \lm(f)$:] Fijemos $f âˆˆ I - \{0\}$.

      Por (5) tenemos que $f = âˆ‘_{i = 1}^n c_i a_i g_i b_i$ con $c_i âˆˆ K$, $a_i, b_i âˆˆ âŸ¨XâŸ©$, $g_i âˆˆ G$ y $\lm(a_i g_i b_i) â‰¤ \lm(f)$.

      Como $\lm(a_i g_i b_i) â‰¤ \lm(f)$, si o si tiene que pasar para algÃºn $j$ que $\lm(a_j g_j b_j) = \lm(f)$ y para este $g_j$ vale que $\lm(g_j) | \lm(f)$.
    \end{description}

  \end{description}
  Con esto se termina la prueba.
\end{proof}

\begin{observation}
  (2) del \cref{thm:equivalencias de base de GrÃ¶bner} nos da una manera precisa de responder al \cref{problem:principal}. Para decidir si $f$ estÃ¡ en el ideal generado por $G$, primero le calculamos una base de GrÃ¶bner al ideal y si la tiene, aplicamos el \cref{alg:reductor} con esta base y si el resultado es $0$ entonces $f$ esta en el ideal.
\end{observation}

Combinando esta observaciÃ³n con el \cref{lemma:sub gen y sub gen â‡’ eq} tenemos el siguiente corolario.

\begin{colorary}\label{col:(G) = (G') cond}
  Sean $G, G' âŠ† KâŸ¨XâŸ©$ bases de GrÃ¶bner, entonces
  \[ (G) = (G') â‡” (âˆ€g âˆˆ G : g â†’_{â‰¤, G'} 0) âˆ§ (âˆ€g' âˆˆ G' : g' â†’_{â‰¤, G} 0)\]
  \qed
\end{colorary}


\section{Algoritmo de Buchberger}

En esta secciÃ³n se explica un primer algoritmo para calcular bases de GrÃ¶bner llamado Algoritmo de Buchberger. Antes de poder calcular bases de GrÃ¶bner algo que estarÃ­a bueno hacer es poder computar si un conjunto es una Base de GrÃ¶bner, porque ninguna de las equivalencias del \cref{thm:equivalencias de base de GrÃ¶bner} es directamente calculable porque hacen cuantificaciones sobre conjuntos infinitos. Para eso vamos a definir algo llamado S-polinomio de dos polinomios y usarlos para enunciar un teorema que nos da una forma computable de determinar si un conjunto es una Base de GrÃ¶bner. Los S-polinomios entre dos polinomios multiplican cada polinomio por monomios a cada lado y por un escalar de forma que los monomios principales se cancelen. O sea, para polinomios $f$ y $g$ vamos a tener una cuenta $k a f b - k' c g d$ de forma que se cancelen los monomios principales.

Primero definimos las ambigÃ¼edades, que representan los polinomios para los cuales puede pasar eso.

\begin{definition}
  Sean $m, m', a, b, c, d âˆˆ âŸ¨XâŸ©$. Se define
  \[ (a, b, c, d, m, m')\text{ es una ambigÃ¼edad} â‡” amb = cm'd \text{.}\]

  La ambigÃ¼edad $(a, b, c, d, m, m')$ se define como:
  \begin{itemize}
    \item de superposiciÃ³n $â‡” (a = Îµ = d âˆ§ |b| < |m'| âˆ§ |c| < |m|) âˆ¨ (b = Îµ = c âˆ§ |a| < |m'| âˆ§ |d| < |m|)$.
    \item de inclusiÃ³n $â‡” a = Îµ = b âˆ¨ c = Îµ = d$.
    \item relevante $â‡”$ es de superposiciÃ³n o de inclusiÃ³n.
  \end{itemize}

  Si $f, f' âˆˆ KâŸ¨XâŸ©$ se define que $(a, b, c, d, f, f')$ es una ambigÃ¼edad si y solo si $(a, b, c, d, \lm_â‰¤{(f)}, \lm_â‰¤{(f')})$ es una ambigÃ¼edad y lo mismo para ambigÃ¼edades de superposiciÃ³n, de inclusiÃ³n y relevantes.

  AdemÃ¡s se define
  \[ \amb(f, f') = \{(a, b, c, d, f, f') : (a, b, c, d, f, f')\text{ es una ambigÃ¼edad relevante}\} \text{.} \]

  Finalmente para $F âŠ† KâŸ¨XâŸ©$ se define
  \[ \amb(F) = â‹ƒ_{f, f' âˆˆ F - \{0\}}{\amb(f, f')} \text{.} \]

\end{definition}

Notar que por como es la definiciÃ³n de ambigÃ¼edad, cuando es relevante siempre hay una parte de $m$ y una parte de $m'$ que son iguales y que no estÃ¡n en los monomios $a$, $b$, $c$ y $d$. Los casos relevantes son los Ãºnicos importantes, y por eso son los que se usan para definir $\amb$. No relevantes siempre hay entre cualquier par de monomios, por ejemplo tomando $a = d = Îµ$, $b = m'$ y $c = m$.

\begin{definition}
  Sean $a, b, c, d âˆˆ âŸ¨XâŸ©, f, f' âˆˆ KâŸ¨XâŸ©$ y $Î± = (a, b, c, d, f, f')$ una ambigÃ¼edad. Se define el S-polinomio de $Î±$ como
  \[ \S(Î±) = \frac{afb}{\lc_â‰¤{(f)}} - \frac{cgd}{\lc_â‰¤{(f')}} \text{.}\]
\end{definition}

Por ejemplo, si $f = 2 cba + 3 dbcda$ y $f' = b + bcd$, entonces una ambigÃ¼edad de inclusiÃ³n serÃ­a

\[Î± = (Îµ, Îµ, d, a, f, f') \text{.} \]

\noindent Siendo su S-polinomio

\[S(Î±) = \frac{f}{3} - d f' a = \frac{2}{3} cba - dba  \text{.} \]

\noindent Y una ambigÃ¼edades de superposiciÃ³n serÃ­a

\[ Î±' = (bc, Îµ, Îµ, bcda, f, f') \text{.} \]

\noindent Siendo su S-polinomio

\[ S(Î±') = \frac{bc f}{3} - f' bcda = bbcda - \frac{2}{3} bccba \text{.} \]

\

Ahora vamos a probar que efectivamente los monomios principales se cancelan y despuÃ©s vamos a dar el teorema para decidir si un conjunto es una base de GrÃ¶bner.

\begin{lemma}\label{lemma:lm ambs}
  Sean $Î± = (a, b, c, d, f, g)$ una ambigÃ¼edad. Entonces:
  \[ \lm_â‰¤{(afb)} = \lm_â‰¤{(cgd)} \text{.}\]
\end{lemma}
\begin{proof}\
  Las siguientes igualdades siguen por la definiciÃ³n de ambigÃ¼edad tanto para monomios como para polinomios.
  \[ \lm_â‰¤{(afb)} = a\lm_â‰¤{(f)}b = c\lm_â‰¤{(g)}d = \lm_â‰¤{(cgd)} \text{.} \]
\end{proof}

Eso permite definir el monomio principal de una ambigÃ¼edad.

\begin{definition}
  Sean $Î± = (a, b, c, d, f, g)$ una ambigÃ¼edad. Se define el monomio principal de $Î±$ como

  \[ \lm_â‰¤(Î±) = \lm_â‰¤(afb) \text{.}\]
\end{definition}

Notar que por el \cref{lemma:lm ambs} tambiÃ©n vale que $\lm_â‰¤(Î±) = \lm_â‰¤(cgd)$.

Lo de que los monomios principales se cancelen produce el siguiente lema.

\begin{lemma}
  Sean $Î± = (a, b, c, d, f, g)$ una ambigÃ¼edad. Entonces
  \[ \lm_â‰¤(\S(Î±)) < \lm_â‰¤(Î±) \text{.}\]
\end{lemma}
\begin{proof}
  Esto es porque en la resta $\frac{afb}{\lc_â‰¤(f)} - \frac{cgd}{\lc_â‰¤(g)}$ los monomios principales se cancelan.
\end{proof}

Otra propiedad importante es que estos S-polinomios son cerrados en el ideal, es decir, que el S-polinomio de dos elementos de un ideal es un elemento del ideal.

\begin{lemma}\label{lemma:S es cerrado en ideal}
  Sean $I âŠ† KâŸ¨XâŸ©$ un ideal $f, g âˆˆ I$ y $Î± = (a, b, c, d, f, g)$ una ambigÃ¼edad. Entonces
  \[ \S(Î±) âˆˆ I \text{.}\]
\end{lemma}
\begin{proof}
  En la definiciÃ³n de $\S$ se ve que es una combinaciÃ³n lineal de $f$ y $g$ con elementos de $KâŸ¨XâŸ©$. MÃ¡s precisamente, con los elementos $\frac{a}{\lc_â‰¤{(f)}}$, $b$, $\frac{c}{\lc_â‰¤{(g)}}$ y $d$. Como $f, g âˆˆ I$ e $I$ es un ideal, esa combinaciÃ³n pertenece a $I$.
\end{proof}

Ahora si enunciamos el teorema para decidir si un conjunto es una base de GrÃ¶bner.

\begin{theorem}[CondiciÃ³n de Buchberger]\label{thm:condiciÃ³n de Buchberger}
  Sean $I$ un ideal de $KâŸ¨XâŸ©$ y $G âŠ† KâŸ¨XâŸ©$. Entonces son equivalentes:
  \begin{enumerate}
    \item $G$ es una base de GrÃ¶bner de $I$.
    \item $âˆ€Î± âˆˆ \amb(G) : \S(Î±) â†’^*_{â‰¤, G} 0$.
  \end{enumerate}
  \qed
\end{theorem}

La demostraciÃ³n se puede encontrar por ejemplo en \cite{phdthesis:Hof23}, en donde algo similar a esto estÃ¡ enunciado en el Teorema 2.4.54. No lo demostraremos acÃ¡ porque requiere varios lemas adicionales que no son pertinentes para este trabajo.

Con esto ya se puede explicar la idea del algoritmo de Buchberger. Supongamos que tenemos un conjunto que no sabemos si es base de GrÃ¶bner o no y estamos chequeando si lo es con el \cref{thm:condiciÃ³n de Buchberger}. Si nos encontramos con un S-polinomio $f$ que se reduce a un polinomio $g$ distinto de $0$ podemos agregar $g$ al conjunto y con eso $f$ pasa a sÃ­ reducirse a $0$. Se podrÃ­a pensar que agregar $g$ cambiarÃ­a el ideal generado, pero por el \cref{lemma:S es cerrado en ideal} sabemos que $g$ es un elemento del ideal y por el \cref{thm:â†’ mantiene pertenencia a ideal} eso implica que $f$ tambiÃ©n pertenece al ideal. Por ende por el \cref{lemma:gen G = gen G U a con a âˆˆ gen G} se puede agregar al conjunto y que el ideal generado siga siendo el mismo. El problema de agregar un nuevo polinomio es que si bien hay un S-polinomio que pasa a si reducirse a $0$ tambiÃ©n aparecen nuevas ambigÃ¼edades. Eso sin embargo no es tanto problema porque lo se hace es repetir hasta que en algÃºn momento todas las ambigÃ¼edades se reducen a $0$. Si eso no pasa nunca simplemente el algoritmo no termina nunca, lo que refleja la no decidibilidad del problema de pertenencia a un ideal.

Ese proceso de agregar polinomios infinitamente lo definimos matemÃ¡ticamente del siguiente modo.

\begin{definition}
  Sean $G âŠ† KâŸ¨XâŸ©$ y $e_â‰¤$ un reductor. Se definen:
  \begin{itemize}
    \item $\B_{e_â‰¤}^0(G) = G$.
    \item $\B_{e_â‰¤}^{i + 1}(G) = \B_{e_â‰¤}^i(G) âˆª \{e_â‰¤(\B_{e_â‰¤}^i(G))(\S(Î±)) : Î± âˆˆ \amb(\B_{e_â‰¤}^i(G))\}$.
    \item $\B_{e_â‰¤}(G) = â‹ƒ_{i = 0}^âˆ \B_{e_â‰¤}^i(G)$.
  \end{itemize}
  A $\B_{e_â‰¤}(G)$ lo llamamos base de Buchberger de $(G)$.
\end{definition}

El nombre base de Buchberger es inventado para esta tesis, otros autores no le han dado ningÃºn nombre concreto a esos conjuntos.

Con el siguiente teorema se enuncia que la base de Buchberger es una base de GrÃ¶bner y que si hay una base de GrÃ¶bner finita entonces en alguna iteraciÃ³n finita se llega, o sea, algÃºn $B_{e_â‰¤}^{i}(G)$ es igual a la base de Buchberger.

\begin{theorem}\label{thm:Buchberger correctitud}
  Sean $G âŠ† KâŸ¨XâŸ©$ y $e_â‰¤$ un reductor. Entonces
  \begin{enumerate}
    \item $\B_{e_â‰¤}(G)$ es una base de GrÃ¶bner de $(G)$.\label{thm:Buchberger correctitud:item:1} % TODO: Hacer esto en todos lados
    \item $(G)$ tiene una base de GrÃ¶bner finita $â‡’ âˆƒi âˆˆ â„• âˆª \{0\} : (\B_{e_â‰¤}^i(G))$ es una base de GrÃ¶bner.
  \end{enumerate}
\end{theorem}

Es esperable que \ref{thm:Buchberger correctitud:item:1} sea cierto por como definimos la base de Buchberger, mientras que (2) es mÃ¡s sorprendente. Para demostrar ambos items primero vamos a probar algunos lemas en el contexto de este teorema (o sea con $G$ y $e_â‰¤$ fijados).

\begin{lemma}\label{lemma:Buchberger correctitud:3}
  $âˆ€i âˆˆ â„• âˆª \{0\} : \B_{e_â‰¤}^{i}(G) âŠ† (G)$.
\end{lemma}
\begin{proof}
  Procedamos por inducciÃ³n sobre $i$. El caso base se cumple porque $G âŠ† (G)$. Para el caso inductivo, supongamos que la afirmaciÃ³n es cierta para $i$ y probemos que tambiÃ©n vale para $i + 1$. Para eso tomemos $f âˆˆ \B_{e_â‰¤}^{i + 1}(G)$ y probemos que $f âˆˆ (G)$.

  Por la definiciÃ³n recursiva de $\B_{e_â‰¤}^{i + 1}$ vale que $f âˆˆ \B_{e_â‰¤}^i(G) âˆ¨ âˆƒÎ± âˆˆ \amb(\B_{e_â‰¤}^i(G)) : f = e_â‰¤(\B_{e_â‰¤}^i(G))(\S(Î±))$. Dividamos en casos segÃºn ese $âˆ¨$.

  \begin{description}
    \item[Caso $f âˆˆ \B_{e_â‰¤}^i(G)$:] Es valido por ser exactamente la hipÃ³tesis inductiva.
    \item[Caso $âˆƒÎ± âˆˆ \amb(\B_{e_â‰¤}^i(G)) : f = e_â‰¤(\B_{e_â‰¤}^i(G))(\S(Î±))$:] En tal caso, por el \cref{lemma:e mantiene pertenencia a ideal} vale que $f âˆˆ \B_{e_â‰¤}^i(G)$ y por la hipÃ³tesis inductiva que $f âˆˆ (G)$.
  \end{description}

\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:4}
  $âˆ€i âˆˆ â„• : \B_{e_â‰¤}(G) âŠ† (G)$.
\end{lemma}
\begin{proof}
  Esto es consecuencia directa del \cref{lemma:Buchberger correctitud:3} y la definiciÃ³n de $\B_{e_â‰¤}$.
\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:5}
  $(\B_{e_â‰¤}(G)) = (G)$.
\end{lemma}
\begin{proof}
  Por la definiciÃ³n de $\B_{e_â‰¤}^i$ tenemos $G âŠ† \B_{e_â‰¤}(G)$ y por ende $G âŠ† (\B_{e_â‰¤}(G))$. Con el \cref{lemma:Buchberger correctitud:4} aplicando el \cref{lemma:sub gen y sub gen â‡’ eq} tenemos lo que queremos probar.
\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:6}
  $âˆ€Î± âˆˆ \amb(\B_{e_â‰¤}(G)) : \S(Î±) â†’^*_{â‰¤, \B_{e_â‰¤}(G)} 0$.
\end{lemma}
\begin{proof}
  Tomemos $Î± = (a, b, c, d, f, g) âˆˆ \amb(\B_{e_â‰¤}(G))$. Por definiciÃ³n de $\amb$ vale que $f, g âˆˆ \B_{e_â‰¤}(G)$, asÃ­ que sean:
  \begin{itemize}
    \item $i âˆˆ â„•$ el mÃ­nimo tal que $f âˆˆ \B_{e_â‰¤}^i(G)$,
    \item $j âˆˆ â„•$ el mÃ­nimo tal que $g âˆˆ \B_{e_â‰¤}^j(G)$ y
    \item $k = \max(i, j)$.
  \end{itemize}

  \noindent Por definiciÃ³n de $\amb$ tiene que valer que
  \[ Î± âˆˆ \amb(\B_{e_â‰¤}^k(G)) \]
  y entonces por definiciÃ³n de $\B_{e_â‰¤}^i$ vale que
  \[ e_â‰¤(\B_{e_â‰¤}^k(G))(\S(Î±)) âˆˆ \B_{e_â‰¤}^{k + 1}(G) \text{.} \]
  Esto implica que
  \[ e_â‰¤(\B_{e_â‰¤}^k(G))(\S(Î±)) â†’_{â‰¤, \B_{e_â‰¤}^{k + 1}(G)} 0\]
  y por ende que
  \[ e_â‰¤(\B_{e_â‰¤}^k(G))(\S(Î±)) â†’_{â‰¤, \B_{e_â‰¤}(G)} 0 \text{.} \]
  Llamemos (i) a esto Ãºltimo. Por otro lado, por definiciÃ³n de reductor tenemos que
  \[ \S(Î±) â†’^*_{â‰¤, \B_{e_â‰¤}^k(G)} e_â‰¤(\B_{e_â‰¤}^k(G))(\S(Î±)) \]
  y por ende
  \[ \S(Î±) â†’^*_{â‰¤, \B_{e_â‰¤}(G)} e_â‰¤(\B_{e_â‰¤}^k(G))(\S(Î±)) \text{(ii).} \]
  Llamemos (ii) a esto Ãºltimo. Combinando (i) y (ii) vale que $\S(Î±) â†’^*_{â‰¤, \B_{e_â‰¤}(G)} 0$, que es lo que querÃ­amos probar.
\end{proof}

Con estos lemas ahora si hagamos la demostraciÃ³n del \cref{thm:Buchberger correctitud}.

\begin{proof}[DemostraciÃ³n del \cref{thm:Buchberger correctitud}]
  Por el \cref{lemma:Buchberger correctitud:5} y el \cref{lemma:Buchberger correctitud:6} vale la equivalencia de base de GrÃ¶bner de la condiciÃ³n de Buchberger (\cref{thm:condiciÃ³n de Buchberger}), asÃ­ que (1), o sea, que $G$ es una base de GrÃ¶bner queda probado.

  Para probar (2), asumamos el antecedente, o sea, que $(G)$ tiene una base de GrÃ¶bner finita, y tomemos una base finita $\{g_1, â€¦, g_n\}$. Ahora tenemos que probar el consecuente, o sea, que $âˆƒi âˆˆ â„• âˆª \{0\} : (\B_{e_â‰¤}^i(G))$ es una base de GrÃ¶bner.  Para cada $i âˆˆ \{1, â€¦, n\}$ sean:
  \begin{itemize}
    \item $g_{i, 1}, â€¦, g_{i, k_i} âˆˆ \B_{e_â‰¤}(G), a_{i, 1}, â€¦, a_{i, k_i}, b_{i, 1}, â€¦, b_{i, k_i} âˆˆ âŸ¨XâŸ©$ con $\lm(a_{i, j} g_{i, j} b_{i, j}) â‰¤ \lm(g_i)$ tales que $g_i = âˆ‘_{j = 1}^{k_i} a_{i, j} g_{i, j} b_{i, j}$. Los cuales existen por por (5) del \cref{thm:equivalencias de base de GrÃ¶bner}.

    \item $G' = \{g_{i, j} : i âˆˆ \{1, â€¦, n\}, j âˆˆ \{1, â€¦, k_i\}\}$.

    \item $k âˆˆ â„•$ el mÃ­nimo tal que $G' âŠ† \B_{e_â‰¤}^k(G)$. Notar que $k$ estÃ¡ bien definido porque $G'$ es finito.
  \end{itemize}

  Tenemos que probar que $\B_{e_â‰¤}^k(G)$ es una base de GrÃ¶bner de $(G)$. Por (5) del \cref{thm:equivalencias de base de GrÃ¶bner} alcanza con probar:
  \[ âˆ€f âˆˆ (G) - \{0\} : âˆƒg'_1, â€¦, g'_n âˆˆ \B_{e_â‰¤}^k(G), a_1, â€¦, a_n, b_1, â€¦, b_n âˆˆ âŸ¨XâŸ© : \lm(a_i g'_i b_i) â‰¤ \lm(f) : f = âˆ‘_{i = 1}^n a_i g'_i b_i \text{.}\]

  Tomemos $f âˆˆ (G) - \{0\}$ y escribamoslo de esa forma. Por (5) del \cref{thm:equivalencias de base de GrÃ¶bner} y el hecho de que $\{g_1, â€¦, g_n\}$ es una base de GrÃ¶bner, sean $i'_1, â€¦, i'_{n'} âˆˆ {1, â€¦, n}, a'_1, â€¦, a'_{n'}, b'_1, â€¦, b'_{n'} âˆˆ âŸ¨XâŸ©$ tales que:
  \begin{itemize}
    \item $\lm(a'_i g_{i'_i} b'_i) â‰¤ \lm(f)$ y
    \item $f = âˆ‘_{i = 1}^{n'} a'_i g_{i'_i} b'_i$.
  \end{itemize}

  Con esto tenemos:

  \begin{DispWithArrows*}
    &f = âˆ‘_{i = 1}^{n'} a'_i g_{i'_i} b'_i \Arrow{CondiciÃ³n de $g_{i, j}$} \\
    & = âˆ‘_{i = 1}^{n'} a'_i (âˆ‘_{j = 1}^{k_{i'_i}} a_{i', j} g_{i, j} b_{i', j}) b'_i \\
    & = âˆ‘_{i = 1}^{n'} âˆ‘_{j = 1}^{k_i'} a'_i a_{i', j} g_{i, j} b_{i', j} b'_i \text{.}
  \end{DispWithArrows*}

  Sabemos ademÃ¡s que $g_{i',j} âˆˆ \B_{e_â‰¤}^k(G)$ y que $g_{i', j} â‰¤ g_{i'_i} â‰¤ f$. AsÃ­ que queda $f$ escrito como querÃ­amos y la prueba completada.
\end{proof}

Con estos conjuntos podemos de forma directa dar un seudocÃ³digo que los calcula:

\begin{algorithm}[H] % La H es para que se quede acÃ¡, porque se iba a otra pÃ¡gina. EstarÃ­a bueno hacerlo global
  \caption{Algoritmo de Buchberger}\label{alg:Buchberger}
  \KwData{$G âŠ† KâŸ¨XâŸ©$, $e_â‰¤$ un reductor}
  \KwResult{$B âŠ† KâŸ¨XâŸ©$ una base de GrÃ¶bner de $(G)$ si es que termina}
  $B â† G$

  \Loop{} {
    $ambs â† \amb(B)$

    $B' â† B$

    \For{$Î± âˆˆ ambs$} {
      $f â† e_â‰¤(B)(\S(Î±))$

      \If{$f â‰  0$} {
        $B' â† B' âˆª \{f\}$
      }
    }

    \If{$B' = B$} {
      \Break
    }

    $B â† B'$
  }
  \Return{$B$}
\end{algorithm}

El algoritmo asÃ­, si bien es una implementaciÃ³n literal de la definiciÃ³n de los conjuntos $\B_{e_â‰¤}^i$ que probamos que es correcta, es muy lento y necesita mejoras. Una mejora muy importante, probablemente la mÃ¡s importante, consiste en usar tambiÃ©n los nuevos polinomios que ya fueron agregados para hacer las nuevas reducciones en el paso. Es decir, llamar a $e_â‰¤$ con $B'$ en lugar de con $B$ en la lÃ­nea 6. % Se podrÃ¡ hacer con un label esto?

Por lo visto antes el cambio tiene sentido que sea correcto y la prueba es similar a la del \cref{thm:Buchberger correctitud}. En la prÃ¡ctica esta mejora hace una diferencia inmensa en la eficiencia, pasa de no andar rÃ¡pido casi nunca a andar rÃ¡pido en una gran cantidad de casos. La justificaciÃ³n teÃ³rica de porque hacer eso hace que pase a ser tanto mas rÃ¡pido no la se ni la pude encontrar en la literatura.

Hay otras dos optimizaciones que se pueden hacer: una es para descartar algunas ambigÃ¼edades sin tener que reducirlas y la otra es para ir sacando algunos polinomios de la base. En la \cref{secton:optimizaciones} se aborda este tema.

\section{Algoritmo F4}

En esta secciÃ³n se explica el algoritmo F4, que es otro mÃ©todo para calcular Bases de GrÃ¶bner. La idea de F4 es considerar varias ambigÃ¼edades y reducir todos sus S-polinomios al mismo tiempo, reduciendo con los elementos que ya estÃ¡n en la base y entre los propios S-polinomios que se estÃ¡n considerando. Para esto se convierte el problema en una reducciÃ³n por filas de una matriz, codificando cada monomio como una columna y cada polinomio como una fila. Para codificar los polinomios como filas de una matriz hacen falta algunas definiciones.

\begin{definition}
  Sea $F âŠ† KâŸ¨XâŸ©$. Se define
  \[ \spn_K(F) = \{âˆ‘_{i = 1}^n c_i f_i : n âˆˆ â„•, c_i âˆˆ K, f_i âˆˆ F\} \text{.} \]
\end{definition}

\begin{definition}
  Sean $M = \{m_1, â€¦, m_n\} âŠ† âŸ¨XâŸ©$ con $m_1 > â‹¯ > m_n$. Se define la funciÃ³n $\poli_M : K^n â†’ \spn_K(M)$ de la siguiente manera:
  \[ \poli_M(v) = âˆ‘_{i = 1}^n v_i m_i \text{.} \]
\end{definition}

\begin{definition}
  Sean $M = \{m_1, â€¦, m_n\} âŠ† âŸ¨XâŸ©$ con $m_1 > â‹¯ > m_n$. Se define $\mat_M : \spn_K(M) â†’ K^n$ como la inversa de $\poli_M$:
  \[ \mat_M(f) = \poli_M^{-1}(f) \text{.} \]
  Para una lista de polinomios se define que $\mat_M$ produzca una matriz:
  \[ \mat_M(f_1, â€¦, f_m) = \begin{pmatrix} \mat_M(f_1) \\ â‹® \\ \mat_M(f_m) \end{pmatrix} \text{.} \]
\end{definition}

Estas definiciones son un diccionario polinomios-matrices y matrices-polinomios. AsÃ­, en la reducciÃ³n, restar un polinomio multiplicado por un escalar y un monomio a cada lado la idea es que pase a ser restarle una fila multiplicada por un escalar a otra en la matriz. Para eso, al comenzar hay que tener en la matriz los polinomios a restar ya multiplicados por los monomios a cada lado, es decir, con los $agb$ con $a,b âˆˆ âŸ¨XâŸ©$ y $g âˆˆ G$. Para eso definimos el algoritmo de preprocesamiento simbÃ³lico que, dado el conjunto por el cual se reduce $G$ y el conjunto a reducir $F$, calcula todos los polinomios necesarios:

\begin{algorithm}[H] % La H es para que se quede acÃ¡, porque se iba a otra pÃ¡gina. EstarÃ­a bueno hacerlo global
  \caption{Preprocesamiento simbÃ³lico}\label{alg:Preprocesamiento simbÃ³lico}
  \KwData{$G, F âŠ† KâŸ¨XâŸ©$ conjuntos finitos}
  \KwResult{$G' âŠ† \{agb : a, b âˆˆ âŸ¨XâŸ©, g âˆˆ G\}$}
  $G' â† âˆ…$

  $conciderados â† \{\lm(g) : g âˆˆ P\}$

  $T â† â‹ƒ_{g âˆˆ P} \sop(\tail(g))$

  \While{$T â‰  âˆ…$} {
    elegir $m âˆˆ T$

    $T â† T - \{m\}$

    \For{$g âˆˆ G$} {
      \If{$\lm(g) | m$} {
        calcular $a$ y $b$ tales que $m = a \lm(g) b$

        $G' â† G' âˆª {agb}$

        $nuevos â† \{m' âˆˆ \sop(\tail(agb)) : m' âˆ‰ conciderados\}$

        $T â† T âˆª nuevos$

        $conciderados â† conciderados âˆª nuevos$
      }
    }
  }

  \Return{$G'$}
\end{algorithm}

% Agregar ejemplo

Una vez que hemos determinados los monomios que necesitamos, armamos la matriz correspondiente a $G$ y $F$ usando la funciÃ³n $\mat_T$ y reducimos por fila esta matriz. Con la matriz no es obvio que hay que hacer, porque hay que solo conciderar las filas que corresponden a los polinomios reducidos, pero no nesesarimente son las mismas filas que eran antes porque la reducciÃ³n por filas puede hacer cosas como intercambiar filas. Para saber cuales son esas filas lo que se hace es guardar cuÃ¡les son los monomios principales de elementos del resultado del preprocesamiento simbÃ³lico y despuÃ©s de hacer la reducciÃ³n por filas agarrar solo las filas que tengan un uno principal en una columna que no corresponda a uno de esos monomios principales.

El siguiente seudocÃ³digo hace eso:

\begin{algorithm}[H] % La H es para que se quede acÃ¡, porque se iba a otra pÃ¡gina. EstarÃ­a bueno hacerlo global
  \caption{MultireducciÃ³n}\label{alg:MultireducciÃ³n}
  \KwData{$G, F âŠ† KâŸ¨XâŸ©$ conjuntos finitos}
  \KwResult{$F' âŠ† KâŸ¨XâŸ©$}
  $G' â†$ Preprocesamiento simbÃ³lico$(G, F)$

  $monomios â† \{\lm(g) : g âˆˆ G'\}$

  $M â† \{m : m âˆˆ \sop(g), g âˆˆ G' âˆª F\}$

  $mat â† \mat_M(G' âˆª F)$

  reducir por filas $mat$

  $F' â† \{\poli_M(v) : v âˆˆ \filas(mat) : v â‰  0 âˆ§ \lm(\poli_M(v)) âˆ‰ monomios\}$

  \Return{$F'$}
\end{algorithm}

Con estos dos algoritmos ya podemos escribir el algoritmo F4:

\begin{algorithm}[H] % La H es para que se quede acÃ¡, porque se iba a otra pÃ¡gina. EstarÃ­a bueno hacerlo global
  \caption{F4}\label{alg:F4}
  \KwData{$G âŠ† KâŸ¨XâŸ©$, $e_â‰¤$ un reductor}
  \KwResult{$B âŠ† KâŸ¨XâŸ©$ una base de GrÃ¶bner de $(G)$ si es que termina}
  $B â† G$

  \Loop{} {
    $ambs â† \amb(B)$

    $B' â† B$

    \While{$ambs â‰  âˆ…$} {
      elegir $Î‘ âŠ† ambs$

      $ambs â† ambs - Î‘$

      $P â† \{\S(Î±) : Î± âˆˆ Î‘\}$

      $P â†$ MultireducciÃ³n$(B', P)$

      $B' â† B' âˆª P$
    }

    \If{$B' = B$} {
      \Break
    }

    $B â† B'$
  }

  \Return{$B$}
\end{algorithm}

Este algoritmo no especifica cuÃ¡les ambigÃ¼edades elegir, pero una buena estrategia es elegir todas las de menor grado. Otra opciÃ³n es elegir todas, pero eso puede hacer que las matrices se vuelvan muy grandes rÃ¡pidamente.

En \cite{thesis:Hof20} se da un algoritmo muy parecido a este (con una diferencia mÃ­nima) y se demuestra que es correcto.

Las optimizaciones mencionadas en la secciÃ³n de Buchberger para descartar ambigÃ¼edades y para quitar polinomios de la base tambiÃ©n se pueden hacer acÃ¡. Otra optimizaciÃ³n que se puede hacer es usar un algoritmo de reducciÃ³n de matrices que anda mÃ¡s rÃ¡pido en las matrices de este problema en particular, llamado eliminaciÃ³n FaugÃ¨re-Lachartre. Esto tambiÃ©n es abordado en la \cref{secton:optimizaciones}.

\chapter{LibrerÃ­a}

Como se dijo al principio, para esta tesis se implementaron los algoritmos de Buchberger y F4 en \cpp junto con estructuras para manejar polinomios no conmutativos en una librerÃ­a llamada \texttt{ncgb}. La librerÃ­a  se encuentra disponible en el repositorio \href{https://github.com/IvanRenison/Non-commutative-Grobner-Bases}{\texttt{Non-commutative-Grobner-Bases}}. Este capÃ­tulo describe la estructura general de la librerÃ­a y cÃ³mo usarla en su versiÃ³n actual (fecha de publicaciÃ³n de esta tesis).

\section{Estructura de la librerÃ­a}

El repositorio tiene varias carpetas, pero hay dos que son las mÃ¡s relevantes para el o la usuaria. La primera es la carpeta \texttt{ncgb}, que es donde estÃ¡ alojada la librerÃ­a en sÃ­. Como la librerÃ­a es genÃ©rica sobre algunos parÃ¡metros, se usan templates. Las clases y funciones genÃ©ricas se definen en archivos \texttt{.hpp}, donde se incluye tanto su declaraciÃ³n como su implementaciÃ³n. La otra carpeta relevante es \texttt{mains}, que tiene varios archivos \texttt{.cpp} con funciones \texttt{main} que usan la librerÃ­a. Estos archivos son Ãºtiles para ver ejemplos de cÃ³mo usar la librerÃ­a.

Todo el cÃ³digo de la librerÃ­a estÃ¡ en el namespace \texttt{ncgb}. En todos los cÃ³digos que veamos asumiremos que \texttt{ngcb} estÃ¡ abierto.

Los polinomios como los definimos en el \cref{cap:Preliminares} estÃ¡n asociados a un cuerpo y un conjunto de variables; ademÃ¡s muchas operaciones y mÃ©todos de los polinomios (y de otras definiciones) dependen de un orden monomial. Para que se puedan variar esas tres cosas se usan templates para hacer las funciones y estructuras de forma genÃ©rica. Por ejemplo, la definiciÃ³n de polinomio es asÃ­: % No se como remplazar "cosas" acÃ¡ porque son dos tipos y un orden

\begin{minted}{C++}
  template<typename K, typename X = __uint8_t, class ord = DegLexOrd<X>>
  struct Poly {
    // â€¦ ImplementaciÃ³n
  };
\end{minted}

El tipo \texttt{K} tiene que tener implementadas todas las operaciones de cuerpo. En particular, la librerÃ­a asume que tiene definidas las siguientes operaciones y construcciones:

\begin{itemize}
  \item \texttt{+}, \texttt{-} (tanto unario como binario), \texttt{*} y \texttt{/} junto con sus versiones de asignaciÃ³n \texttt{+=}, \texttt{-=}, \texttt{*=} y \texttt{/=}. De las versiones asignaciÃ³n no se usa el resultado, solo el hecho de que modifican el operando izquierdo, asÃ­ que pueden devolver \texttt{void}.
  % Miguel puso: No entiendo quÃ© significa esto. Â¿Es relevante para que yo pueda definir un nuevo cuerpo?
  % Es relevante porque significa que podÃ©s hacer que devuelvan void, y eso de hecho pasa en ModularArithmetic
  % No se como explicarlo de otra forma.
  \item \texttt{==} (y tambiÃ©n \texttt{!=}, pero a partir de \cppXX estÃ¡ automÃ¡ticamente con \texttt{==}).
  % Miguel sugiriÃ³: (y tambiÃ©n !=. SÃ³lo es necesario si se compila con un estÃ¡ndar anterior a C++20 ).
  % No creo que compile con un C++ anterior al 20, pero, algo pasa es que si en C++ mayor o igual a 20 igual se define !=, se usa ese != definido a parte, no la negaciÃ³n de ==. No me convence lo que sugiere Miguel por que no queda claro eso.
  \item \texttt{<<} para imprimir y \texttt{>>} para leer.
  \item Hacer \texttt{K(0)} y \texttt{K(1)} tiene que andar.
\end{itemize}

Y como es esperable, las operaciones tienen que cumplir todos los axiomas de cuerpos.

En este trabajo se usaron dos cuerpos distintos, los nÃºmeros racionales, usando el tipo \texttt{mpq\_class} de la librerÃ­a GMP que ya tiene todo lo que \texttt{K} tiene que tener (\cite{lib:gmp}) y la aritmÃ©tica modular con una implementaciÃ³n propia en el archivo \texttt{extras/ModularArithmetic.hpp}, que sirve para ver un ejemplo de un cuerpo que anda con la librerÃ­a (aunque tiene algunas operaciones extra).
% Lo de ModularArithmetic es genÃ©rico para un nÃºmero, pero se rompe si el nÃºmero no es un primo

El tipo \texttt{X} se usa para representar las variables como nÃºmeros y la idea es que se use algÃºn tipo de nÃºmeros sin signo. Usar otros tipos podrÃ­a funcionar pero no estÃ¡ probado. Por defecto se usa \texttt{\_\_uint8\_t} que permite tener hasta 256 variables. Para usar mÃ¡s variables hay que cambiarlo a un entero sin signo mÃ¡s grande como \texttt{\_\_uint32\_t}.
% Miguel puso:
%   Â¿por quÃ© tienen que ser nÃºmeros? Â¿es buena idea?
%   Â¿QuÃ© podrÃ­a fallar? Â¿QuÃ© operaciones asumÃ­s sobre X?
% Ni idea de que podrÃ­a fallar, pero porque alguien querrÃ­a usar otra cosa? O sea, el motivo para hacerlo genÃ©rico es por si alguien lo quiere usar para mÃ¡s de 256 variables, no para hacer cosas raras

Por Ãºltimo, \texttt{ord} es el orden monomial que se usa y estÃ¡ puesto por defecto \texttt{DegLexOrd} que es el orden lexicogrÃ¡fico por grado y ya estÃ¡ definido junto con la definiciÃ³n de monomios. Para usar otro orden hay que definir una estructura que tenga un operador \texttt{()} que implemente el testeo del orden. Esta es la forma estÃ¡ndar de definir Ã³rdenes para usar en templates en \cpp. Algo asÃ­ podrÃ­a ser el cÃ³digo si es una implementaciÃ³n para un \texttt{X} genÃ©rico:
% Miguel puso: Â¡Pero no dÃ¡s la implementaciÃ³n!
% Pero quÃ© deberÃ­a hacer?

\begin{minted}{C++}
  template<typename X>
  struct Orden {
    bool operator()(const Monomial<X>& a, const Monomial<X>& b) const {
      // â€¦ ImplementaciÃ³n
    }
  };
\end{minted}

Tanto para \texttt{X} como para \texttt{ord} los valores por defecto estÃ¡n puestos solo en las estructuras de monomios y polinomios, porque en las otras funciones y estructuras no hace falta ya que para usarlas hay que ya tener un monomio o un polinomio (que se pase como argumento) y de ahÃ­ \cpp infiere \texttt{X} y \texttt{ord} automÃ¡ticamente.
% Miguel puso: Esto puede ir antes.
% Pero no se donde podrÃ­a ir antes

La librerÃ­a tambiÃ©n tiene un Makefile con el que se pueden compilar los mains de la carpeta \texttt{mains} y correr los tests. Este Makefile puede servir de ejemplo de como se compila un archivo que usa la librerÃ­a.

\section{Monomios}

Los monomios estÃ¡n definidos en el archivo \texttt{nc\_monomial.hpp} y lo mÃ¡s importante de su funcionalidad se puede resumir asÃ­:

\begin{minted}{C++}
  template<typename X = __uint8_t>
  struct Monomial {
    Monomial();
    Monomial(const std::vector<X>& vals);

    bool operator==(const Monomial& m) const;
    Monomial operator*(const Monomial& m) const;
    void operator*=(const Monomial& m);
    size_t size() const;
    bool empty() const;

    // Returns the positions of m.vals where this monomial divides m
    std::vector<size_t> divide_indexes(const Monomial& m) const;

    // Does this monomial divides m?
    bool divides(const Monomial& m) const;

    // Make all possible divisions of m by this monomial
    std::vector<std::pair<Monomial, Monomial>> divide(const Monomial& m) const;

    friend std::ostream& operator<<(std::ostream& os, const Monomial& m);
    friend std::istream& operator>>(std::istream& is, Monomial& m);

    void nice_print(std::ostream& os = std::cout) const;
    static Monomial nice_read(std::istream& is = std::cin);
  };
\end{minted}

El Ãºnico argumento del template es \texttt{X}, porque no hace falta nada del cuerpo ni tampoco un orden monomial (de hecho no tendrÃ­a sentido que haga falta un orden monomial para definir monomios).

Relacionado a la divisiÃ³n el mÃ©todo mÃ¡s importante es \texttt{divide\_indexes} que se llama como \texttt{m0.divide\_indexes(m1)} y devuelve un vector de \texttt{size\_t} que indica las posiciones de \texttt{m1} donde empieza una sub-palabra igual a \texttt{m0}.

Respecto a la representaciÃ³n como strings, hay dos pares de mÃ©todos. Por un lado estÃ¡n \texttt{operator>>} y \texttt{operator<<} que leen y escriben en un formato numÃ©rico que es cÃ³modo para usar en cÃ³digo. Por otro lado \texttt{nice\_read} y \texttt{nice\_print} que leen y escriben en el formato que se suele usar al escribir a mano los monomios.

El formato numÃ©rico consiste en un nÃºmero entero no negativo $n$ seguido de $n$ nÃºmeros $x_1$, â€¦, $x_n$ que son los nÃºmeros de variables. Cuando $n = 0$ no hay ningÃºn $x_i$. Se puede representar asÃ­ el formato:

$\begin{array}{llll} n & x_1 & â‹¯ & x_n \end{array}$

Por ejemplo, acÃ¡ hay un monomio en el formato como se suelen escribir a mano:

\begin{lstlisting}
  adbda
\end{lstlisting}

\noindent Y acÃ¡ estÃ¡ el mismo monomio en el formato numÃ©rico:

\begin{lstlisting}
  5 0 3 1 3 0
\end{lstlisting}

Para declarar un monomio con \texttt{X = \_\_uint8\_t}, leerlo en formato numÃ©rico e imprimirlo en formato bonito se puede hacer asÃ­:

\begin{minted}{C++}
  Monomial m;
  std::cin >> m;
  m.nice_print();
\end{minted}

En el mismo archivo \texttt{nc\_monomial.hpp} estÃ¡ definido el orden lexicogrÃ¡fico por grado \texttt{DegLexOrd}.

\section{Polinomios}

Los polinomios estÃ¡n definidos en el archivo \texttt{nc\_polynomial.hpp} y lo mÃ¡s importante de su funcionalidad se puede resumir asÃ­:

\begin{minted}{C++}
  template<typename K, typename X = __uint8_t, class ord = DegLexOrd<X>>
  struct Poly {
    Poly();
    Poly(const Monomial<X>& m, K c = K(1));
    Poly(std::vector<std::pair<Monomial<X>, K>> p);

    bool operator==(const Poly& p) const;

    Poly operator+(const Poly& p) const;
    Poly operator-(const Poly& p) const;
    Poly operator*(const Poly& p) const;
    Poly operator*(Monomial<X> m) const;
    Poly operator*(K c) const;
    Poly operator/(K c) const;
    Poly operator-() const;
    void operator+=(const Poly& p);
    void operator-=(const Poly& p);
    void operator*=(const Poly& p);
    void operator*=(Monomial<X> m);
    void operator*=(K c);

    K coeff(const Monomial<X>& m) const;

    const Monomial<X>& lm() const;
    K lc() const;
    Poly lt() const;
    bool monic() const;
    bool isZero() const;

    friend std::ostream& operator<<(std::ostream& os, const Poly& p);
    friend std::istream& operator>>(std::istream& is, Poly& p);

    void nice_print(std::ostream& os = std::cout) const;
    static Poly nice_read(std::istream& is = std::cin);
  };
\end{minted}

Para construir un polinomio hay tres constructores: el constructor vacÃ­o que produce el polinomio $0$, un constructor que toma un monomio $m$ y un elemento del cuerpo $c$ y produce el polinomio $cm$, y un constructor que toma un vector de pares monomio-coeficiente y produce el polinomio que es la suma de cada coeficiente multiplicado con su monomio.

El tipo \texttt{Poly} tiene implementadas todas las operaciones entre polinomios (como la suma) con los operadores correspondientes (como \texttt{operator+} y \texttt{operator+=}, por ejemplo), mÃ©todos algunas de las cosas definidas en la \cref{def:cosas de polinomios} (\texttt{coeff}, \texttt{lm}, \texttt{lc} y \texttt{lt}) y mÃ©todos relacionados a la representaciÃ³n de los polinomios como strings. % No se porque remplazar "cosas" acÃ¡

Al igual que con los monomios, para la representaciÃ³n como strings, hay dos pares de mÃ©todos: \texttt{operator>>} y \texttt{operator<<} para formato numÃ©rico, y \texttt{nice\_print} y \texttt{nice\_read} para formato visualmente bonito.

El formato numÃ©rico consiste en, primero, un nÃºmero entero no negativo $k$ que es la cantidad de tÃ©rminos, seguido de la descripciÃ³n de $k$ tÃ©rminos. La descripciÃ³n de cada tÃ©rmino consiste en primero el coeficiente y despuÃ©s la descripciÃ³n del monomio en el formato numÃ©rico de los monomios. Se puede representar asÃ­ el formato:

$\begin{array}{llllll}
  k &&&& \\
  c_1 & n_1 & x_{1, 1} & â‹¯ & x_{1, n_1} \\
  â‹® &&&& \\
  c_m & n_m & x_{k, 1} & â‹¯ & x_{k, n_m}
\end{array}$

Por ejemplo, acÃ¡ hay un polinomio en el formato como se suelen escribir a mano:

\begin{lstlisting}
  3 aaa - 5 bcc + adbda
\end{lstlisting}

\noindent Y acÃ¡ estÃ¡ el mismo polinomio en el formato numÃ©rico:

\begin{lstlisting}
  3
  3 3 0 0 0
  -5 3 1 2 2
  1 5 0 3 1 3 0
\end{lstlisting}

Por ejemplo, para declarar un polinomio con \texttt{K = mpq\_class}, \texttt{X = \_\_uint8\_t} y \texttt{ord = DegLexOrd<X>}, leerlo en formato numÃ©rico e imprimirlo en formato bonito se puede hacer asÃ­:

\begin{minted}{C++}
  Poly<mpq_class> p;
  std::cin >> p;
  p.nice_print();
\end{minted}

\section{Buchberger y F4}

Los algoritmos de Buchberger y F4 estÃ¡n ambos hechos de una forma que se usan similar, asÃ­ que por eso estÃ¡n explicados juntos.

Como ambos algoritmos tienen el problema de que pueden no terminar, no conviene hacer directamente una funciÃ³n que tome el conjunto generador y devuelva una base de GrÃ¶bner porque podrÃ­a no terminar. Si tiene sentido tener una funciÃ³n como esa para casos en los que se sabe que va a terminar, pero no conviene que sea la Ãºnica forma de usar los algoritmos.

Se podrÃ­a hacer una funciÃ³n que ademÃ¡s del conjunto generador tome un nÃºmero que sea la cantidad de pasos a ejecutar y que ademÃ¡s de devolver un conjunto devuelva si se llegÃ³ a una base de GrÃ¶bner o no. Esta opciÃ³n tiene el problema de que una vez que la funciÃ³n retorna no se puede seguir con el cÃ¡lculo, lo cual en algunos casos podrÃ­a ser deseable.

Para evitar esos problemas se definiÃ³ una estructura que el constructor toma a los polinomios y tiene un mÃ©todo \texttt{next} que calcula un paso mÃ¡s del cÃ¡lculo de la base de GrÃ¶bner y en caso de haber terminado lo dice y un mÃ©todo \texttt{fullBase} para usar solo en el caso de que se sepa que hay una base finita, que hace las llamadas a \texttt{next} hasta que termina y devuelve la base.

Para Buchberger la estructura estÃ¡ en el archivo \texttt{Buchberger.hpp} y se llama \texttt{BuchbergerIncremental} y para F4 la estructura estÃ¡ en el archivo \texttt{F4.hpp} y se llama \texttt{F4Incremental}. En el caso de Buchberger el mÃ©todo \texttt{next} devuelve un \texttt{std::optional<Poly<K, ord>>} que es vacÃ­o solo en el caso de que ya se haya llegado a una base de GrÃ¶bner y si no tiene un polinomio de la base de GrÃ¶bner. En el caso de F4 el mÃ©todo \texttt{next} devuelve un \texttt{std::vector<Poly<K, ord>>} que es vacÃ­o solo en el caso de que ya se haya llegado a una base de GrÃ¶bner y si no tiene varios polinomios de la base de GrÃ¶bner. En ambos casos devolver vacÃ­o es la forma de decir que ya terminÃ³ el algoritmo.

La interfaz de Buchberger podrÃ­a describirse asÃ­:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  struct BuchbergerIncremental {
    BuchbergerIncremental(const std::vector<Poly<K, X, ord>>& G);
    std::optional<Poly<K, X, ord>> next();
    std::vector<Poly<K, X, ord>> fullBase();
  };
\end{minted}

Y la de F4 asÃ­:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  struct F4Incremental {
    F4Incremental(const std::vector<Poly<K, X, ord>>& G);
    std::vector<Poly<K, X, ord>> next();
    std::vector<Poly<K, X, ord>> fullBase();
  };
\end{minted}

En ambos casos el conjunto generador se toma como un vector porque usar un set de \cpp serÃ­a mÃ¡s costoso innecesariamente.

Para ambos algoritmos hay ademÃ¡s una funciÃ³n \texttt{inIdeal} que toma un conjunto generador, un polinomio y una cantidad de pasos y trata de decir si el polinomio estÃ¡ en el ideal generado por el conjunto generador haciendo esa cantidad de llamadas a \texttt{next}. Esa funciÃ³n devuelve un elemento del siguiente tipo (con los significados que estÃ¡n comentados):

\begin{minted}{C++}
  enum IdealMembershipStatus {
    InIdeal,   // The element is definitely in the ideal
    NotInIdeal,// The element is definitely not in the ideal
    Unknown    // More steps are needed to determine if the element is in the ideal
  };
\end{minted}

\noindent Y estÃ¡ declarada asÃ­:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  IdealMembershipStatus
  inIdeal(const std::vector<Poly<K, X, ord>>& G, Poly<K, X, ord> f, size_t st = 20);
\end{minted}

Esa funciÃ³n bÃ¡sicamente trata de responder el \cref{problem:principal} de si un polinomio estÃ¡ en el ideal generado por un conjunto generador.

\section{RepresentaciÃ³n con cofactores}\label{section:representaciÃ³n con cofectores (librerÃ­a)}

La funciÃ³n \texttt{inIdeal} solo decide la pertenencia al ideal generado, pero en caso afirmativo no da una forma de escribirlo como combinaciÃ³n lineal de elementos del conjunto generador con polinomios como coeficientes.

Con las bases de GrÃ¶bner pasa lo mismo, los algoritmos dan la base pero no dan una forma de escribir los elementos de la base usando los elementos del conjunto generador.

Sin embargo esa informaciÃ³n se puede calcular y ese cÃ¡lculo estÃ¡ implementado para Buchberger en el mismo archivo \texttt{Buchberger.hpp} en unas funciones y estructuras con nombres que terminan en \texttt{Cofactor}. Esta terminaciÃ³n es porque la forma de escribir un polinomio como combinaciÃ³n lineal de otros se llama representaciÃ³n de cofactores.

Estas funciones devuelven elementos del tipo \texttt{CofactorPoly} definido en el archivo \texttt{nc\_cofactorPolynomial.hpp}. Este tipo representa un polinomio como una combinaciÃ³n lineal de elementos del conjunto generador. En particular, guarda un vector de elementos $m$, $i$, $m'$, $c$ de forma que, si los $g_i$ son el conjunto generador, el polinomio representado es $âˆ‘ m g_i m' c$.

Para F4 esto no estÃ¡ implementado (en el siguiente capÃ­tulo se explica mÃ¡s del por quÃ©).


\section{ComparaciÃ³n de bases de GrÃ¶bner}\label{section:ComparaciÃ³n de bases de GrÃ¶bner (libreria)}

En el archivo \texttt{cmpBases.hpp} estÃ¡ la funciÃ³n \texttt{cmpBases} que toma dos conjuntos generadores y, asumiendo que son bases de GrÃ¶bner, dice si generan el mismo ideal o no.

\section{Paralelismo} % O paralelizaciÃ³n?

Como ya se dijo antes, uno de los objetivos del trabajo fue paralelizar el cÃ¡lculo de bases de GrÃ¶bner. Eso se hizo parcialmente para F4. O sea, se hizo solo para una parte del cÃ³digo. En esta secciÃ³n se explica como hacer que el la parte del cÃ³digo que puede ejecutarse en paralelo lo haga.

La paralelizaciÃ³n estÃ¡ hecha con OpenMP (\cite{lib:openmp}), que es una librerÃ­a de \cpp de paralelizaciÃ³n, asÃ­ que para que corra en paralelo es igual que en cualquier otro cÃ³digo paralelizado con OpenMP.

Para compilar para que se corra en paralelo hay que usar el flag \texttt{-fopenmp}. Este flag estÃ¡ puesto en la configuraciÃ³n del Makefile para cuando se compilan los mains y los test. Solo con usar ese flag sigue igual corriendo con un solo hilo. Para que corra con varios hilos hay varias formas, la mÃ¡s fÃ¡cil es incluir a OpenMP con \texttt{\#include <omp.h>} y en el main llamar a la funciÃ³n \texttt{omp\_set\_num\_threads} pasandole la cantidad del hilos con los que se quiere correr.


\section{Ejemplo}

Ahora un pequeÃ±o ejemplo de uso de la librerÃ­a, con un ejemplo similar al del archivo \texttt{mains/base\_Buchberger.cpp}:

\begin{minted}{C++}
  #include <bits/stdc++.h>
  #include <gmpxx.h>
  #include "ncgb/Buchberger.hpp"
  using namespace std;
  using namespace ncgb;

  typedef Poly<mpq_class> P;

  int main() {
    size_t n;
    cin >> n;
    vector<P> G(n);
    for (size_t i = 0; i < n; ++i) cin >> G[i];

    BuchbergerIncremental<P> bi(G);
    vector<P> base = bi.fullBase();

    cout << base.size() << endl;
    for (P& f : base) f.nice_print();
  }
\end{minted}

Este cÃ³digo, que trabaja sobre los racionales, lee un conjunto generador en formato numÃ©rico, le calcula una base de GrÃ¶bner, asumiendo que tiene una finita, y la imprime de forma bonita.


\chapter{ImplementaciÃ³n}

En este capÃ­tulo se explican los detalles de cÃ³mo estÃ¡ hecha la implementaciÃ³n en su versiÃ³n actual (fecha de publicaciÃ³n de esta tesis).

\section{Monomios}

Los monomios, o sea los elementos de $âŸ¨XâŸ©$, como son palabras se implementaron usando vectores de \texttt{X}. La base de la implementaciÃ³n es asÃ­:

\begin{minted}{C++}
  template<typename X = __uint8_t>
  struct Monomial {
    std::vector<X> vals;
    // â€¦ MÃ©todos
  };
\end{minted}

Con esto, usando \texttt{X = \_\_uint8\_t}, que tiene 8 bits, se pueden tener hasta 256 variables. Cuando los monomios se imprimen o leen de forma bonita solo hay 26 variables, correspondiendo el 0 con la \texttt{a}. Si se quiere imprimir de forma bonita un monomio que usa variables mayores o iguales a 26 salta una aserciÃ³n.

Esta estructura tiene implementadas las operaciones y mÃ©todos que se describieron en el capÃ­tulo anterior. La mayorÃ­a tienen una implementaciÃ³n directa. Las Ãºnicas no directas son las relacionadas a la divisiÃ³n, porque chequear divisibilidad es chequear si una palabra es sub-palabra de otra, para lo cual, la forma directa de hacerlo lleva tiempo cuadrÃ¡tico en el largo de las palabras, pero se puede hacer en tiempo lineal.

Hay muchas formas de hacerlo en tiempo lineal, la que se usÃ³ es la funciÃ³n Z (que en el cÃ³digo estÃ¡ en el archivo \texttt{Zfunc.hpp}). En \cite{web:cp-algo:Zfunc} se explica la funciÃ³n Z y cÃ³mo usarla para chequear si una palabra es sub-palabra de otra.
% TambiÃ©n quizÃ¡s tiene sentido aclarar que no es la misma que la funciÃ³n Î¶ de Riemann, que es lo primero que aparece al buscar en google "funciÃ³n Z"

Junto con la implementaciÃ³n de los monomios, en el archivo \texttt{nc\_monomial.hpp} estÃ¡ la implementaciÃ³n del orden lexicogrÃ¡fico por grado, que tambiÃ©n es directa.

\section{Polinomios}

Los polinomios, o sea los elementos de $KâŸ¨XâŸ©$ estÃ¡n implementados usando un vector de pares monomio-coeficiente que siempre se mantiene ordenado por el orden monomial. La base de la implementaciÃ³n es asÃ­:

\begin{minted}{C++}
  template<typename K, typename X = __uint8_t, class ord = DegLexOrd<X>>
  struct Poly {
    std::vector<std::pair<Monomial<X>, K>> terms;
    // â€¦ MÃ©todos
  };
\end{minted}

Con esta estructura para los polinomios todas las operaciones se hacen de forma directa.

El orden de los polinomios estÃ¡ definido como \texttt{template<typename K, typename X, class ord> struct PolyOrd}.

\section{ReducciÃ³n}

La reducciÃ³n estÃ¡ implementada en el archivo \texttt{reductions.hpp}, en particular en la funciÃ³n \texttt{reduce} que toma un polinomio y un vector de polinomios y reduce el polinomio con los polinomios del vector. La reducciÃ³n se hace modificando el propio argumento. Esa funciÃ³n serÃ­a una implementaciÃ³n de un reductor concreto, o sea, de un $e_â‰¤$ y trata siempre de reducir primero por los primeros elementos del vector y empezando por los monomios mÃ¡s grandes del polinomio.

En el archivo tambiÃ©n hay una funciÃ³n \texttt{reduce} que ademÃ¡s toma un vector de booleanos que tiene que ser del mismo largo que el vector de polinomios (en \cpp se puede tener varias funciones con el mismo nombre si tienen argumentos de distinto tipo) y hace la reducciÃ³n solo con los polinomios que tengan un \texttt{false} en la misma posiciÃ³n en el vector de booleanos. Esta funciÃ³n estÃ¡ para poder implementar la optimizaciÃ³n de ir eliminando algunos elementos de la base sin tener que estar modificando un vector.

\section{AmbigÃ¼edades}

Las ambigÃ¼edades, que son necesarias para el algoritmo de Buchberger, estÃ¡n implementadas en el archivo \texttt{ambiguities.hpp} y consisten en una estructura asÃ­:

\begin{minted}{C++}
  template<typename X>
  struct Amb {
    const Monomial<X>& p, q;
    enum Type { Inclusion, Overlap };
    Type type;
    size_t pos; // position where q starts in p
    Monomial<X> a, b;

    size_t size() const;
    Monomial<X> lm() const;
  };
\end{minted}

Los campos de la ambigÃ¼edad son:

\begin{itemize}
  \item \texttt{p} y \texttt{q} son referencias a los monomios sobre los cuales es la ambigÃ¼edad. El motivo por el cual se guardan en la estructura es para poder implementar una de las optimizaciones.
  \item \texttt{type} indica si la ambigÃ¼edad es de inclusiÃ³n o de superposiciÃ³n (recordar que todas las ambigÃ¼edades que se usan en el algoritmo de Buchberger son relevantes).
  \item \texttt{pos} es la posiciÃ³n de \texttt{p} donde empieza el pedazo que es en comÃºn con \texttt{q} y por la cual existe la ambigÃ¼edad.
  \item \texttt{a} y \texttt{b} son los monomios que hacen que en el caso de las de inclusiÃ³n \texttt{p} sea igual a \texttt{aqb} y en el caso de las de superposiciÃ³n \texttt{ap} sea igual a \texttt{qb}. % El producto acÃ¡ es medio raro, pero no se como hacerlo mejor
\end{itemize}

En el archivo tambiÃ©n estÃ¡ la funciÃ³n \texttt{ambiguities} que toma dos monomios y devuelve un vector de \texttt{Amb} con todas las ambigÃ¼edades entre esos dos monomios. En esta funciÃ³n, al igual que en la divisibilidad de monomios, se usa la funciÃ³n Z para evitar tener que hacer algo cuadrÃ¡tico en los largos de los monomios.

DespuÃ©s, en el archivo estÃ¡ la funciÃ³n \texttt{S\_poly} que toma una ambigÃ¼edad y dos polinomios que deberÃ­an ser los polinomios correspondientes y devuelve el S-polinomio correspondiente.

Y por Ãºltimo estÃ¡ la funciÃ³n \texttt{checkDeletionCriteria} que implementa la optimizaciÃ³n que permite descartar algunas ambigÃ¼edades sin tener que reducirlas.

\section{Buchberger}

Como ya se dijo antes, por el inconveniente de que el algoritmo puede no terminar, se usa una estructura con un mÃ©todo \texttt{next}. En esa estructura ya estÃ¡n implementadas las optimizaciones antes mencionadas, pero en esta secciÃ³n primero se explica cÃ³mo serÃ­a la estructura sin esas optimizaciones y despuÃ©s en la secciÃ³n \cref{secton:optimizaciones} se explica algo de cÃ³mo se agregan.

La base de esa estructura es asÃ­:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  struct BuchbergerIncremental {
    std::vector<Poly<K, X, ord>> G;
    std::queue<std::tuple<Amb<X>, size_t, size_t>> ambs;
    size_t t = 0;
    // â€¦ MÃ©todos
  };
\end{minted}

Los campos de esta estructura guardan lo siguiente:

\begin{itemize}
  \item \texttt{G} es la base de GrÃ¶bner que se estÃ¡ construyendo. Al principio se inicializa con los polinomios con los que se llama al constructor.
  \item \texttt{ambs} son las ambigÃ¼edades que todavÃ­a no se procesaron junto con los Ã­ndices en \texttt{G} de los polinomios a los que corresponde la ambigÃ¼edad. Se usa una cola para procesar siempre la que hace mÃ¡s tiempo estÃ¡ esperando.
  \item La variable \texttt{t} estÃ¡ porque como la base de GrÃ¶bner incluye a los polinomios originales, las primeras llamadas a \texttt{next} tienen que devolver esos polinomios y \texttt{t} indica cuÃ¡ntos de esos ya se devolvieron. Cuando \texttt{t} es igual al tamaÃ±o de \texttt{G} es porque ya se devolvieron todos esos.
\end{itemize}

La estructura ademÃ¡s de tener los mÃ©todos \texttt{next} y \texttt{fullBase} tiene varios mÃ©todos que se usan internamente. Entre todos los mÃ©todos son los siguientes: % Por todos los mÃ©todos me refiero a los ya mencionados y a los todavÃ­a no mencionados

\begin{itemize}
  \item \texttt{add\_amb}: Este mÃ©todo toma una ambigÃ¼edad y dos Ã­ndices, que son los Ã­ndices en \texttt{G} de los polinomios a los que corresponde la ambigÃ¼edad, y los agrega a la cola de ambigÃ¼edades. Siempre que hay que agregar una ambigÃ¼edad se hace con este mÃ©todo. El motivo por el cual esto estÃ¡ en un mÃ©todo propio es para despuÃ©s, al implementar la optimizaciÃ³n de descartar ambigÃ¼edades, poder hacerlo solo en este mÃ©todo.
  \item \texttt{add\_poly}: Este mÃ©todo agrega un polinomio a \texttt{G} agregando ademÃ¡s todas las nuevas ambigÃ¼edades que aparecen (llamando a \texttt{add\_amb}). Cada vez que hay que agregar un nuevo polinomio se usa este mÃ©todo, tanto al comienzo cuando se agregan los polinomios iniciales como cuando se agrega un S-polinomio reducido.
  \item \texttt{next}: Este es el mÃ©todo que corre el algoritmo. Lo principal que hace (despuÃ©s de usar la variable \texttt{t} para ver si tiene que devolver un elemento de \texttt{G}) es sacar ambigÃ¼edades de la cola hasta encontrar una que no se reduzca a $0$ y cuando la encuentra la agrega a la base (con \texttt{add\_poly}) y la devuelve. Si se acaban las ambigÃ¼edades devuelve vacÃ­o (recordar que devuelve \texttt{std::optional<Poly<K, ord>>}).
  \item \texttt{fullBase}: Simplemente llama a \texttt{next} en un ciclo hasta que devuelva vacÃ­o y despuÃ©s devuelve la base.
\end{itemize}

Lo de las optimizaciones se explica mÃ¡s adelante en la \cref{secton:optimizaciones}.


\section{F4}

F4 es un poco mÃ¡s complejo que Buchberger y tiene mÃ¡s partes, asÃ­ que esta secciÃ³n estÃ¡ dividida en varias subsecciones para las distintas partes.

\subsection{ReducciÃ³n por filas de matrices}

Para F4 hace falta hacer la reducciÃ³n por filas de una matriz. Para esto, en el archivo \texttt{matrix.cpp} se definiÃ³ un tipo matriz como un vector de vectores y una funciÃ³n \texttt{rref} que hace una eliminaciÃ³n gaussiana directamente y que funciona para cualquier \texttt{K}. Sin embargo, la reducciÃ³n por filas de una matriz es un tema ya muy analizado y hay algunas librerÃ­as que lo hacen para distintos tipos \texttt{K} mucho mÃ¡s rÃ¡pido.

Una librerÃ­a que hace la reducciÃ³n por filas es FLINT, que lo hace para el tipo \texttt{mpq\_class} de GMP que ya dijimos que son los nÃºmeros racionales \cite{lib:flint, lib:gmp}. Para usarla, en el archivo \texttt{matrix\_mpq\_class.hpp} hay una especializaciÃ³n de \texttt{rref} para \texttt{mpq\_class} (en \cpp una especializaciÃ³n es cuando hay cÃ³digo definido con un template y se hace una definiciÃ³n aparte para alguna combinaciÃ³n particular de parÃ¡metros del template).

Algo malo que tiene esa especializaciÃ³n es que las matrices de racionales con las que trabaja FLINT no estÃ¡n definidas como vectores de vectores, sino que son su propio tipo \texttt{fmpq\_mat\_t}, asÃ­ que la funciÃ³n tiene que primero copiar la matriz a una matriz de FLINT, despuÃ©s hacer la reducciÃ³n por filas y por Ãºltimo copiar el resultado de vuelta a la matriz original.

El motivo por el cual se hizo eso es que esas matrices de FLINT se usan de una forma muy particular y complicada. Por ejemplo, para asignarle un valor \texttt{x} de tipo \texttt{mpq\_class} a una posiciÃ³n de la matriz hay que hacer \texttt{fmpq\_set\_mpq(fmpq\_mat\_entry(mat, i, j), x.get\_mpq\_t());}. Esto hace que si se quisiera directamente en F4 trabajar con las matrices de FLINT no se podrÃ­a hacer el cÃ³digo genÃ©rico para cualquier \texttt{K}. Se probÃ³ tambiÃ©n hacer que las matrices sean una estructura propia y hacer una especializaciÃ³n de \texttt{Matrix<mpq\_class>} para que use \texttt{fmpq\_mat\_t} por dentro, pero andaba mas lento, asÃ­ que se descartÃ³.

\subsection{Preprocesamiento simbÃ³lico}

El preprocesamiento simbÃ³lico (\cref{alg:Preprocesamiento simbÃ³lico}) estÃ¡ implementado en el propio archivo \texttt{F4.hpp} en la funciÃ³n \texttt{symbolicPreprocessing}. La implementaciÃ³n es directa, asÃ­ que no hay mucho para comentar.

\subsection{ReducciÃ³n}

Como en F4 se reducen varios polinomios al mismo tiempo, se implementÃ³ una funciÃ³n \texttt{multiReduction} que toma dos vectores de polinomios, la base actual y los polinomios a reducir y los reduce todos a la vez.

En el \cref{alg:F4} esto se hizo dentro del propio algoritmo de F4 pero en la implementaciÃ³n se hizo aparte porque es bastante lo que tiene que hacer el cÃ³digo.

La implementaciÃ³n lo que hace es construir la matriz con una funciÃ³n llamada \texttt{toMatrix}, despuÃ©s llamar a la funciÃ³n \texttt{rref} que ya se explicÃ³, despuÃ©s marcar que columnas corresponden a monomios principales del vector por el cual se estÃ¡ reduciendo (esto para poder saber cuales polinomios son los reducidos) y por Ãºltimo convertir a polinomios las filas que su coeficiente principal (el primero no nulo de izquierda a derecha) no estÃ¡ marcada como que es un monomio principal del vector por el cual se estÃ¡ reduciendo.

\subsection{El propio F4}

La primera diferencia tiene que ver con la selecciÃ³n de ambigÃ¼edades. En Buchberger solo habÃ­a que elegir una ambigÃ¼edad, pero acÃ¡ hay que elegir varias. PodrÃ­a haber muchas formas de elegir, pero, como ya se dijo antes, una estrategia que funciona bien es elegir siempre todas las de menor grado. Para eso se hizo que las ambigÃ¼edades estÃ©n guardadas por grado en un vector, asÃ­:

\begin{minted}{C++}
  std::vector<std::vector<std::tuple<Amb<X>, size_t, size_t>>> ambs_per_deg;
\end{minted}

El otro lugar en el que hay diferencia, y mucha, es en \texttt{next}. En F4 este mÃ©todo lo que hace es, agarrar todas las ambigÃ¼edades de menor grado, poner todos los S-polinomios correspondientes en un vector, hacer la reducciÃ³n de esos polinomios con la funciÃ³n \texttt{multiReduction} y, si hay alguno que queda no nulo, agregar los polinomios reducidos a la base, agregando tambiÃ©n las nuevas ambigÃ¼edades que aparecen y devolver esos nuevos polinomios, y si quedan todos nulos pasar a las ambigÃ¼edades de grado siguiente. Si no quedan mÃ¡s grados de ambigÃ¼edades se devuelve vacÃ­o.

\section{Optimizaciones}\label{secton:optimizaciones}

Como ya se dijo varias veces, hay algunas optimizaciones que se pueden hacer en los algoritmos de Buchberger y F4, que estÃ¡n explicadas en la SecciÃ³n 4.5 de \cite{thesis:Hof20}. AcÃ¡ solo se van a explicar por arriba las optimizaciones y se va a explicar como estÃ¡n implementadas.

\subsection{Descartar ambigÃ¼edades}

La primer optimizaciÃ³n consiste en que se pueden descartar algunas ambigÃ¼edades, sin tener que reducir su S-polinomio, segÃºn si se cumplen ciertas propiedades con otros polinomios que ya estÃ¡n en la base.

En particular algunos teoremas de \cite{thesis:Hof20} permiten definir una funciÃ³n con la siguiente signatura:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  bool
  checkDeletionCriteria(
    std::vector<Poly<K, X, ord>>& G, Amb<X>& amb, size_t i, size_t j);
\end{minted}

Que toma la base, la ambigÃ¼edad y a que polinomios corresponde y devuelve \texttt{true} si y solo si esa ambigÃ¼edad se puede descartar sin reducirla.

Usando esa funciÃ³n, en el mÃ©todo \texttt{add\_amb} tanto de Buchberger como de F4, antes de agregar la ambigÃ¼edad, se agregÃ³ una llamada a \texttt{checkDeletionCriteria} para solo agregar la ambigÃ¼edad si da \texttt{false}.

\subsection{EliminaciÃ³n de polinomios}

La segunda optimizaciÃ³n consiste en que cuando se procesa una ambigÃ¼edad de inclusiÃ³n se puede borrar de la base al polinomio grande de la ambigÃ¼edad.

Para recordar, una ambigÃ¼edad de inclusiÃ³n entre los polinomio $f$ y $g$ es cuando se tiene que $\lm(f) = a \lm(g) b$ con $a, b âˆˆ âŸ¨XâŸ©$. Esta optimizaciÃ³n permite en esas ambigÃ¼edades borrar $f$ de la base.

Esta optimizaciÃ³n se implementÃ³ en Buchberger pero no en F4, porque por algÃºn motivo cuando se probÃ³ en F4 anduvo mÃ¡s lento. No se investigÃ³ por quÃ© pasÃ³ eso.

Para implementar esta optimizaciÃ³n en Buchberger lo que se hizo no es directamente borrar el polinomio de \texttt{G}, porque para eso habrÃ­a que tambiÃ©n cambiar los Ã­ndices que estÃ¡n guardados junto con las ambigÃ¼edades, sino que se agrego un vector de booleanos \texttt{removed} a la estructura, que tiene siempre el mismo largo que \texttt{G} y vale \texttt{true} solo en las posiciones de polinomios que se borraron. O sea que mÃ¡s bien se estÃ¡ marcando como borrados los polinomios.

A las funciones que se habÃ­an explicado, que toman a \texttt{G} como parÃ¡metro y se usan en Buchberger, se les agregÃ³ un parÃ¡metro extra que es el vector de booleanos y se hizo que solo trabajen con los polinomios de posiciones que no estÃ¡n en \texttt{true}.

\subsection{ReducciÃ³n mÃ¡s eficiente en F4}\label{subsection:ReducciÃ³n mÃ¡s eficiente en F4}

Como ya se dijo antes, para F4 tambiÃ©n hay otra optimizaciÃ³n que consiste en hacer la reducciÃ³n por filas de la matriz de forma mÃ¡s eficiente aprovechando la estructura particular que tienen las matrices de F4. Esta reducciÃ³n se llama reducciÃ³n FaugÃ¨re-Lachartre y estÃ¡ explicada en \cite{thesis:Hof20}.

Esta optimizaciÃ³n no se implementÃ³ principalmente por el poco soporte para trabajar con matrices de un cuerpo arbitrario, o de una implementaciÃ³n especÃ­fica de $â„š$, que hay en \cpp. Sin embargo, queda como trabajo futuro en la \cref{section:trabajos futuros}.

\section{RepresentaciÃ³n de cofactores}

Como se dijo en el capÃ­tulo anterior, la representaciÃ³n de cofactores se implementÃ³ solo para Buchberger, y no para F4. El motivo es que, como para F4 de cualquier manera no estÃ¡ implementada la optimizaciÃ³n de hacer la reducciÃ³n mÃ¡s eficiente, se va a tener que seguir trabajando en la parte de la reducciÃ³n y cuando se tenga lista la versiÃ³n mÃ¡s eficiente es el momento de implementar la representaciÃ³n de cofactores.

Como se explicÃ³ en la \cref{section:representaciÃ³n con cofectores (librerÃ­a)}, para la representaciÃ³n de cofactores se usa el tipo \texttt{CofactorPoly} que guarda polinomios de un ideal como combinaciÃ³n lineal de elementos de la base.

La estructura de la implementaciÃ³n de este tipo es asÃ­:

\begin{minted}{C++}
  template<typename K, typename X = __uint8_t, class ord = DegLexOrd<X>>
  struct CofactorPoly {
    std::vector<std::tuple<Monomial<X>, size_t, Monomial<X>, K>> terms;
    // â€¦ MÃ©todos
  };
\end{minted}

Y tiene definidas las operaciones de suma, resta y producto entre polinomios, al igual que con los polinomios normales. AdemÃ¡s tiene un mÃ©todo \texttt{add} para agregar una tupla monomio, Ã­ndice, monomio, coeficiente al polinomio.

A diferencia de los polinomios comunes, acÃ¡ \texttt{terms} no se mantiene ordenado de ninguna manera.

Con \texttt{CofactorPoly} se hizo la estructura \texttt{BuchbergerIncrementalCofactor}, que es muy parecida a \texttt{BuchbergerIncremental} pero con algunos agregados, y se hicieron versiones \texttt{Cofactor} de las funciones que se usan.

Para las reducciones se implementÃ³ una funciÃ³n que toma, por referencia, un polinomio $f$, reduce in place a su forma normal $f^*$ y devuelve la diferencia $f - f^*$ como un \texttt{CofactorPoly}. La signatura es:

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  CofactorPoly<K, X, ord>
  reduceCofactor(
    Poly<K, X, ord>& f, const std::vector<Poly<K, X, ord>>& G,
    const std::vector<CofactorPoly<K, X, ord>>& g_rec);
\end{minted}

TambiÃ©n se hizo una versiÃ³n de la funciÃ³n de los S-polinomios, que toma la ambigÃ¼edad y los polinomios correspondientes $f$ y $g$ y devuelve, ademÃ¡s del S-polinomio $p$, los los monomios $a$, $b$, $a'$ y $b'$ y los elementos del cuerpo $c$ y $c'$, que hacen que $p = c a f b + c' a' f b'$.

\begin{minted}{C++}
  template<typename K, typename X, class ord>
  std::tuple<
    Poly<K, X, ord>,
    std::tuple<Monomial<X>, Monomial<X>, K>,
    std::tuple<Monomial<X>, Monomial<X>, K>>
  S_polyCofactor(
    const Amb<X>& amb, const Poly<K, X, ord>& f, const Poly<K, X, ord>& g);
\end{minted}

Con esto, en la estructura \texttt{BuchbergerIncrementalCofactor} se agregÃ³ (con respecto a \texttt{BuchbergerIncremental}) un campo \texttt{std::vector<CofactorPoly<K, ord>> G\_rec} que guarda la representaciÃ³n de cofactores de cada polinomio de \texttt{G}.

En este campo \texttt{G\_rec}, a los elementos iniciales simplemente se los agrega como \texttt{{Monomial(), i, Monomial(), K(1)}} y a los elementos que vienen de un S-polinomio se les construye el \texttt{CofactorPoly} con los \texttt{CofactorPoly} de los polinomios que forman la ambigÃ¼edad multiplicados por los monomios y coeficientes que devuelve \texttt{S\_polyCofactor} y con el \texttt{CofactorPoly} de la reducciÃ³n que devuelve la funciÃ³n \texttt{reduceCofactor}.

\section{ComparaciÃ³n de bases de GrÃ¶bner}

La funciÃ³n \texttt{cmpBases} que se mencionÃ³ en la \cref{section:ComparaciÃ³n de bases de GrÃ¶bner (libreria)} que toma dos conjuntos generadores y asumiendo que son bases de GrÃ¶bner dice si generan el mismo ideal o no estÃ¡ implementada usando tal cual el \cref{col:(G) = (G') cond}.

\section{Paralelismo}

Cuando se va a paralelizar siempre es importante primero tratar de optimizar la versiÃ³n no paralela lo mÃ¡s posible. En este caso lo mejor no paralelo es el algoritmo F4, pero como no estÃ¡ implementada la optimizaciÃ³n de la reducciÃ³n eficiente, no estÃ¡ todavÃ­a optimizado al mÃ¡ximo. De cualquier manera, como la reducciÃ³n de matrices es solo una parte del algoritmo, se puede pensar cÃ³mo se podrÃ­a paralelizar el resto.

El mÃ©todo \texttt{add\_poly} que ya se explicÃ³ que agrega un polinomio a la base y las nuevas ambigÃ¼edades correspondientes, sin paralelizar se implementÃ³ asÃ­:

\begin{minted}{C++}
  void add_poly(const Poly<K, X, ord>& f) {
    G.push_back(f);
    for (size_t k = 0; k < G.size() - 1; k++) {
      for (auto& amb : ambiguities(G[k].lm(), f.lm())) {
        add_amb(amb, k, G.size() - 1);
      }
      for (auto& amb : ambiguities(f.lm(), G[k].lm())) {
        add_amb(amb, G.size() - 1, k);
      }
    }
  }
\end{minted}

Y el mÃ©todo \texttt{add\_amb} se implementÃ³ asÃ­:

\begin{minted}{C++}
  void add_amb(Amb<X>& amb, size_t i, size_t j) {
    if (checkDeletionCriteria(G, amb, i, j)) {
      return;
    }
    ambs.push({amb, i, j});
  }
\end{minted}

El primer \texttt{for} de \texttt{add\_poly} asÃ­ como estÃ¡ casi que se podrÃ­a paralelizar. Lo Ãºnico que lo impide es que \texttt{add\_amb} hace un \texttt{ambs.push} que serÃ­a problemÃ¡tico si se llega a ejecutar al mismo tiempo por mÃ¡s de un hilo. Para solucionar eso lo que se hizo es guardar las ambigÃ¼edades en varios vectores, uno por cada polinomio de \texttt{G} y despuÃ©s al final de la funciÃ³n agregar todas las ambigÃ¼edades a \texttt{ambs}. AsÃ­:

\begin{minted}{C++}
  void add_poly(Poly<K, X, ord>& f) {
    G.push_back(f);
    size_t lim = G.size() - 1;
    std::vector<std::vector<std::tuple<Amb<X>, size_t, size_t>>> to_add(lim);

    for (size_t k = 0; k < lim; k++) {
      for (auto& amb : ambiguities(G[k].lm(), G.back().lm())) {
        if (!checkDeletionCriteria(G, amb, k, lim)) {
          to_add[k].push_back({amb, k, lim});
        }
      }
      for (auto& amb : ambiguities(G.back().lm(), G[k].lm())) {
        if (!checkDeletionCriteria(G, amb, lim, k)) {
          to_add[k].push_back({amb, lim, k});
        }
      }
    }

    for (size_t k = 0; k < lim; k++) {
      for (auto& [amb, i, j] : to_add[k]) {
        size_t d = amb.size();
        while (ambs_per_deg.size() <= d) {
          ambs_per_deg.push_back({});
        }
        ambs_per_deg[d].push_back({amb, i, j});
      }
    }
  }
\end{minted}

Con esto el primer \texttt{for} se puede paralelizar directamente.

\subsection{Uso de OpenMP para paralelizar}

Para paralelizar se usÃ³ la librerÃ­a OpenMP \cite{lib:openmp}. Con OpenMP para que un \texttt{for} como el de \texttt{add\_poly} se corra en paralelo solo hace falta agregar en la lÃ­nea anterior \texttt{\#pragma omp parallel for}, asÃ­ que en el primer \texttt{for} de \texttt{add\_poly} se agrego eso en la linea anterior. En el \cref{cap:Benchmarks} se dan los datos de quÃ© tal anda.

\chapter{Tests}

Siempre que se programa, para que salga bien hay que testear todo, y este trabajo no fue una excepciÃ³n. A medida que se fue escribiendo el cÃ³digo se fueron haciendo tests del cÃ³digo para eliminar los bugs. AdemÃ¡s con algunos de los tests se hizo que hagan mediciones de tiempo para ver que tan rÃ¡pido andaba el cÃ³digo. Esto Ãºltimo se llama benchmarking. En esta secciÃ³n se explican los tests y en el siguiente capÃ­tulo los benchmarks que se hicieron.

Todos los tests estÃ¡n en la carpeta \texttt{test}, la cual estÃ¡ dividida en varias subcarpetas con varios tests cada una. Para correr todos los tests se puede usar el comando \texttt{make test}. En la carpeta \texttt{.github/workflows} estÃ¡ configurado para que al subir los cambios al repositorio se corran los tests automÃ¡ticamente, aunque eso no siempre funciona porque cuando se corren los tests en GitHub se tiene que instalar SageMath y a veces falla la instalaciÃ³n.

Algunos tests corren el cÃ³digo de la librerÃ­a y el cÃ³digo de \texttt{operator\_gb}, que es la librerÃ­a hecha por Clemens Hofstadler en su tesis de master \cite{thesis:Hof20} usando SageMath, y comparan los resultados, y otros corren solo cÃ³digo de la librerÃ­a.

TambiÃ©n, algunos tests corren los mains de ejemplo de la carpeta \texttt{mains} y otros directamente incluyen a los archivos de la librerÃ­a y los testean directamente.

A continuaciÃ³n una lista de lo mas importante de los test:

\begin{itemize}
  \item Hay tests de las operaciones bÃ¡sicas de monomios, polinomios, reducciÃ³n, etc. en la carpeta \texttt{test/internal\_tests}.
  \item Para algunos conjuntos generadores que se sabe que sus ideales generados tienen bases de GrÃ¶bner finitas hay un tests que calcula una base de GrÃ¶bner con Buchberger, una con F4 y una con \texttt{operator\_gb} y chequea que los resultados sean equivalentes usando \texttt{mains/compare\_bases.cpp}. Este archivo lo que hace es leer dos conjuntos generadores y, asumiendo que son bases de GrÃ¶bner, dice si generan el mismo ideal o no usando la funciÃ³n \texttt{cmpBases} explicada en la \cref{section:ComparaciÃ³n de bases de GrÃ¶bner (libreria)}. Esto test estÃ¡ en la carpeta \texttt{test/base\_tests}.
  \item Para algunos conjuntos generadores construidos al azar se construye otro polinomio tambiÃ©n al azar y tanto con Buchberger como con F4 y con \texttt{operator\_gb} se ejecutan algunos pasos del cÃ¡lculo de la base de GrÃ¶bner para ver si estÃ¡ el polinomio en el ideal o no. Si alguno(s) de los tres da que si estÃ¡ en el ideal y otro(s) no, se ejecutan los que no con muchÃ­simos mÃ¡s pasos, para que tenga que terminar si o si porque por los que dieron que si sabemos que (si no hay bugs) si estÃ¡. Esto estÃ¡ en la carpeta \texttt{test/InIdeal\_tests}. % Esto me parece que no se entiende nada, pero no se como explicarlo.
  \item Con respecto a la representaciÃ³n de cofactores, hay un test que corre los algoritmos con y sin representaciÃ³n de cofactores y se fija que el resultado de con cofactores despuÃ©s de convertir los \texttt{CofactorPoly} en \texttt{Poly} sea igual al resultado sin cofactores. Este test estÃ¡ en la carpeta \texttt{test/cofactor\_tests}.
  \item Por Ãºltimo hay un test que corre F4 no paralelo y paralelo con distintas cantidades de hilos y se fija que siempre de el mismo resultado. Esto estÃ¡ en la carpeta \texttt{test/parallelism\_tests}.
\end{itemize}

\chapter{Benchmarks}\label{cap:Benchmarks}

En este capÃ­tulo se presentan los resultados obtenidos tras correr los tests que incluyen benchmarks. Las corridas se hicieron en la computadora `atom' de FAMAF que tiene las siguientes caracterÃ­sticas:

\begin{itemize}
  \item Procesador: AMD EPYC 7643 48-Core Processor
  \item RAM: 126 GB
\end{itemize}

De cualquier manera esos datos no son muy importantes porque lo importante son las relaciones entre los distintos tiempos.

Los tests que tienen benchmarks son, todos salvo uno, tests que usan los mains de la carpeta \texttt{mains} y mains hechos en Python con \texttt{operator\_gb} y son corridos con distintas entradas desde un archivo de Python. Los tiempos en casi todos se miden desde el programa de Python, asÃ­ que incluyen el tiempo hasta que se inicializa el programa y lee la entrada y el tiempo de impresiÃ³n de la salida, pero como son siempre entradas y salidas relativamente chicas eso no deberÃ­a ser problema.

Todos los tests que tienen benchmarks, salvo uno, funcionan tomando como input un conjunto generador que se sabe que el ideal generado tiene una base de GrÃ¶bner finita. Para estos benchmarks se usaron los siguientes conjuntos generadores:

\begin{itemize}
  \item FK2 $ = \{a^2\}$
  \item FK3 $ = \{a^2,\ b^2,\ c^2,\ ac + ba + cb,\ ab + bc + ca\}$
  \item FK4 $ = \{a^2,\ b^2,\ c^2,\ d^2,\ e^2,\ f^2,\ ac + ba + cb,\ ae + da + ed,\ bf + db + fd,\ cf + ec + fe,\ ab + bc + ca,\ ad + de + ea,\ bd + df + fb,\ ce + ef + fc,\ cd + dc,\ be + eb,\ af + fa\}$
  \item tri1 $ = \{a^2 - 1,\ b^3 - 1,\ {(ababab^2ab^2)}^2 - 1\}$
  \item tri2 $ = \{a^2 - 1,\ b^3 - 1,\ {(ababab^2)}^3 - 1\}$
  \item tri3 $ = \{a^3 - 1,\ b^3 - 1,\ {(abab^2)}^2 - 1\}$
  \item tri4 $ = \{a^3 - 1,\ b^3 - 1,\ {(abaab^2)}^2 - 1\}$
  \item tri5 $ = \{a^2 - 1,\ b^5 - 1,\ {(abab^2)}^2 - 1\}$
  \item tri6 $ = \{a^2 - 1,\ b^5 - 1,\ {(ababab^4)}^2 - 1\}$
  \item tri7 $ = \{a^2 - 1,\ b^5 - 1,\ {(abab^2ab^4)}^2 - 1\}$
  \item tri8 $ = \{a^2 - 1,\ b^2 - 1,\ {(ababab^3)}^2 - 1\}$
  \item tri9 $ = \{a^2 - 1,\ b^3 - 1,\ {(abab^2)}^2 - 1\}$
  \item tri10 $ = \{a^2 - 1,\ b^3 - 1,\ {(ababab^2)}^2 - 1\}$
  \item tri11 $ = \{a^2 - 1,\ b^3 - 1,\ {(abababab^2)}^2 - 1\}$
  \item tri12 $ = \{a^2 - 1,\ b^3 - 1,\ {(ababab^2abab^2)}^2 - 1\}$
  \item tri13 $ = \{a^2 - 1,\ b^3 - 1,\ {(babababab^2ab^2)}^2 - 1\}$
  \item trit3 $ = \{a^3 - 1,\ b^3 - 1,\ c^3 - 1,\ {(ab)}^2 - 1,\ {(ac)}^2 - 1,\ {(bc)}^2 - 1\}$
  \item trit4 $ = \{a^3 - 1,\ b^3 - 1,\ c^4 - 1,\ {(ab)}^2 - 1,\ {(ac)}^2 - 1,\ {(bc)}^2 - 1\}$
  \item trit5 $ = \{a^3 - 1,\ b^3 - 1,\ c^5 - 1,\ {(ab)}^2 - 1,\ {(ac)}^2 - 1,\ {(bc)}^2 - 1\}$
\end{itemize}

Los FK provienen de la teorÃ­a de Ã¡lgebras de Nichols, las cuales son de interÃ©s para Cristian Vay, el director de esta tesis, y otros investigadores de FAMAF. Los FK definen algo que se llama Ã¡lgebras de Fomin-Kirillov y son una familia infinita parametrizada por un $n âˆˆ â„•$, que fijando el $n$ se describe a continuaciÃ³n.

\begin{itemize}
  \item El cuerpo es $â„š$.
  \item El alfabeto es $\{x_{ij} : i, j âˆˆ \{1, â€¦, n\} : i â‰  j\}$, donde los $_{ij}$ son un par no ordenado.
  \item El conjunto generador es:
  \begin{align*}
    & \{ x_{ij}Â² : i, j âˆˆ \{1, â€¦, n\} : i â‰  j \} \\
    & âˆª \{ x_{ij} x_{ik} + x_{ik} x_{jk} + x_{jk} x_{ij} : i, j, k âˆˆ \{1, â€¦, n\} : i â‰  j â‰  k â‰  i \} \\
    & âˆª \{ x_{ik} x_{ij} + x_{jk} x_{ik} + x_{ij} x_{jk} : i, j, k âˆˆ \{1, â€¦, n\} : i â‰  j â‰  k â‰  i \} \\
    & âˆª \{ x_{ij} x_{kl} + x_{kl} x_{ij} : i, j, k, l âˆˆ \{1, â€¦, n\} : i â‰  j âˆ§ k â‰  l \} \text{.}
  \end{align*}
\end{itemize}

\noindent Se sabe que para $n â‰¤ 5$ los ideales generados por FK$n$ tienen bases de GrÃ¶bner finitas, pero para $n > 5$ no se sabe. En \cite{web:Nichols} y \cite{book:introNichols} se puede encontrar mas informaciÃ³n sobre las Ã¡lgebras de Nichols.

Los tri estÃ¡n porque \cite{thesis:Hof20} los usa, con ese mismo nombre, y Ã©l los sacÃ³ del Teorema 2.12 de \cite{book:class-tri}. Los trit son directamente tomados de la ProposiciÃ³n 1.9 de \cite{book:class-tri}.

En todos los benchmarks que usan estos conjuntos se trabaja sobre los racionales, porque es para los racionales que se sabe que tienen bases finitas.

En las siguientes subsecciones se presentan los resultados de cada uno de los benchmarks.

\section{Ideales con bases de GrÃ¶bner finitas}\label{section:Ideales con bases de GrÃ¶bner finitas}

El test que usa los distintos algoritmos para calcular bases de GrÃ¶bner de ideales que se sabe que tienen bases de GrÃ¶bner finitas incluye mediciones de los tiempos y usa los casos que vimos reciÃ©n.

En el siguiente grÃ¡fico se muestran los tiempos de ejecuciÃ³n de Buchberger de esta tesis (\texttt{Buchberger}), de F4 de esta tesis (\texttt{F4}) y de \texttt{operator\_gb} (que usa F4) para esos casos.

\noindent \begin{tikzpicture}
  \begin{axis}[
      ybar = 0.5pt, % Tipo de grÃ¡fico: barras verticales
      width = \textwidth,
      height = 0.4\textwidth,
      bar width = 0.01\textwidth, % Ancho de cada barra
      symbolic x coords = {FK2, FK3, FK4, tri1, tri2, tri3, tri4, tri5, tri6, tri7, tri8, tri9, tri10, tri11, tri12, tri13, trit3, trit4, trit5}, % Etiquetas en el eje x
      xtick = data, % Mostrar marcas en el eje x para cada dato
      ylabel = {Tiempo en segundos}, % Etiqueta del eje y
      %xlabel = {CategorÃ­as}, % Etiqueta del eje x
      xticklabel style = {rotate = 45}, % Rotar etiquetas
      ymin = 0, % MÃ­nimo del eje y
      ymax = 215,
      enlarge x limits = 0.03, % Espaciado en los bordes
      legend style = {at = {(0.024, 0.94)}, anchor = north west}, % Estilo de la leyenda
      legend entries = {\texttt{Buchberger}, \texttt{F4}, \texttt{operator\_gb}}, % Entradas de la leyenda
      cycle list = {{brown,fill = brown!30}, {red,fill = red!30}, {blue,fill = blue!30}}, % Colores
  ]
    % Datos para cada conjunto
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.01) (tri1, 0.26) (tri10, 0.01) (tri11, 0.03) (tri12, 3.27) (tri13, 0.01) (tri2, 6.01) (tri3, 0.02) (tri4, 0.04) (tri5, 0.01) (tri6, 6.53) (tri7, 33.33) (tri8, 0.09) (tri9, 0.00) (trit3, 0.01) (trit4, 0.14) (trit5, 77.16)};
    \addplot coordinates {(FK2, 0.01) (FK3, 0.01) (FK4, 0.08) (tri1, 0.08) (tri10, 0.01) (tri11, 0.02) (tri12, 0.21) (tri13, 0.01) (tri2, 0.29) (tri3, 0.04) (tri4, 0.07) (tri5, 0.02) (tri6, 1.78) (tri7, 1.81) (tri8, 0.06) (tri9, 0.01) (trit3, 0.05) (trit4, 0.49) (trit5, 207.84)};
    \addplot coordinates {(FK2, 1.70) (FK3, 0.80) (FK4, 0.87) (tri1, 0.98) (tri10, 0.85) (tri11, 0.88) (tri12, 1.04) (tri13, 0.83) (tri2, 1.16) (tri3, 0.90) (tri4, 0.94) (tri5, 0.87) (tri6, 1.27) (tri7, 1.45) (tri8, 0.91) (tri9, 0.82) (trit3, 0.87) (trit4, 1.04) (trit5, 5.21)};
  \end{axis}
\end{tikzpicture}

A simple vista se puede ver que para los casos en los que se distinguÃ© algo \texttt{operator\_gb} es mucho mÃ¡s rÃ¡pido, pero solo se ven los casos que demoran mucho tiempo, los otros no. AsÃ­ que a continuaciÃ³n estÃ¡ el grÃ¡fico de vuelta pero solo con la parte de mas abajo y dejando que las barras muy largas se salgan del grÃ¡fico.

\noindent \begin{tikzpicture}
  \begin{axis}[
      ybar = 0.5pt, % Tipo de grÃ¡fico: barras verticales
      width = \textwidth,
      height = 0.4\textwidth,
      bar width = 0.01\textwidth, % Ancho de cada barra
      symbolic x coords = {FK2, FK3, FK4, tri1, tri2, tri3, tri4, tri5, tri6, tri7, tri8, tri9, tri10, tri11, tri12, tri13, trit3, trit4, trit5}, % Etiquetas en el eje x
      xtick = data, % Mostrar marcas en el eje x para cada dato
      ylabel = {Tiempo en segundos}, % Etiqueta del eje y
      %xlabel = {CategorÃ­as}, % Etiqueta del eje x
      xticklabel style = {rotate = 45}, % Rotar etiquetas
      ymin = 0, % MÃ­nimo del eje y
      ymax = 10,
      enlarge x limits = 0.03, % Espaciado en los bordes
      legend style = {at = {(0.024, 0.94)}, anchor = north west}, % Estilo de la leyenda
      legend entries = {\texttt{Buchberger}, \texttt{F4}, \texttt{operator\_gb}}, % Entradas de la leyenda
      cycle list = {{brown,fill = brown!30}, {red,fill=red!30}, {blue,fill=blue!30}}, % Colores
  ]
    % Datos para cada conjunto
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.01) (tri1, 0.26) (tri10, 0.01) (tri11, 0.03) (tri12, 3.27) (tri13, 0.01) (tri2, 6.01) (tri3, 0.02) (tri4, 0.04) (tri5, 0.01) (tri6, 6.53) (tri7, 33.33) (tri8, 0.09) (tri9, 0.00) (trit3, 0.01) (trit4, 0.14) (trit5, 77.16)};
    \addplot coordinates {(FK2, 0.01) (FK3, 0.01) (FK4, 0.08) (tri1, 0.08) (tri10, 0.01) (tri11, 0.02) (tri12, 0.21) (tri13, 0.01) (tri2, 0.29) (tri3, 0.04) (tri4, 0.07) (tri5, 0.02) (tri6, 1.78) (tri7, 1.81) (tri8, 0.06) (tri9, 0.01) (trit3, 0.05) (trit4, 0.49) (trit5, 207.84)};
    \addplot coordinates {(FK2, 1.70) (FK3, 0.80) (FK4, 0.87) (tri1, 0.98) (tri10, 0.85) (tri11, 0.88) (tri12, 1.04) (tri13, 0.83) (tri2, 1.16) (tri3, 0.90) (tri4, 0.94) (tri5, 0.87) (tri6, 1.27) (tri7, 1.45) (tri8, 0.91) (tri9, 0.82) (trit3, 0.87) (trit4, 1.04) (trit5, 5.21)};
  \end{axis}
\end{tikzpicture}

AcÃ¡ se puede ver que en los casos mÃ¡s chiquitos si pasa que \texttt{Buchberger} y \texttt{F4} le ganan a \texttt{operator\_gb}. Que en los grandes gane \texttt{operator\_gb} tiene sentido por el hecho de que tiene implementada la optimizaciÃ³n de reducir las matrices mas eficientemente. Que en los chicos \texttt{Buchberger} y \texttt{F4} sean mÃ¡s rÃ¡pido tambiÃ©n tiene sentido por el hecho de que \cpp es mucho mÃ¡s rÃ¡pido que Python.

\section{Paralelismo}

El test que prueba que de el mismo resultado correr con distintas cantidades de hilos tambiÃ©n usa los mismos casos y mide los tiempos. En el siguiente grÃ¡fico se pueden ver los resultados.

\noindent \begin{tikzpicture}
  \begin{axis}[
      ybar = 0.5pt, % Tipo de grÃ¡fico: barras verticales
      width = \textwidth,
      height = 0.4\textwidth,
      bar width = 0.003\textwidth,
      symbolic x coords = {FK2, FK3, FK4, tri1, tri2, tri3, tri4, tri5, tri6, tri7, tri8, tri9, tri10, tri11, tri12, tri13, trit3, trit4, trit5}, % Etiquetas en el eje x
      xtick = data, % Mostrar marcas en el eje x para cada dato
      ylabel = {Tiempo en segundos}, % Etiqueta del eje y
      %xlabel = {Cantidad de hilos}, % Etiqueta del eje x
      xticklabel style = {rotate = 45}, % Rotar etiquetas
      ymin = 0, % MÃ­nimo del eje y
      ymax = 215, % MÃ¡ximo del eje y
      enlarge x limits = 0.03, % Espaciado en los bordes
      legend style = {at = {(0.024, 0.94)}, anchor = north west}, % Estilo de la leyenda
      legend entries = {1, 2, 4, 6, 8, 16}, % Entradas de la leyenda
  ]
    % Datos para cada conjunto
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.10) (tri10, 0.01) (tri11, 0.02) (tri12, 0.32) (tri13, 0.01) (tri2, 0.53) (tri3, 0.03) (tri4, 0.07) (tri5, 0.01) (tri6, 2.20) (tri7, 2.19) (tri8, 0.07) (tri9, 0.00) (trit3, 0.04) (trit4, 0.47) (trit5, 213.58)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.08) (tri10, 0.01) (tri11, 0.02) (tri12, 0.28) (tri13, 0.00) (tri2, 0.42) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.98) (tri7, 2.02) (tri8, 0.06) (tri9, 0.00) (trit3, 0.04) (trit4, 0.47) (trit5, 212.76)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.07) (tri10, 0.01) (tri11, 0.01) (tri12, 0.22) (tri13, 0.00) (tri2, 0.36) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.82) (tri7, 1.92) (tri8, 0.06) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45) (trit5, 209.93)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.22) (tri13, 0.01) (tri2, 0.32) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.86) (tri7, 1.84) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45) (trit5, 212.14)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.20) (tri13, 0.00) (tri2, 0.31) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.83) (tri7, 1.81) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45) (trit5, 208.28)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.20) (tri13, 0.00) (tri2, 0.29) (tri3, 0.03) (tri4, 0.05) (tri5, 0.01) (tri6, 1.79) (tri7, 1.80) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.46) (trit5, 208.62)};
  \end{axis}
\end{tikzpicture}

De vuelta a simple vista no se ve casi nada, salvo que en trit5 es caso lo mismo con mas hilos. Para poder ver en mas detalla, a continuaciÃ³n un grÃ¡fico de lo mismo pero sin trit5.

\noindent \begin{tikzpicture}
  \begin{axis}[
      ybar = 0.5pt, % Tipo de grÃ¡fico: barras verticales
      width = \textwidth,
      height = 0.4\textwidth,
      bar width = 0.003\textwidth,
      symbolic x coords = {FK2, FK3, FK4, tri1, tri2, tri3, tri4, tri5, tri6, tri7, tri8, tri9, tri10, tri11, tri12, tri13, trit3, trit4}, % Etiquetas en el eje x
      xtick = data, % Mostrar marcas en el eje x para cada dato
      ylabel = {Tiempo en segundos}, % Etiqueta del eje y
      %xlabel = {Cantidad de hilos}, % Etiqueta del eje x
      xticklabel style = {rotate = 45}, % Rotar etiquetas
      ymin = 0, % MÃ­nimo del eje y
      ymax = 2.5, % MÃ¡ximo del eje y
      enlarge x limits = 0.03, % Espaciado en los bordes
      legend style = {at = {(0.024, 0.94)}, anchor = north west}, % Estilo de la leyenda
      legend entries = {1, 2, 4, 6, 8, 16}, % Entradas de la leyenda
  ]
    % Datos para cada conjunto
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.10) (tri10, 0.01) (tri11, 0.02) (tri12, 0.32) (tri13, 0.01) (tri2, 0.53) (tri3, 0.03) (tri4, 0.07) (tri5, 0.01) (tri6, 2.20) (tri7, 2.19) (tri8, 0.07) (tri9, 0.00) (trit3, 0.04) (trit4, 0.47)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.08) (tri10, 0.01) (tri11, 0.02) (tri12, 0.28) (tri13, 0.00) (tri2, 0.42) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.98) (tri7, 2.02) (tri8, 0.06) (tri9, 0.00) (trit3, 0.04) (trit4, 0.47)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.07) (tri10, 0.01) (tri11, 0.01) (tri12, 0.22) (tri13, 0.00) (tri2, 0.36) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.82) (tri7, 1.92) (tri8, 0.06) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.06) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.22) (tri13, 0.01) (tri2, 0.32) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.86) (tri7, 1.84) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.20) (tri13, 0.00) (tri2, 0.31) (tri3, 0.03) (tri4, 0.06) (tri5, 0.01) (tri6, 1.83) (tri7, 1.81) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.45)};
    \addplot coordinates {(FK2, 0.00) (FK3, 0.00) (FK4, 0.07) (tri1, 0.06) (tri10, 0.01) (tri11, 0.01) (tri12, 0.20) (tri13, 0.00) (tri2, 0.29) (tri3, 0.03) (tri4, 0.05) (tri5, 0.01) (tri6, 1.79) (tri7, 1.80) (tri8, 0.05) (tri9, 0.00) (trit3, 0.04) (trit4, 0.46)};
  \end{axis}
\end{tikzpicture}

Se puede ver que aumentar los hilos hace que sea un poco mÃ¡s rÃ¡pido, pero muy poco. Esto tiene sentido por el hecho de que solo la parte de agregar ambigÃ¼edades estÃ¡ paralelizada.

\section{RepresentaciÃ³n de cofactores}

El test que compara ejecutar Buchberger con y sin representaciÃ³n de cofactores tambiÃ©n usa los mismos casos y mide los tiempos. Este es el Ãºnico benchmark que no funciona con mains de la carpeta \texttt{mains} si no que usa sus propios archivo, y ademÃ¡s este benchmark mide los tiempos desde \cpp. En el siguiente grÃ¡fico se pueden ver los resultados.

\noindent \begin{tikzpicture}
  \begin{axis}[
      ybar = 0.5pt, % Tipo de grÃ¡fico: barras verticales
      width = \textwidth,
      height = 0.4\textwidth,
      bar width = 0.015\textwidth, % Ancho de cada barra
      symbolic x coords = {FK2, FK3, FK4, tri1, tri2, tri3, tri4, tri5, tri6, tri7, tri8, tri9, tri10, tri11, tri12, tri13, trit3, trit4, trit5}, % Etiquetas en el eje x
      xtick = data, % Mostrar marcas en el eje x para cada dato
      ylabel = {Tiempo en segundos}, % Etiqueta del eje y
      %xlabel = {CategorÃ­as}, % Etiqueta del eje x
      xticklabel style = {rotate = 45}, % Rotar etiquetas
      ymin = 0, % MÃ­nimo del eje y
      %ymax = 215,
      enlarge x limits = 0.03, % Espaciado en los bordes
      legend style = {at = {(0.024, 0.94)}, anchor = north west}, % Estilo de la leyenda
      legend entries = {Normal, RepresentaciÃ³n de cofactores}, % Entradas de la leyenda
  ]
    % Datos para cada conjunto
    \addplot coordinates {(FK2, 0.0) (FK3, 0.0) (FK4, 0.007) (tri1, 0.238) (tri10, 0.006) (tri11, 0.026) (tri12, 2.99) (tri13, 0.005) (tri2, 5.497) (tri3, 0.016) (tri4, 0.03) (tri5, 0.006) (tri6, 5.929) (tri7, 30.415) (tri8, 0.083) (tri9, 0.0) (trit3, 0.008) (trit4, 0.126) (trit5, 70.421)};
    \addplot coordinates {(FK2, 0.0) (FK3, 0.0) (FK4, 0.011) (tri1, 0.383) (tri10, 0.007) (tri11, 0.035) (tri12, 4.26) (tri13, 0.016) (tri2, 8.544) (tri3, 0.022) (tri4, 0.052) (tri5, 0.009) (tri6, 7.749) (tri7, 101.729) (tri8, 0.113) (tri9, 0.001) (trit3, 0.011) (trit4, 0.173) (trit5, 94.521)};
  \end{axis}
\end{tikzpicture}

Se puede ver que la representaciÃ³n de cofactores lleva mÃ¡s tiempo, pero en general no tanto mÃ¡s. AcÃ¡ no hay demasiado mÃ¡s para ver mirando solo la parte de abajo, asÃ­ que no se hace un grÃ¡fico con la parte de mÃ¡s abajo.

\section{Pertenencia a ideales}

El test que para conjuntos generadores construidos al azar y polinomios construidos al azar ve con los distintos algoritmos si el polinomio estÃ¡ en el ideal generado o no, tambiÃ©n mide los tiempos. Estos corren tanto para los racionales como para la aritmÃ©tica modular, pero para los raciones incluyen la comparaciÃ³n con \texttt{operator\_gb} y para la aritmÃ©tica modular no, porque \texttt{operator\_gb} es solo para racionales. Este benchmark imprime los tiempos promedios sobre todos los conjuntos generadores construidos al azar y polinomios construidos al azar y tambiÃ©n los tiempos mÃ¡ximos. Estos son los resultados para los racionales (tal cual los imprime el test, \texttt{Buch} es \texttt{Buchberger} y \texttt{GB} es \texttt{operator\_gb}):

\begin{minted}{text}
  Average times:
  Buch: 0.0041429424s
  F4: 0.0105502963s
  GB: 0.8995876765s
  Max times:
  Buch: 0.1320753098s
  F4: 0.0925185680s
  GB: 4.6477575302s
\end{minted}

Y estos para la aritmÃ©tica modular (tambiÃ©n tal cual los imprime el test):

\begin{minted}{text}
  Average times:
  Buch_Zp: 0.0028817248s
  F4_Zp: 0.0072190428s
  Max times:
  Buch_Zp: 0.0779249668s
  F4_Zp: 0.0799708366s
\end{minted}

Estos datos igualmente mucho no dicen, porque como buscan por una cierta cantidad de pasos, y los pasos son distintos en los distintos algoritmos, no se puede comparar. En particular, un paso de \texttt{F4} puede corresponder a muchos pasos de \texttt{Buchberger}.

Este benchmark se usÃ³ principalmente para tenerlo como comparaciÃ³n cuando se hacÃ­an cambios en el cÃ³digo. Como se corrÃ­an siempre todos los tests y benchmarks antes y despuÃ©s del cambio, este servÃ­a para comparar el antes y el despuÃ©s.

\chapter{Conclusiones}

El tema de este trabajo fue propuesto por el director Cristian Vay por su interÃ©s ya mencionado de usarlo para las Ã¡lgebras de Nichols. Para mi este era un tema completamente nuevo, asÃ­ que empece por estudiar el tema. Primero leyendo \cite{book:ideals-varieties-algorithms} que trata sobre bases de GrÃ¶bner conmutativas, mientras leÃ­a ese libro hice tambiÃ©n una implementaciÃ³n asÃ­ nomÃ¡s de bases de GrÃ¶bner conmutativas en \cpp. Esto fue bueno porque me sirviÃ³ de prÃ¡ctica para despuÃ©s hacer la implementaciÃ³n de bases de GrÃ¶bner no conmutativas. DespuÃ©s de eso fui leyendo \cite{thesis:Hof20} y \cite{phdthesis:Hof23}, que son sobre bases de GrÃ¶bner no conmutativas, e implementando lo explicado.

A continuaciÃ³n menciono algunas cosas positivas y despuÃ©s algunos posibles trabajos futuros.

\section{Cosas positivas este trabajo}

Es la primer implementaciÃ³n de bases de GrÃ¶bner no conmutativas en \cpp (que yo sepa). Esto es muy bueno porque \cpp es un lenguaje particularmente rÃ¡pido y en el que es fÃ¡cil paralelizar. Esto es Ãºtil si se quieren correr casos que se demoran mucho.

Es la primer implementaciÃ³n de F4 que funciona para un cuerpo arbitrario (que yo sepa). Esto estÃ¡ bueno para que si en algÃºn momento alguien lo quiere usar para algÃºn cuerpo distinto lo pueda hacer.

La implementaciÃ³n de Buchberger incluye la parte de la construcciÃ³n de la respuesta, que si bien es algo muy fÃ¡cil, la Ãºnica otra implementaciÃ³n que lo hace es \texttt{operator\_gb} (que yo sepa).

\section{Trabajos futuros}\label{section:trabajos futuros}

Como ya se dijo varias veces, falta usar la reducciÃ³n por filas de FaugÃ¨re-Lachartre que es mÃ¡s eficiente, y esa es una de las cosas mÃ¡s importantes para hacer.

Del algoritmo F4 (y de Buchberger) para el caso si conmutativo hay varias implementaciones en \cpp, por ejemplo \cite{lib:openf4, lib:mathic, lib:M4GB}, inclusive en paralelo, como \cite{DBLP:journals/jsc/Reeves98, lib:parallelGBC}. Muchas son solo para los enteros mÃ³dulo un primo, pero hay algunas que tambiÃ©n para los racionales. Es muy probable que analizando esas implementaciones se puedan sacar muchas cosas Ãºtiles, en particular, podrÃ­a ser que ya alguien haya hecho la implementaciÃ³n de la reducciÃ³n por filas de FaugÃ¨re-Lachartre, ya que posiblemente sirva tambiÃ©n para el caso no conmutativo.

Cuando se fue haciendo la librerÃ­a, muchas veces pasaba que habÃ­a cambios que parecÃ­an optimizaciones pero al hacerlos el cÃ³digo resultaba andar mas lento, asÃ­ que se descartaban esos cambios. SerÃ­a bueno agregar mas test y probar hacer cambios para ver si mejoran o no los tiempos teniendo mÃ¡s tests.

Se podrÃ­a analizar cuanto tiempo se consume en las distintas partes de los algoritmos, porque eso podrÃ­a ayudar a saber en que partes se pueden realizar a optimizaciones.

En la librerÃ­a hay una especializaciÃ³n de \texttt{rref} para hacer que para \texttt{mpq\_class} sea mÃ¡s rÃ¡pido, pero para aritmÃ©tica modular se estÃ¡ usando un tipo propio definido en el archivo \texttt{extras/ModularArithmetic.hpp} y se usa la versiÃ³n genÃ©rica de \texttt{rref}. Es posible que ya haya librerÃ­as que tengan tipos de aritmÃ©tica modular mÃ¡s rÃ¡pidos que el que se implementÃ³ y con una reducciÃ³n por filas mÃ¡s rÃ¡pida.

Actualmente la librerÃ­a no viene con nada para instalarla automÃ¡ticamente porque en \cpp eso no es fÃ¡cil de hacer. Esto significa que si alguien quiere usar la librerÃ­a tiene que arreglÃ¡rselas y probablemente hacer algo medio feo como poner los archivos en alguna carpeta particular. Otros librerÃ­as de \cpp si vienen con algo para eso, asÃ­ que serÃ­a bueno hacerlo para esta librerÃ­a tambiÃ©n.

AdemÃ¡s de los ideales de la \cref{def:ideal} existen los ideales a izquierda que se definen de la siguiente manera.
\begin{definition}
  Sean $R$ un anillo e $I âŠ† R$. Se define que $I$ es un ideal a izquierda de $R$ si y solo si:
  \begin{enumerate}
    \item $I â‰  âˆ…$.
    \item $âˆ€a, b âˆˆ I : a + b âˆˆ I$.
    \item $âˆ€a âˆˆ I, r âˆˆ R : r a âˆˆ I$.
  \end{enumerate}
\end{definition}
\noindent Con los ideales a izquierda sobre polinomios no conmutativos tambiÃ©n hay toda una teorÃ­a de bases de GrÃ¶bner. En \cite{phdthesis:Hof23} se puede encontrar una explicaciÃ³n sobre esta teorÃ­a. Implementar el cÃ¡lculo de bases de GrÃ¶bner de la teorÃ­a de ideales a izquierda en \cpp es otro trabajo que se podrÃ­a hacer. AnÃ¡logamente, tambiÃ©n se pueden considerar ideales a derecha.

Como ya se mencionÃ³ en el \cref{cap:Benchmarks}, los FK$n$ no se sabe para $n â‰¥ 6$ si tienen una base finita o no. Cuando se tenga una versiÃ³n muy buena de F4 algo que se podrÃ­a hacer es correrla por mucho tiempo para FK6 u otros FK para ver si llega en algÃºn momento a una base finita.

Actualmente para estudiar el tema de bases de GrÃ¶bner, tanto conmutativas cono no conmutativas, hay libros y artÃ­culos sobre el tema, en particular \cite{book:ideals-varieties-algorithms} para conmutativas y \cite{thesis:Hof20} para no conmutativas, pero para practicar las implementaciones no hay mucha ayuda. Por ejemplo, cuando implementÃ© las bases de GrÃ¶bner conmutativas para practicar tubo que hacer su propio testing. Para que estudiar el tema sea mÃ¡s fÃ¡cil algo que serÃ­a Ãºtil es preparar problemas del estilo de programaciÃ³n competitiva sobre el tema. Estos problemas se podrÃ­an poner en, por ejemplo, \href{https://judge.yosupo.jp}{Library Checker}, o en un grupo de \href{https://codeforces.com}{Codeforces}.

Por Ãºltimo, otra cosa que se podrÃ­a hacer es implementar el calculo de bases de GrÃ¶bner no conmutativas en otros lenguajes como por ejemplo Rust.

\chapter{BibliografÃ­a}

\printbibliography[heading=none]

\end{document}
