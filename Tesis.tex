\documentclass{report}

\usepackage{polyglossia}
\setdefaultlanguage{spanish}

\usepackage{amsthm}
\usepackage{fontspec}
\usepackage{enumitem}
\usepackage[bookmarks]{hyperref}
\defaultfontfeatures{Renderer=Basic,Ligatures={TeX}}
\usepackage[math-style=ISO,bold-style=ISO]{unicode-math}
\setmathfont{Asana Math}
\usepackage{witharrows}
\WithArrowsOptions{fleqn,displaystyle,i,tikz={font={\small\normalfont}},ygap=0.5em,wrap-lines}

\DeclareEmphSequence{\bfseries}

\hfuzz=50pt % Elimina warnings de "Overfull \hbox"

\usepackage[margin=5mm]{geometry} % Adjust the margin values as desired

\usepackage{float}
\usepackage[ruled, vlined, linesnumbered]{algorithm2e}
\SetKw{Break}{break}
\SetKwFor{Loop}{loop}{}{end loop}

\usepackage{listings}
\lstset{basicstyle=\ttfamily} % Cambia la fuente a monospace
\usepackage{minted}

\usepackage[capitalise]{cleveref}

\setlist[enumerate,1]{label={\em{(\arabic*)}}}

\newtheoremstyle{customstyle} % <name>
{} % <Space above>
{} % <Space below>
{\slshape} % <Body font> % Preguntar que opinan, y porque hay un warning
{1.5em} % <Indent amount>
{\bfseries} % <Theorem head font>
{.} % <Punctuation after theorem head>
{.5em} % <Space after theorem head>
{} % <Theorem head spec (can be left empty, meaning `normal`)

\theoremstyle{customstyle}
\newtheorem{definition}{DefiniciÃ³n}[chapter]
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}{Lema:}[chapter]
\addto\captionsspanish{\renewcommand{\proofname}{DemostraciÃ³n}}
\renewenvironment{proof}[1][\proofname]{{\bfseries #1: }}{\qed} % Cambiar estilo del tÃ­tulo de la demostraciÃ³n

\newtheoremstyle{factstyle} % <name>
{} % <Space above>
{} % <Space below>
{\normalfont} % <Body font> % Preguntar que opinan, y porque hay un warning
{1.5em} % <Indent amount>
{\bfseries} % <Theorem head font>
{.} % <Punctuation after theorem head>
{.5em} % <Space after theorem head>
{} % <Theorem head spec (can be left empty, meaning `normal`)

\theoremstyle{factstyle}
\newtheorem{fact}{AfirmaciÃ³n}[theorem]



\DeclareMathOperator{\sop}{sop}
\DeclareMathOperator{\lm}{lm}
\DeclareMathOperator{\lc}{lc}
\DeclareMathOperator{\lt}{lt}
\DeclareMathOperator{\tail}{tail}
\DeclareMathOperator{\amb}{amb}
\renewcommand{\S}{\text{S}}
\DeclareMathOperator{\B}{B}
\DeclareMathOperator{\spn}{spn} % span estÃ¡ ocupado y re rompe todo si lo re-declaro
\DeclareMathOperator{\mat}{mat}
\DeclareMathOperator{\poli}{poli}
\DeclareMathOperator{\filas}{filas}


\begin{document}
\fontsize{16pt}{19pt}\selectfont % Increase the font size

\chapter{IntroducciÃ³n informal}

En este capitulo se explica informalmente mas o menos de que se trata el tema de la tesis.

Usted posiblemente haya escuchado hablar de los polinomios de varias variables, esos como $5  + 3 y - 2 x y + x^3 y^5$ y que todo el conjunto de los polinomios con, por ejemplo, variables $x, y$ sobre un cuerpo $K$ se denota como $K[x, y]$.

En esos polinomios es producto entre las variables conmuta, asÃ­ que es lo mismo el polinomio $x y$ que el polinomio $y x$. Se puede considerar que eso no pasa, que el producto de las variables no conmuta, asÃ­ que $x y â‰  y x$, (pero que el producto de las variables con los coeficientes si conmuta, asÃ­ que por ejemplo $x 3 y = 3 x y$). Al hacer eso se obtiene algo como los polinomios, pero en el que los monomios son palabras. A esos polinomios se los llama polinomios no conmutativos y, por ejemplo, para las variables $x, y$ con coeficientes en un cuerpo $K$ se denota como $KâŸ¨x, yâŸ©$ y en general si $X$ es un alfabeto, $KâŸ¨XâŸ©$ es el conjunto de los polinomios no conmutativos sobre $X$.

Una problema de decisiÃ³n que existe sobre los polinomios no conmutativos es, dado un conjunto $G$ de polinomios no conmutativos y un polinomio no conmutativo $f$ es decidir si $f$ se pude escribir como combinaciÃ³n lineal lineal de elementos de $G$ con coeficientes en $KâŸ¨XâŸ©$, o escrito formalmente determinar si:

\[ âˆƒn âˆˆ â„•, g_1, â€¦, g_n âˆˆ F, f_1, â€¦, f_n, f'_1, â€¦, f'_n âˆˆ KâŸ¨XâŸ© : f = âˆ‘_{i = 1}^n f_i g_i f'_i \]

Este problema en el caso general no es computable, pero si se puede hacer un algoritmo que si es verdadero termina y si no puede no terminar, o hacer un algoritmo que intenta determinarlo y puede devolver que si, que no, o que no sabe pero podrÃ­a llegar a averiguarlo si sigue computando (asÃ­ como podrÃ­a no averiguarlo nunca).

Para eso se considera el conjunto $(G)$ de todos los polinomios no conmutativos que satisfacen ese $âˆƒ$ y se calcula algo que se llama una base de GrÃ¶bner de $(G)$, la cual puede ser finita o infinita computacionalmente enumerable y son estos Ãºltimos casos los que hacen que el problema no sea computable.

Para calcular esas bases de GrÃ¶bner hay dos algoritmos principales, llamados algoritmo de Buchberger y F4.

Antes de ahora ya hubo varias implementaciones de esos algoritmos, siendo la mas importante \texttt{operator\_gb} hecha por Clemens Hofstadler en python usando \texttt{sagemath} y que estÃ¡ explicada en â€¦ % Citar a Hof
junto con una explicaciÃ³n de toda la teorÃ­a (mucho mas en detalle que en esta tesis).

Como esa implementaciÃ³n estÃ¡ hecha en python y no corre en paralelo, el objetivo original de esta tesis fue implementar en C++ esos algoritmos y hacerlos correr en paralelo.

La parte de implementar en C++ esos algoritmos se logrÃ³, pero hay una optimizaciÃ³n que ayuda bastante y no se hizo. La parte de hacerlo correr en paralelo se hizo, pero solo para una parte y para la parte de la optimizaciÃ³n que no se hizo tampoco se hizo nada en paralelo. Hacer esa optimizaciÃ³n podrÃ­a ser un trabajo para una tesis futura.

\chapter{Definiciones preliminares}\label{cap:Definiciones preliminares}

En este capitulo se explica toda la parte matemÃ¡tica, basada principalmente en la explicaciÃ³n de â€¦. % Citar a Hof
En particular, primero se explican sistemas de re-escritura, despuÃ©s se introduce el Ã¡lgebra libre, se prueba que es un anillo, se dan algunas definiciones y teoremas de anillos y se definen las bases de GrÃ¶bner y por Ãºltimo se explican y dan seudocÃ³digos para los algoritmos de Buchberger y F4, que son los dos algoritmos importantes para calcular bases de GrÃ¶bner no conmutativas.

Muchos de los conceptos y definiciones tienen un anÃ¡logo en el caso conmutativo, pero eso no se cubre acÃ¡. Para una explicaciÃ³n de eso se puede leer â€¦. % Citar al libro de Ideals, Varieties, and Algorithms

\section{Sistemas de re-escritura}

En esta secciÃ³n se explican algunas definiciones y teoremas bÃ¡sicos de sistemas de re-escritura. En esta parte es muy probable que a cualquiera que haya estudiado computaciÃ³n muchas cosas ya las conozca o le suenen, pero estÃ¡n acÃ¡ para que se puede entender mejor sin tener que buscar nada en otro lado.

Sistemas de re-escritura se trata bÃ¡sicamente del estudio de relaciones entre objetos con la idea de usar las relaciones para convertir un objeto a otro. Vamos a en general usar relaciones denotados con algÃºn sÃ­mbolo con forma de flecha porque estÃ¡ la idea de que se ``usa'' la relaciÃ³n para convertir el objeto de la izquierda en el objeto de la derecha.

Para toda estÃ¡ secciÃ³n fijemos un conjunto $A$. Primero definimos algunas operaciones muy comunes sobre relaciones.

\begin{definition} Sean $â†’, âŸ¿ âŠ† A^2$ relaciones sobre $A$:
  \begin{itemize}
    \item $â†’ âˆ˜ âŸ¿ = \{(x, z) âˆˆ A^2 : âˆƒy âˆˆ A : x â†’ y âˆ§ y âŸ¿ z\}$
    \item $â†’^0 = \{(x, x) : x âˆˆ A\}$
    \item $â†’^{n + 1} = â†’^n âˆ˜ â†’$
    \item $â†’^* = â‹ƒ_{n = 0}^âˆ â†’^n$
    \item $â† = \{(y, x) âˆˆ A^2 : (x, y) âˆˆ â†’\}$
    \item $â†” = â†’ âˆª â†$
  \end{itemize}
\end{definition}

Para el resto de la secciÃ³n fijemos $â†’$ una relaciÃ³n sobre $A$.

Como vamos a hablar de usar $â†’$ para transformar un objeto en otro, es Ãºtil la proxima definiciones que nos permiten haber de la forma normal de un objeto como el elemento un que se llega aplicando $â†’$ hasta que no se puede mas.

\begin{definition}\
  \begin{itemize}
    \item $a$ estÃ¡ en forma normal $â‡” âˆ„x âˆˆ A : a â†’ x$
    \item $b$ es forma normal de $a â‡” a â†’^* b âˆ§ b$ estÃ¡ en forma normal
    \item $a$ tiene forma normal $â‡” âˆƒx âˆˆ A : x$ es forma normal de $a$
    \item $a â†“ b â‡” âˆƒx âˆˆ A : a â†’^* x âˆ§ b â†’^* x$
  \end{itemize}
\end{definition}

Y tambiÃ©n vamos a necesitar definir algunas propiedades sobre las relaciones:

\begin{definition}\
  \begin{itemize}
    \item $â†’$ es confluente $â‡” âˆ€x, y, z âˆˆ A : x â†’^* y âˆ§ x â†’^*z â‡’ y â†“ z$
    \item $â†’$ es Church-Rosser $â‡” âˆ€x, y âˆˆ A : x â†”ï¸^* y â‡” x â†“ y$
    \item $â†’$ es normalizante $â‡” âˆ€x âˆˆ A : x$ tiene forma normal
    \item $â†’$ es terminante $â‡” âˆ„X âˆˆ A^â„• : âˆ€i âˆˆ â„• : X_i â†’ X_{i + 1}$
  \end{itemize}
\end{definition}

Sobre estas propiedades tenemos estos teoremas:

\begin{theorem}\label{thm:terminante â‡’ normalizante}
  $â†’$ es terminante $â‡’Â â†’$ es normalizante
\end{theorem}

\begin{theorem}\label{thm:confluente â‡” Church-Rosser}
  $â†’$ es confluente $â‡”Â â†’$ es Church-Rosser
\end{theorem}

\section{Ãlgebra libre}

El Ã¡lgebra libre es bÃ¡sicamente el conjunto de los polinomios no conmutativo con sus operaciones. En esta secciÃ³n estÃ¡ toda la parte de la tesis de el Ã¡lgebra libre.

En los polinomios no conmutativos los monomios son bÃ¡sicamente palabras y lo Ãºnico que se puede hacer con los monomios entre si es multiplicarlos que equivale a concatenar la palabras. En la proxima definiciÃ³n se define eso.

\begin{definition}
  Sea $X$ un alfabeto finito. Se define la estructura $(âŸ¨XâŸ©, Â·)$ de la siguiente manera:
  \begin{itemize}
    \item $âŸ¨XâŸ©$ son las palabras finitas sobre $X$
    \item $Â· : âŸ¨XâŸ©^2 â†’ âŸ¨XâŸ©$ es la concatenaciÃ³n
  \end{itemize}
  A los elementos de $âŸ¨XâŸ©$ se los llama monomios libres sobre $X$, a $Â·$ el producto de $âŸ¨XâŸ©$ y a $(âŸ¨XâŸ©, Â·)$ el monoide libre sobre $X$.
\end{definition}

Por ejemplo, si $X = \{a, b, c\}$ algunos monomios son:

\begin{align*}
  m_0 &= abbcb \\
  m_1 &= bbc \\
  m_2 &= bcb \\
  m_3 &= Îµ \\
  m_1 Â· m_2 &= bccbcb
\end{align*}

El $Îµ$ de $m_3$ es la palabra vacÃ­a. Notar que $m_1 â‰  m_2$ ya que el producto es no es conmutativo.

A partir de ahora para todo el resto de la tesis fijamos $X$ un alfabeto finito.

En estos monomios al igual que no los conmutativos se puede hablar de que un monomio divida a otro, pero acÃ¡ que un monomio divida a otro es equivalente a que un un monomio sea sub-palabra de otro.

\begin{definition}
  Sean $v, w âˆˆ âŸ¨XâŸ©$:
  \begin{itemize}
    \item $v | w â‡” âˆƒa , b âˆˆ âŸ¨XâŸ© : w = avb$
  \end{itemize}
  Y cuando $v | w$ se dice que $v$ divide a $w$.
\end{definition}

En el ejemplo de antes tenemos por ejemplo $m_1 | m_0$ ya que $m_0 = a m_1 b$.

De lo que es un poco mas complicado hablar acÃ¡ es de el resultado de la divisiÃ³n porque es como que tendrÃ­a que haber dos resultados, asÃ­ que no vamos a hablar de dividir un monomio en otro ni escribir divisiones entre monomios.

Mas adelante va a ser necesario tener un orden entre los elementos de $âŸ¨XâŸ©$, pero no es necesario fijar uno concreto, asÃ­ que lo que vamos a hacer es definir las propiedades que tienen que tener un orden para servir y trabajar con un orden cualquiera que las cumpla.

\begin{definition}
  Sea $â‰¤$ un orden total sobre $âŸ¨XâŸ©$, definimos que $â‰¤$ es un buen orden monomial si y solo si:
  \begin{enumerate}
    \item $âˆ€v, w, a, b âˆˆ âŸ¨XâŸ© : v â‰¤ w â‡’ avb â‰¤ awb$
    \item $âˆ€S âŠ† âŸ¨XâŸ© : S â‰  âˆ… â‡’ S$ tiene mÃ­nimo elemento con respecto a $â‰¤$
  \end{enumerate}
\end{definition}

En ejemplo de orden que cumple con esta definiciÃ³n es el siguente:

\begin{definition}
  Fijemos $X = \{x_1, â€¦, x_n\}$ y un orden total sobre $X$: $x_1 â‰¤ â€¦ â‰¤ x_n$, el cual se extiende (como es usual) de forma lexicogrÃ¡fica a $âŸ¨XâŸ©$. El orden lexicogrÃ¡fico por grado $ â‰¤_{deglex}$ sobre $âŸ¨XâŸ©$ se define asÃ­:
  \[ a â‰¤_{deglex} b â‡” |a| < |b| âˆ¨ (|a| = |b| âˆ§ a â‰¤ b) \]
\end{definition}

O sea, el orden lexicogrÃ¡fico por grado es orden primero por cardinalidad, que se llama grado tambiÃ©n y desempatar por orden lexicogrÃ¡fico, por ejemplo tenemos $bc â‰¤_{deglex} abb$, $aabbc â‰¤_{deglex} abbcc$ y $Îµ â‰¤_{deglex} a$.

Se puede probar fÃ¡cilmente que este orden es un bueno orden monomial.

A partir de ahora fijamos un buen orden monomial $â‰¤$ y vamos a usar $<$, $â‰¥$ y $>$ como se usan habitualmente.

Una propiedad sobre el orden monomial que es consecuencia directa de la definiciÃ³n es la siguiente:

\begin{theorem}\label{thm:â‰¤ no cadenas dec inf}
  La relaciÃ³n $â‰¤$ no tiene cadenas estrictamente decrecientes infinitas
\end{theorem}

Ahora pasemos a hablar de sumar monomios entre si para tener polinomios no conmutativos.

\begin{definition}[Ãlgebra libre (asociativa)]
  Sea $R$ un anillo conmutativo. Se define $RâŸ¨XâŸ©$ la $R$-Ã¡lgebra libre sobre $X$ como:
  \[ RâŸ¨XâŸ© = \{âˆ‘_{i = 1}^n c_i w_i : c_1, â€¦, c_n âˆˆ R, w_1, â€¦, w_n âˆˆ âŸ¨XâŸ©\} \]

  La suma en $RâŸ¨XâŸ©$ se define de la manera esperable.

  El producto por escalares de define como:
  \[ c (âˆ‘_{i = 1}^n c_i w_i) = (âˆ‘_{i = 1}^n c c_i w_i) \]

  El producto entre elementos de $RâŸ¨XâŸ©$ se define como:
  \[ (âˆ‘_{i = 1}^n c_i w_i) Â· (âˆ‘_{i = 1}^m c'_i w'_i) = âˆ‘_{i = 1}^n âˆ‘_{j = 1}^m c_i c'_j w_i w'_j \]

  A los elementos de $RâŸ¨XâŸ©$ se los llama polinomios no conmutativos.
  % Esta definiciÃ³n creo que hay que mejorarla, pero no se como
\end{definition}

Esta definiciÃ³n puede ser medio difÃ­cil de entender exactamente que estÃ¡ haciendo, pero es lo que se espera que sean los polinomios no conmutativos y sus operaciones. Algunos ejemplos de polinomios no conmutativos sobre $â„šâŸ¨\{a, b, c\}âŸ©$ son los siguientes:
\[ p_0 = a \]
\[ p_1 = ab + cb \]
\[ p_2 = 3 abb + 4 bcca - 2 acab \]

Notar que $p_1 â‰  ab + bc$ ya que el producto es no conmutativo.

Sobre los polinomios no conmutativos se hacen las siguientes definiciones que despuÃ©s vamos a usar mucho:

\begin{definition}\label{def:cosas de polinomios}
  Sean $R$ un anillo conmutativo, $p âˆˆ RâŸ¨XâŸ©$, $c_1, â€¦, c_n âˆˆ R$, $w_1, â€¦, w_n, w âˆˆ âŸ¨XâŸ©$, $f = âˆ‘_{i = 1}^n c_i w_i$ y $â‰¤$ un buen orden monomial.
  \begin{itemize}
    \item $f_w = \left\{\begin{array}{ll} w = w_i â†’ c_i \\ \text{si no} â†’ 0  \end{array} \right.$
    \item $\sop(f) = \{w_1, â€¦, w_n\}$
    \item $\lm_â‰¤(f) = \min_â‰¤(\sop(f))$
    \item $\lc_â‰¤(f) = f_{\lm(f)}$
    \item $\lt_â‰¤(f) = \lc_â‰¤(f) Â· \lm_â‰¤(f)$
    \item $\tail_â‰¤(f) = f - \lt_â‰¤(f)$
    \item $f$ es mÃ³nico $â‡” \lc_â‰¤(f) = 1$
  \end{itemize}

  A $\sop(f)$ se lo llama soporte de $f$, a $\lm_â‰¤(f)$ se lo llama monomio principal de $f$, a $\lc_â‰¤(f)$ se lo llama coeficiente principal de $f$ y a $\lt_â‰¤(f)$ se lo llama tÃ©rmino principal de $f$. Los nombres lm, lc, lt y tail vienen del inglÃ©s leading monomial, leading coefficient, leading term y tail respectivamente.
\end{definition}

La estructura del Ã¡lgebra libre es un anillo, lo cual nos va a ser muy Ãºtil por muchas definiciones y teoremas que ya existen sobre los anillos.

\begin{theorem}
  Sea $R$ un anillo conmutativo, entonces:
  \[ (RâŸ¨XâŸ©, +, Â·)\text{ es un anillo} \]
\end{theorem}

Las definiciones y teoremas sobre anillos que vamos a usar las vamos a repasar a continuaciÃ³n para no tener que estar buscÃ¡ndolos en otro lado.

\begin{definition}\label{def:ideal}
  Sean $R$ un anillo e $I, B âŠ† R$, definimos que $I$ es un ideal de $R$ si y solo si:
  \begin{enumerate}
    \item $I â‰  âˆ…$
    \item $âˆ€a, b âˆˆ I : a + b âˆˆ I$
    \item $âˆ€a âˆˆ I, r, r' âˆˆ R : r a r' âˆˆ I$
  \end{enumerate}
  \[ (B) = \{âˆ‘_{i = 1}^n c_i b_i c_i' : n âˆˆ â„•, b_1, â€¦, b_n âˆˆ B, c_1, â€¦, c_n, c_1', â€¦, c_n' âˆˆ R\} \]
\end{definition}

Los ideales son bÃ¡sicamente conjuntos cerrados por suma producto por elementos cualquiera y $(B)$ es el ideal generado por $B$.

\begin{theorem}
  Sean $R$ un anillo y $B âŠ† R$, entonces:
  \[ (B)\text{ es un ideal de }R \]
\end{theorem}

Cada ideal define una clase de equivalencia en el anillo, la cual se llama congruencia modulo el ideal.

\begin{definition}[Congruencia modulo un ideal]\label{def:congruencia mod ideal}
  Sean $R$ un anillo e $I âŠ† R$, se define $â‰¡_I$ como relaciÃ³n en $R$ asÃ­:
  \[ a â‰¡_I b â‡” a - b âˆˆ I \]
\end{definition}

\begin{theorem}\label{thm:congruencia mod ideal es equivalencia}
  Sean $R$ un anillo y $I âŠ† R$ un ideal, entonces:
  \[ â‰¡_I \text{es una relaciÃ³n de equivalencia} \]
\end{theorem}

Esta congruencia es parecida a la de los nÃºmeros modulo otro nÃºmero (de hecho la congruencia de los nÃºmeros modulo otro nÃºmero es un subcaso de esta tomando como ideal a todos los mÃºltiplos del modulo) y vale que la clase de equivalencia del $0$ es el propio ideal:

\begin{theorem}\label{thm:en ideal â‡” congruente 0}
Sean $R$ un anillo, $I âŠ† R$ un ideal y $a âˆˆ R$, entonces:
\[ a âˆˆ I â‡” a â‰¡_I 0 \]
\end{theorem}

Por Ãºltimo, con respecto al ideal generado por un conjunto tenemos el siguiente teorema.

\begin{theorem}\label{thm:gen B = gen B U a con a âˆˆ gen B}
  Sean $R$ un anillo, $B âŠ† R$ y $a âˆˆ (B)$, entonces:
  \[ (B) = (B âˆª {a}) \]
\end{theorem}

Ahora volvemos al Ã¡lgebra libre y a partir de ahora fijamos un cuerpo $K$.

Con las definiciones que tenemos ahora la pregunta que planteÃ¡bamos en la introducciÃ³n se puede escribir como dado un conjunto finito $F âŠ† KâŸ¨XâŸ©$ y un elemento $f âˆˆ KâŸ¨XâŸ©$, determinar si $f âˆˆ (F)$. Ahora nos vamos a poner con el tema de esa pregunta.

Para varias cosas va a ser necesario comparar no solo monomios si no tambiÃ©n polinomios, asÃ­ que el orden $â‰¤$ se extiende a $KâŸ¨XâŸ©$ asÃ­:

\begin{definition}
  Sean $f, g âˆˆ  KâŸ¨XâŸ©$, definimos que $f < g$ si y solo si vale alguna de las siguientes:
  \begin{enumerate}
    \item $f = 0 âˆ§ g â‰  0$
    \item $\lm_â‰¤(f) < \lm_â‰¤(g)$
    \item $\lm(f) = \lm(g) âˆ§ \tail(f) < \tail(g)$
  \end{enumerate}
  Y $f â‰¤ g$ si y solo si $f < g âˆ¨ f = g$.
\end{definition}

Es decir, el orden en los polinomios es orden lexicogrÃ¡fico con el polinomio visto como una lista de monomios, sin coeficientes, ordenada de mayor a menor.

Por ejemplo, tenemos estas desigualdades en $KâŸ¨XâŸ©$:
\[ a < ab \]
\[ bcc + c < bcc + abb \]
\[ ac < ac + aa \]

Si bien a este $<$ lo estamos llamando (y lo vamos a seguir llamando) orden en realidad no es un orden si no un pre-orden porque cuando solo cambian los coeficientes entre un polinomio y otro ninguno de los polinomios es menor que el otro.

\begin{theorem}
  La relaciÃ³n $<$ en $KâŸ¨XâŸ©$ es un pre-orden parcial.
\end{theorem}

Sobre este orden hay varias propiedades que vamos a necesitar y que estÃ¡n enunciadas y probadas a continuaciÃ³n.

\begin{theorem}\label{thm:â‰¤ en KX no cadenas dec inf}
  La relaciÃ³n $â‰¤$ en $KâŸ¨XâŸ©$ no tiene cadenas estrictamente decrecientes infinitas.
\end{theorem}
\begin{proof}
  Supongamos que existen cadenas estrictamente decreciente infinita. Tomemos una $P$ que minimize $\lm(P_1)$. Tomar este mÃ­nimo es posible por el \cref{thm:â‰¤ no cadenas dec inf}

  Notar que:

  \begin{fact}\label{fact:â‰¤ en KX no cadenas dec inf:1}
    $âˆ€i âˆˆ â„• : \lm(P_i) = \lm(P_1)$
  \end{fact}
  En efecto, no puede ser $\lm(P_i) < \lm(P_1)$ porque entonces $P_i, P_{i + 1}, â€¦$ serÃ­a una cadena estrictamente decreciente infinita que romperÃ­a la minimalidad de $\lm(P_1)$ y no puede ser $\lm(P_i) > \lm(P_1)$ porque $P$ es una cadena estrictamente decreciente.

  \begin{fact}\label{fact:â‰¤ en KX no cadenas dec inf:2}
    $\tail(P_1), \tail(P_2), â€¦$ es una cadena estrictamente decreciente infinita.
  \end{fact}
  Esto vale por aplicar la definiciÃ³n del orden polinomial, por la \cref{fact:â‰¤ en KX no cadenas dec inf:1} y por lo que estamos suponiendo sobre $P$.

  Como claramente $0$ es un mÃ­nimo:

  \begin{fact}\label{fact:â‰¤ en KX no cadenas dec inf:3}
    $P_1 â‰  0$.
  \end{fact}

  Sin embargo, la \cref{fact:â‰¤ en KX no cadenas dec inf:2} contradice la minimalidad de $\lm(P_1)$ ya que por la \cref{fact:â‰¤ en KX no cadenas dec inf:3} vale que $\lm(\tail(P_1)) < \lm(P_1)$.

\end{proof}

Ahora vamos a definir una relaciÃ³n de reducciÃ³n en los polinomios no conmutativos (y acÃ¡ es donde entre lo de sistemas de re-escritura).

La relaciÃ³n que vamos a definir va a ser dependiente de el orden monomial y de un conjunto de polinomios no conmutativos y lo que va a hacer es tratar de achicar un polinomio con los elementos del conjunto para que llega a quedar lo menor posible con respecto al orden polinomial.

Para definirla ademÃ¡s de definirla para un conjunto de la define para un solo polinomio y un polinomio y dos monomios de forma auxiliar.

\begin{definition}
  Sean $F âŠ† KâŸ¨XâŸ©$, $g âˆˆ KâŸ¨XâŸ© - \{0\}$, $a, b âˆˆ âŸ¨XâŸ©$ y $f, f' âˆˆ KâŸ¨XâŸ©$:
  \begin{itemize}
    \item $f â†’_{â‰¤, a, g, b} f' â‡” \lm_â‰¤(agb) âˆˆ \sop(f) âˆ§ f' = f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb$
    \item $â†’_{â‰¤, g} = â‹ƒ_{a, b âˆˆ âŸ¨XâŸ©} â†’_{â‰¤, a, g, b}$
    \item $â†’_{â‰¤, F} = â‹ƒ_{g âˆˆ F} â†’_{â‰¤, g}$
  \end{itemize}
\end{definition}

A continuaciÃ³n la prueba de que efectivamente achica.

\begin{theorem}[Las reducciones achican]\label{thm:â†’ achican}
  Sean $F âŠ† KâŸ¨XâŸ©$, $g âˆˆ KâŸ¨XâŸ© - \{0\}$, $a, b âˆˆ âŸ¨XâŸ©$ y $f, f' âˆˆ KâŸ¨XâŸ©$, entonces:
  \begin{enumerate}
    \item $f â†’_{â‰¤, a, g, b} f' â‡’ f' < f$
    \item $f â†’_{â‰¤, g} f' â‡’ f' < f$
    \item $f â†’_{â‰¤, F} f' â‡’ f' < f$
  \end{enumerate}
\end{theorem}
  \begin{proof}
  Por definiciÃ³n de las reducciones tenemos que (1) $â‡’$ (2) $â‡’$ (3), por lo cual alcanza con probar (1). Para ello supongamos el antecedente $f â†’_{â‰¤, a, g, b} f'$

  Esto implica por definiciÃ³n de reducciones:
  \begin{enumerate}
    \setcounter{enumi}{3}
    \item $\lm_â‰¤(agb) âˆˆ \sop(f)$
    \item $f' = f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb$
  \end{enumerate}

  Escribamos $f = âˆ‘_{i = 1}^n c_i m_i$ con $c_1, â€¦, c_n âˆˆ K$, $m_1, â€¦, m_n âˆˆ âŸ¨XâŸ©, m_1 > m_2 > â‹¯ > m_n$

  Sea $i$ tal que $m_i = \lm_â‰¤(agb)$, el cual existe por (4).

  \begin{fact}\label{fact:â†’ achican:3}
    Notar tambiÃ©n que $m_i = \lm_â‰¤(\frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb)$ porque es multiplicar por un escalar adentro del $\lm$ en la condiciÃ³n de $i$.
  \end{fact}
  \begin{description}
    \item[Si $i â‰  0$] la \cref{fact:â†’ achican:3} significa que los tÃ©rminos $c_1 m_1, c_2 m_2, â€¦, c_{i-1}, m_{i-1}$ son iguales en $f$ y en $f'$ y no hay nada mas en el medio, porque $f'$ es $f$ con cosas menores o iguales a $\lm_â‰¤(\frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb)$ restadas (por (5)).

    AdemÃ¡s, como $m_i = \lm_â‰¤(\frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb)$, tenemos que $f'_{m_i} = 0$, por ende, el tÃ©rmino que sigue despuÃ©s de $m_{i-1}$ (si es que hay) es menor que $m_i$ y por ende menor que $f$.

    \item[Si $i = 0$] aplica lo mismo pero directamente a $m_0$ solo que sin tener en cuenta los $m$ anteriores.
  \end{description}

\end{proof}

EstÃ¡ relaciÃ³n tiene un montÃ³n de propiedades que van a hacer falta y que se prueban a continuaciÃ³n.

\begin{theorem}\label{thm:suma â†’â†“}
  Sean $F âŠ† KâŸ¨XâŸ©, f, f_0, f_1 âˆˆ KâŸ¨XâŸ©$, entonces:
  \[ f_0 â†’_{â‰¤, F} f_1 â‡’ f_0 + f â†“_{â‰¤, F} f_1 + f \]
\end{theorem}
\begin{proof}
  Supongamos el antecedente $f_0 â†’_{â‰¤, F} f_1$.

  Sean $g âˆˆ F, a, b âˆˆ KâŸ¨XâŸ©$ tales que $f_1 = f_0 - \frac{{f_0}_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb$, los cuales existen por el antecedente y por definiciÃ³n de $â†’_{â‰¤, F}$.

  Dividamos en casos segÃºn si $\lm_â‰¤(agb) âˆˆ \sop(f)$:

  \begin{description}
    \item[Caso $\lm_â‰¤(agb) âˆ‰ \sop(f)$]\

    En este caso tenemos $f_0 + f â†’_{â‰¤, F} f_1 + f$ por tomar $g$, $a$ y $b$, y por ende tenemos $f_0 + f â†“_{â‰¤, F} f_1 + f$

    \item[Caso $\lm_â‰¤(agb) âˆˆ \sop(f)$]\
    \begin{description}
      \item[Subcaso $f_{\lm_â‰¤(agb)} = -{f_0}_{\lm_â‰¤(agb)}$]

      Este es el caso en el que $\lm_â‰¤(agb)$ se cancela en la suma $f_0 + f$. Y como ademÃ¡s $\lm_â‰¤(agb) âˆ‰ \sop(f_1)$ por el antecedente, tenemos:

      \begin{DispWithArrows*}
        &f_1 + f â†’_{â‰¤, F} f_1 + f - \frac{f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \Arrow{Subcaso} \\
        & â‡’ f_1 + f â†’_{â‰¤, F} f_1 + f + \frac{{f_0}_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \Arrow{CondiciÃ³n de $g$, $a$ y $b$} \\
        & â‡’ f_1 + f â†’_{â‰¤, F} f_0 + f \\
        & â‡’ f_1 + f â†“_{â‰¤, F} f_0 + f
      \end{DispWithArrows*}

      \item[Subcaso $f_{\lm_â‰¤(agb)} â‰  -{f_0}_{\lm_â‰¤(agb)}$] En este caso $\lm_â‰¤(agb)$ no se cancela en la suma $f_0 + f$, asÃ­ que podemos aplicar $â†’_{â‰¤, F}$:
      \begin{DispWithArrows*}
        &f_0 + f â†’_{â‰¤, F} f_0 + f - \frac{(f_0 + f)_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \\
        & â‡’ f_0 + f â†’_{â‰¤, F} f_0 + f - \frac{{f_0}_{\lm_â‰¤(agb)} + f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \\
        & â‡’ f_0 + f â†’_{â‰¤, F} f_0 + f - \frac{{f_0}_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb - \frac{f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \Arrow{CondiciÃ³n de $g$, $a$ y $b$}\\
        & â‡’ f_0 + f â†’_{â‰¤, F} f_1 + f - \frac{f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb
      \end{DispWithArrows*}
      Â Â Llamemos (1) a este Ãºltimo resultado.

      AdemÃ¡s por el caso y por subcaso tambiÃ©n tenemos $\lm_â‰¤(agb) âˆˆ \sop(f_1 + f)$, asÃ­ que tenemos:
      \begin{DispWithArrows*}
        &f_1 + f â†’_{â‰¤, F} f_1 + f - \frac{(f_1 + f)_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \\
        & â‡’ f_1 + f â†’_{â‰¤, F} f_1 + f - \frac{{f_1}_{\lm_â‰¤(agb)} + f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \Arrow{$\lm_â‰¤(agb) âˆ‰ \sop(f_1)$ porque $f_0 â†’_{â‰¤, F} f_1$ y definiciÃ³n de $â†’_{â‰¤, F}$}\\
        & â‡’ f_1 + f â†’_{â‰¤, F} f_1 + f - \frac{0 + f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb \\
        & â‡’ f_1 + f â†’_{â‰¤, F} f_1 + f - \frac{f_{\lm_â‰¤(agb)}}{g_{\lm_â‰¤(agb)}} agb
      \end{DispWithArrows*}
      Â Â Llamemos (2) a este Ãºltimo resultado.

      Por (1) y (2) tenemos $f_0 + f â†“_{â‰¤, F} f_1 + f$
    \end{description}
  \end{description}
\end{proof}

\begin{theorem}[Clausura reflexo transitiva de las reducciones]\label{thm:â†’^* = â‰¡}
  Sea $F âŠ† KâŸ¨XâŸ©$, entonces:
  \[ â†”^*_{â‰¤, F} = â‰¡_{(F)} \]

  (Donde $â‰¡_{(F)}$ es la congruencia modulo un ideal definida en la \cref{def:congruencia mod ideal})
\end{theorem}
\begin{proof}
  Lo vamos a probar por doble inclusiÃ³n
  \begin{description}
    \item[Prueba de $â†”^*_{â‰¤, F} âŠ† â‰¡_{(F)}$] Como tanto $â†”^*_{â‰¤, F}$ como $â‰¡_{(F)}$ son relaciones de equivalencia y ademÃ¡s $â†”^*_{â‰¤, F}$ es la mÃ­nima relaciÃ³n de equivalencia que contiene a $â†’_{â‰¤, F}$, alcanza con probar $â†’_{â‰¤, F} âŠ† â‰¡_{(F)}$. Para eso supongamos $f â†’_{â‰¤, F} f'$ y probemos $f â‰¡_{(F)} f'$.

    Sean $g âˆˆ F, a, b âˆˆ âŸ¨XâŸ©$ tales que $f' = f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb$, los cuales existen por lo que estamos suponiendo y por la definiciÃ³n de $â†’_{â‰¤, F}$. Tenemos:

    \begin{DispWithArrows*}
      &f â‰¡_{(F)} f' \\
      & â‡” f - f' âˆˆ (F) \\
      & â‡” f - (f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb) âˆˆ (F) \\
      & â‡” \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb âˆˆ (F)
    \end{DispWithArrows*}
    Y esto Ãºltimo es claramente cierto por la definiciÃ³n de ideal (\cref{def:ideal})

    \item[Prueba de $â‰¡_{(F)} âŠ† â†”^*_{â‰¤, F}$] Supongamos $f â‰¡_{(F)} f'$ y probemos $f â†”^*_{â‰¤, F} f'$.

    Sean:
    \begin{itemize}
      \item $g = f - f'$.
      \item $c_1, â€¦, c_n, c_1', â€¦, c_n' âˆˆ KâŸ¨XâŸ©$, $g_1, â€¦, g_n âˆˆ F$ tales que $g = âˆ‘_{i = 1}^n c_i g_i c_i'$, los cuales existen porque por definiciÃ³n de $â‰¡_Â·$ tenemos $g âˆˆ (F)$ y por definiciÃ³n de $(\ Â·\ )$.
      \item $f_0 = f$
      \item Para cada $i âˆˆ \{1, â€¦, n\}$: $f_i = f_{i - 1} - c_i g_i c_i'$.
    \end{itemize}

    Tenemos entonces:

    \begin{DispWithArrows*}
      &âˆ€i âˆˆ \{1, â€¦, n\} : g_i â†’_{â‰¤, F} 0 \\
      & â‡’ âˆ€i âˆˆ \{1, â€¦, n\} : - c_i g_i c_i' â†’_{â‰¤, F} 0 \Arrow{\cref{thm:suma â†’â†“}} \\
      & â‡’ âˆ€i âˆˆ \{1, â€¦, n\} : f_{i - 1} â†“_{â‰¤, F} f_i \\
      & â‡’ âˆ€i âˆˆ \{1, â€¦, n\} : f_{i - 1} â†”^*_{â‰¤, F} f_i \\
      & â‡’ f_0 â†”^*_{â‰¤, F} f_n \Arrow{$f_n = f - g = f'$}\\
      & â‡’ f â†”^*_{â‰¤, F} f_n
    \end{DispWithArrows*}

  \end{description}
\end{proof}

\begin{theorem}[Las reducciones se mantienen en ideal]\label{thm:â†’ mantiene pertenencia a ideal}
  Sean $F âŠ† KâŸ¨XâŸ©, f, f' âˆˆ (F)$, entonces:
  \[ f â†’^*_{â‰¤, F} f' â‡’ (f âˆˆ (F) â‡” f' âˆˆ (F)) \]
\end{theorem}
\begin{proof}
  Si asumimos $f â†’^*_{â‰¤, F} f'$ tenemos por el \cref{thm:â†’^* = â‰¡} $f â‰¡_{(F)} f'$ y entonces por el \cref{thm:en ideal â‡” congruente 0} tenemos $f âˆˆ (F) â‡” f' âˆˆ (F)$
\end{proof}

\begin{theorem}
  Sea $F âŠ† KâŸ¨XâŸ©$, entonces:
  \begin{itemize}
    \item $â†’_{â‰¤, F}$ es terminante
  \end{itemize}
\end{theorem}
\begin{proof}
  Lo vamos a demostrar por contradicciÃ³n. Supongamos que $â†’_{â‰¤, F}$ no es terminante, por definiciÃ³n de terminante podemos tomar una cadena $P âˆˆ KâŸ¨XâŸ©^â„•$ tal que:

  $âˆ€i âˆˆ â„• : P_i â†’_{â‰¤, F} P_{i+1}$

  Por el \cref{thm:â†’ achican} tenemos que:

  $âˆ€i âˆˆ â„• : P_i > P_{i+1}$

  Pero esto contradice el \cref{thm:â‰¤ en KX no cadenas dec inf} que dice que no hoy cadenas estrictamente decrecientes infinitas en $KâŸ¨XâŸ©$.

\end{proof}

\begin{theorem}[CaracterizaciÃ³n de las formas normales de $â†’$]
  Sea $F âŠ† KâŸ¨XâŸ©, f âˆˆ KâŸ¨XâŸ©$, entonces: % Por algÃºn motivo acÃ¡ se pone solo un salto de linea extra
  \[ f\text{ estÃ¡ en forma normal con respecto a} â†’_{â‰¤, F} â‡” âˆ„g âˆˆ F, m âˆˆ \sop(f) : \lm(g) | m \]
\end{theorem}
\begin{proof}
  Por contradicciÃ³n, supongamos que tenemos $g âˆˆ F, m âˆˆ \sop(f)$ tales que $\lm(g) âˆˆ \sop(f)$.

  Sean $a, b âˆˆ âŸ¨XâŸ©$ tal que $m = agb$, los cuales existen por la definiciÃ³n de divisibilidad.

  Entonces tenemos $f â†’_{â‰¤, F} f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb$ y por ende $f$ no estÃ¡ en forma normal.

\end{proof}

Probamos que $â†’_{â‰¤, F}$ es terminante, pero, no necesariamente es confluente. Que fuera confluente serÃ­a muy util porque significarÃ­a que para cualquier clase de equivalencia de $â‰¡_{(F)}$ podrÃ­amos siempre llegar a una misma forma normal y asÃ­ poder determinar si dos elementos son equivalentes (y en particular por poder determinar si un elemento estÃ¡ en el idea viendo si se llega a $0$ como la forma normal).

Sin embargo en algunas casos $â†’_{â‰¤, F}$ si es confluente. Esos casos en lo que si es terminante se llaman bases de GrÃ¶bner y lo que vamos a hacer despuÃ©s es calcular una base de GrÃ¶bner de un ideal generado por un conjunto que no es base de GrÃ¶bner.

\begin{definition}[Bases de GrÃ¶bner]\label{def:base de GrÃ¶bner}
  Sean $I$ un ideal de $KâŸ¨XâŸ©$ y $F âŠ† KâŸ¨XâŸ©$:
  \begin{itemize}
    \item $F$ es una base de GrÃ¶bner de $I â‡” (F) = IÂ âˆ§ â†’_{â‰¤, F}$ es confluente
  \end{itemize}
\end{definition}

Como en algunos casos $â†’_{â‰¤, F}$ no es confluente vamos la siguiente definiciÃ³n nos perimite hablar mas comodamente de una forma normal de un elemento (tanto en las definiciones teoremas como en los algoritmos).

\begin{definition}
  Sea $e_â‰¤ : ğ’«(KâŸ¨XâŸ©) â†’ KâŸ¨XâŸ© â†’ KâŸ¨XâŸ©$:
  \begin{itemize}
    \item $e_â‰¤$ es una estrategia de reducciÃ³n $â‡” âˆ€F âŠ† KâŸ¨XâŸ©, f âˆˆ KâŸ¨XâŸ© : e_â‰¤(F)(f)$ es forma normal de $f$ con respecto a $â†’_{â‰¤, F}$
  \end{itemize}
\end{definition}

Un ejemplo de estrategia de reducciÃ³n podrÃ­a calcularse con el siguiente seudocÃ³digo:

\begin{algorithm}[H] % La H es para que se quede acÃ¡, porque se iba a otra pÃ¡gina. EstarÃ­a bueno hacerlo global
  \caption{Ejemplo de estrategia de reducciÃ³n}\label{alg:estrategia de reducciÃ³n}
  \KwData{$F = \{f_1, â€¦, f_n\} âŠ† KâŸ¨XâŸ©, g âˆˆ KâŸ¨XâŸ©$}
  \KwResult{$g' âˆˆ KâŸ¨XâŸ©$}
  $g' â† g$

  $i â† 1$

  \While{$i â‰¤ n$} {
    \While{$i â‰¤ n$} {
      \If{$f_i âˆˆ \sop(g')$} {
        $g' â† g' - \frac{g'_{\lm(f_i)}}{\lc(f_i)}f_i$

        $i â† 1$

        \Break
      }
      \Else{
        $i â† i + 1$
      }
    }
  }
  \Return{$g'$}
\end{algorithm}

Este algoritmo consiste bÃ¡sicamente en siempre buscar entre los elementos de $G$ si hay alguno con el que reducir, y parar cuando ya no hay ninguno.

Una propiedad sobre las estrategias de reducciÃ³n que vamos a necesitar es la siguiente:

\begin{lemma}[Las estrategias de reducciÃ³n mantienen la pertenencia a ideales]\label{lemma:e mantiene pertenencia a ideal}
  Sean $e_â‰¤$ una estrategia de reducciÃ³n, $F âŠ† KâŸ¨XâŸ©$ y $f âˆˆ (F)$, entonces:
  \[ e_â‰¤(F)(f) âˆˆ (F) \]
\end{lemma}
\begin{proof}
  Es consecuencia directa de la definiciÃ³n y del \cref{thm:â†’ mantiene pertenencia a ideal}.
\end{proof}

Las bases de GrÃ¶bner se definieron por la propiedad mas importante que queremos que tengan, pero para poder usarlas van a hacer falta las siguientes equivalencias.

\begin{theorem}\label{thm:equivalencias de base de GrÃ¶bner}
  Sean $I$ un ideal de $KâŸ¨XâŸ©$ y $G âŠ† KâŸ¨XâŸ©$. Las siguientes afirmaciones son equivalentes:
  \begin{enumerate}
    \item $G$ es una base de GrÃ¶bner de $I$

    \item $âˆ€f âˆˆ KâŸ¨XâŸ© : (f âˆˆ I â‡” f â†’^*_{â‰¤, G} 0)$

    \item $âˆ€f âˆˆ KâŸ¨XâŸ© : (f âˆˆ I â‡’ f â†’^*_{â‰¤, G} 0)$

    \item $(G) = I âˆ§ âˆ€f âˆˆ I : âˆƒg âˆˆ G : \lm(g) | \lm(f)$

    \item $âˆ€f âˆˆ I - \{0\} : âˆƒg_1, â€¦, g_n âˆˆ G, a_1, â€¦, a_n, b_1, â€¦, b_n âˆˆ âŸ¨XâŸ© : \lm(a_i g_i b_i) â‰¤ \lm(f) : f = âˆ‘_{i = 1}^n a_i g_i b_i$
  \end{enumerate}

\end{theorem}
\begin{proof} Vamos a probar (1) $â‡’$ (2), (2) $â‡’$ (1), (2) $â‡”$ (3), (2) $â‡’$ (4), (4) $â‡’$ (3), (2) $â‡’$ (5) y (5) $â‡’$ (4).
  \begin{description}

    \item[(1) $â‡’$ (2)] Supongamos que $G$ es una base de GrÃ¶bner de $I$ y tomemos $f âˆˆ KâŸ¨XâŸ©$. Tenemos que probar $f âˆˆ I â‡” f â†’^*_{â‰¤, G} 0$. Vamos de un lado para el otro:

    \begin{DispWithArrows*}
      &f âˆˆ I \Arrow{\cref{thm:en ideal â‡” congruente 0}} \\
      & â‡” f â‰¡_I 0 \Arrow{\cref{thm:â†’^* = â‰¡}} \\
      & â‡” f â†”^*_{â‰¤, G} 0 \Arrow{Al ser $G$ una base de GrÃ¶bner $â†’_{â‰¤, G}$ es confluente y por ende por el \cref{thm:confluente â‡” Church-Rosser} es Church-Rosser, asÃ­ que aplico el sii de Church-Rosser} \\
      & â‡” f â†“_{â‰¤, G} 0 \Arrow{DefiniciÃ³n de $â†“$} \\
      & â‡” âˆƒf' âˆˆ KâŸ¨XâŸ© : f â†’^*_{â‰¤, G} f' âˆ§ 0 â†’^*_{â‰¤, G} f' \Arrow{Como $0$ es el mÃ­nimo elemento y el \cref{thm:â†’ achican} dice que las reducciones achican el segundo tÃ©rmino del $âˆ§$ ocurre solo para $f' = 0$} \\
      & â‡” f â†’^*_{â‰¤, G} 0
    \end{DispWithArrows*}

    \item[(2) $â‡’$ (1)]
    Supongamos (2), o sea $âˆ€f âˆˆ KâŸ¨XâŸ© : (f âˆˆ I â‡” f â†’^*_{â‰¤, G} 0)$. Tenemos que probar que $G$ es una base de GrÃ¶bner de $I$, es decir $(G) = IÂ âˆ§ â†’_{â‰¤, G}$ es confluente.

    Probemos cada termino del $âˆ§$ por separado:

    \begin{description}
      \item[Prueba de $(G) = I$] Tomemos $f âˆˆ KâŸ¨XâŸ©$ y probemos $f âˆˆ (G) â‡” f âˆˆ I$, probando ida y vuelta por separado:

      \begin{description}
        \item[Ida ($â‡’$)] Supongamos antecedente $f âˆˆ (G)$.

        Sean $c_1, â€¦, c_n, c_1', â€¦, c_n' âˆˆ KâŸ¨XâŸ©$, $g_1, â€¦, g_n âˆˆ G$ tales que $f = âˆ‘_{i = 1}^n c_i g_i c_i'$, los cuales existen por la definiciÃ³n de $(\ Â·\ )$.

        Definamos $f_0 = f$ y para $i âˆˆ \{1, â€¦, n\}$ $f_i = f_{i-1} - c_i g_i c_i'$.

        Notar que tenemos $âˆ€i âˆˆ \{1, â€¦, n\} : f_{i-1} â†’_{â‰¤, G} f_i$ y que $f_n = 0$.

        Esto significa que $f â†’^*_{â‰¤, G} 0$ y por ende por (2) vale $f âˆˆ I$.

        \item[Vuelta ($â‡$)] Supongamos el antecedente $f âˆˆ I$.

        Por (2) tenemos que $f â†’^*_{â‰¤, G} 0$

        AsÃ­ que sean $f_0, f_1, â€¦, f_n âˆˆ KâŸ¨XâŸ©$ tales que $f_0 = f$, $f_n = 0$ y $âˆ€i âˆˆ \{1, â€¦, n\} : f_{i-1} â†’_{â‰¤, G} f_i$, los cuales existen por la definiciÃ³n de $^*$.

        AdemÃ¡s, para cada $i âˆˆ \{1, â€¦, n\}$ sean $c_i, c_i' âˆˆ KâŸ¨XâŸ©, g_i âˆˆ G$ tales que $f_i = f_{i-1} - c_i g_i c_i'$, los cuales existen por definiciÃ³n de $â†’_{â‰¤, G}$.

        Notar que en particular $f_{i-1} = f_i + c_i g_i c_i'$ y por ende $f = âˆ‘_{i = 1}^n c_i g_i c_i'$, lo cual prueba que $f âˆˆ (G)$.

      \end{description}

      \item[Prueba de $â†’_{â‰¤, G}\text{ es confluente}$]\

      Por definiciÃ³n de confluencia alcanza que probar $âˆ€f, f_0, f_1 âˆˆ KâŸ¨XâŸ© : f â†’^*_{â‰¤, G} f_0 âˆ§ f â†’^*_{â‰¤, G} f_1 â‡’ f_0 â†“_{â‰¤, G} f_1$.

      AsÃ­ que tomemos $f, f_0, f_1 âˆˆ KâŸ¨XâŸ©$ y probemos el implica yendo de un lado para el otro.
      \begin{DispWithArrows*}
        &f â†’^*_{â‰¤, G} f_0 âˆ§ f â†’^*_{â‰¤, G} f_1 \\
        & â‡’ f_0 â†”^*_{â‰¤, G} f_1 \Arrow{\cref{thm:â†’^* = â‰¡}} \\
        & â‡’ f_0 â‰¡_{(G)} f_1 \Arrow{DefiniciÃ³n $â‰¡_{\ Â·\ }$} \\
        & â‡’ f_0 - f_1 âˆˆ (G) \Arrow{(6), ya probamos que $(G) = I$} \\
        & â‡’ f_0 - f_1 â†’^*_{â‰¤, G} 0 \Arrow{\cref{thm:suma â†’â†“}} \\
        & â‡’ (f_0 - f_1) + f_1 â†“_{â‰¤, G} 0 + f_1 \\
        & â‡’ f_0 â†“_{â‰¤, G} f_1
      \end{DispWithArrows*}
    \end{description}

    \item[(2) $â‡”$ (3)] La ida es claramente cierta y la vuelta $f âˆˆ I â‡ f â†’^*_{â‰¤, G} 0$ es cierta por el \cref{thm:â†’^* = â‰¡}.

    \item[(2) $â‡’$ (4)] Supongamos (2).

    La parte de $(G) = I$ es valida porque (2) $â‡’$ (1) y $(G) = I$ es parte de la definiciÃ³n de base de GrÃ¶bner.

    Para la parte de $âˆ€f âˆˆ I : âˆƒg âˆˆ G : \lm(g) | \lm(f)$ tomemos $f âˆˆ I$ y mostremos un $g$ que cumple el $âˆƒ$:

    Por (2) tenemos $f â†’^*_{â‰¤, G} 0$, esto significa que en alguno de los pasos de el $â†’^*_{â‰¤, G}$ se tiene que reducir el monomio principal de $f$, o sea, uno de los pasos es de la forma $â†’_{â‰¤, a, g, b}$ tal que $a \lm(g) b = \lm(f)$ con $g âˆˆ G, a, b âˆˆ âŸ¨XâŸ©$, por lo tanto, tenemos que $\lm(g) | \lm(f)$.

    \item[(4) $â‡’$ (3)] Lo probamos por contradicciÃ³n, o sea, supongamos que vale (4) y que no vale (3). En particular tomemos el mÃ­nimo $f$ tal que $f âˆˆ I$ pero no se cumple que $f â†’^*_{â‰¤, G} 0$.

    Por (4) sea $g âˆˆ G$ tal que $\lm(g) | \lm(f)$ y sean tambiÃ©n:
    \begin{itemize}
      \item $a, b âˆˆ âŸ¨XâŸ©$ tales que $a \lm(g) b = \lm(f)$
      \item $f' = f - \frac{f_{\lm_â‰¤(agb)}}{\lc_â‰¤(g)}agb$
    \end{itemize}

    Notar que $f' âˆˆ I$ ya que $f âˆˆ I$ y $g âˆˆ (G) = I$ y notar que $f â†’_{â‰¤, G} f'$.

    AdemÃ¡s por \cref{thm:â†’ achican} $f' < f$.

    Y como no vale $f â†’^*_{â‰¤, G} 0$ tampoco puede valer $f' â†’^*_{â‰¤, G} 0$, sin embargo esto contradice que $f$ sea mÃ­nimo.

    \item Los casos (2) $â‡’$ (5) y (5) $â‡’$ (4) son fÃ¡ciles y quedan como ejercicio. % Son fÃ¡ciles pero es un viaje

  \end{description}
  Con esto se termina la prueba.
\end{proof}


\section{Algoritmo de Buchberger}

En esta secciÃ³n se explica un primer algoritmo para calcular bases de GrÃ¶bner llamado Algoritmo de Buchberger.

Este algoritmo se llama asÃ­ porque es similar a un algoritmo en los polinomios conmutativos que fue inventado por alguien llamado Buchberger, pero no porque lo haya inventado Buchberger.

Antes de poder calcular bases de GrÃ¶bner algo que vamos a querer hacer es poder computar si un conjunto es una Base de GrÃ¶bner, porque ninguna de las equivalencias de \cref{thm:equivalencias de base de GrÃ¶bner} es directamente calculable porque hacen cuantificaciones sobre conjuntos infinitos.

Para eso vamos a definir algo llamado S-polinomio de dos polinomios que lo que hace es bÃ¡sicamente multiplicar cada polinomio por monomios a cada lado y por un escalar de forma que los monomios principales se cancelen. O sea para polinomios $f$ y $g$ vamos a tener una cuenta $k a f b - c g d$ de forma que se cancelen los monomios principales.

Para eso antes definimos las ambigÃ¼edades que representan los polinomios para los cuales puede pasar eso sin que todo lo importante estÃ© en los monomios $a$, $b$, $c$ y $d$.

\begin{definition}
  Sean $p, q, a, b, c, d âˆˆ âŸ¨XâŸ©$
  \[ (a, b, c, d, p, q)\text{ es una ambigÃ¼edad} â‡” apb = cqd âˆ§ |a|, |b| < |q| âˆ§ |c|, |d| < |p| \]

  La ambigÃ¼edad $(a, b, c, d, p, q)$ se dice que es:
  \begin{itemize}
    \item De superposiciÃ³n $â‡” a = Îµ = d âˆ¨ b = Îµ = c$
    \item De inclusiÃ³n $â‡” a = Îµ = b âˆ¨ c = Îµ = d$
    \item Relevante $â‡”$ es de superposiciÃ³n o de inclusiÃ³n
  \end{itemize}

  AdemÃ¡s, si $f, g âˆˆ KâŸ¨XâŸ©$ se dice que $(a, b, c, d, f, g)$ es una ambigÃ¼edad si y solo si $(a, b, c, d, \lm_â‰¤{(f)}, \lm_â‰¤{(g)})$ es una ambigÃ¼edad y lo mismo para ambigÃ¼edades de superposiciÃ³n, de inclusiÃ³n y relevantes.

  Sea ademÃ¡s $F âŠ† KâŸ¨XâŸ©$:
  \begin{itemize}
    \item $\amb(f, g) = \{(a, b, c, d, f, g) : a, b, c, d âˆˆ âŸ¨XâŸ© âˆ§ (a, b, c, d, f, g)\text{ es una ambigÃ¼edad}\}$
    \item $\amb(F) = â‹ƒ_{f, g âˆˆ F - \{0\}}{\amb(f, g)}$
  \end{itemize}

\end{definition}

\begin{definition}
  Sean $a, b, c, d âˆˆ âŸ¨XâŸ©, f, g âˆˆ KâŸ¨XâŸ©$ y $Î± = (a, b, c, d, f, g)$ una ambigÃ¼edad.
  \[ \S(Î±) = \frac{afb}{\lc_â‰¤{(f)}} - \frac{cgd}{\lc_â‰¤{(g)}} \]
\end{definition}

Notar que por como es la definiciÃ³n de ambigÃ¼edad, siempre es como que hay una parte de $p$ y una parte de $q$ que son iguales y que no estÃ¡n en los monomios $a$, $b$, $c$ y $d$.

Ahora vamos a probar que los S-polinomios hacen eso que dijimos que hacen y despuÃ©s vamos a dar el teorema para calcular si un conjunto es una base de GrÃ¶bner.

\begin{theorem}\label{thm:lm ambs}
  Sean $a, b, c, d âˆˆ âŸ¨XâŸ©$ y $f, g âˆˆ KâŸ¨XâŸ©$ entonces si $Î± = (a, b, c, d, f, g)$ es una ambigÃ¼edad tenemos que:
  \[ \lm_â‰¤{(afb)} = \lm_â‰¤{(cgd)} \]
\end{theorem}
\begin{proof}\
  \begin{DispWithArrows*}
    &\lm_â‰¤{(afb)} \Arrow{DefiniciÃ³n de ambigÃ¼edad para polinomios} \\
    & = a\lm_â‰¤{(f)}b \Arrow{DefiniciÃ³n de ambigÃ¼edad} \\
    & = c\lm_â‰¤{(g)}d \Arrow{DefiniciÃ³n de ambigÃ¼edad para polinomios} \\
    & = \lm_â‰¤{(cgd)}
  \end{DispWithArrows*}
\end{proof}

Eso nos permite definir el monomio principal de una ambigÃ¼edad.

\begin{definition}
  Sean $a, b, c, d âˆˆ âŸ¨XâŸ©, f, g âˆˆ KâŸ¨XâŸ©$ y $Î± = (a, b, c, d, f, g)$ una ambigÃ¼edad:
  \[ \lm_â‰¤{(Î±)} = \lm_â‰¤{(afb)} \]
\end{definition}

Notar que por el \cref{thm:lm ambs} tambiÃ©n vale que $\lm_â‰¤{(Î±)} = \lm_â‰¤{(cgb)}$.

Lo de que los monomios principales se cancelen se enuncia en el siguiente teorema.

\begin{theorem}
  Sean $a, b, c, d âˆˆ âŸ¨XâŸ©, f, g âˆˆ KâŸ¨XâŸ©$ y $Î± = (a, b, c, d, f, g)$ una ambigÃ¼edad, entonces:
  \[ \lm_â‰¤{(\S(Î±))} < \lm_â‰¤{(Î±)} \]
\end{theorem}
\begin{proof}
  Esto es porque en la resta $\frac{afb}{\lc_â‰¤{(f)}} - \frac{cgd}{\lc_â‰¤{(g)}}$ los monomios principales se cancelan.
\end{proof}

Otra cosa importante es que estos S-polinomios son cerraros en el ideal, es decir que el S-polinomio de dos elementos de un ideal, por ejemplo en particular del conjunto generador, es un elemento del ideal.

\begin{theorem}\label{thm:S es cerrado en ideal}
  Sean $I âŠ† KâŸ¨XâŸ©$ un ideal $a, b, c, d âˆˆ âŸ¨XâŸ©, f, g âˆˆ I$ y $Î± = (a, b, c, d, f, g)$ una ambigÃ¼edad, entonces:
  \[ \S(Î±) âˆˆ I \]
\end{theorem}
  \begin{proof}
  En la definiciÃ³n de $\S$ se ve claramente que es una combinaciÃ³n lineal de $f$ y $g$ con elementos de $KâŸ¨XâŸ©$ (en particular con los elementos $\frac{a}{\lc_â‰¤{(f)}}$, $b$, $\frac{c}{\lc_â‰¤{(g)}}$ y $d$)
\end{proof}

Ahora si damos el anunciado teorema para computar si un conjunto es una base de GrÃ¶bner.

\begin{theorem}[CondiciÃ³n de Buchberger]\label{thm:condiciÃ³n de Buchberger)}
  Sean $I$ un ideal de $KâŸ¨XâŸ©$ y $G âŠ† KâŸ¨XâŸ©$.

  Son equivalentes:
  \begin{enumerate}
    \item $G$ es una base de GrÃ¶bner de $I$
    \item $âˆ€Î± âˆˆ \amb(G) : \S(Î±) â†’^*_{â‰¤, G} 0$
  \end{enumerate}
\end{theorem}
% TODO: Agregar prueba. De cualquier manera, Hof no lo prueba a esto

Con esto ya se puede explicar la idea del algoritmo de Buchberger.

Cuando estamos chequeando si un conjunto es una base de GrÃ¶bner usando el \cref{thm:condiciÃ³n de Buchberger)} si nos encontramos con un S-polinomio $p$ que se reduce a un polinomio $q$ que es distinto de $0$ lo que podemos hacer es agregar $q$ al conjunto y con eso $p$ si se va a reducir a $0$.

Se podrÃ­a pensar que agregar $q$ por ahÃ­ cambia el ideal generado, pero por el teorema \cref{thm:S es cerrado en ideal} sabemos que $q$ es un elemento del ideal y por el \cref{thm:â†’ mantiene pertenencia a ideal} eso implica que $p$ tambiÃ©n estÃ¡ en el ideal y por ende por el \cref{thm:gen B = gen B U a con a âˆˆ gen B} se puede agregar al conjunto y que el ideal generado siga siendo el mismo.

El problema con eso de agregar un nuevo polinomio es que si bien hay una S-polinomio que pasa a si reducirse a $0$ tambiÃ©n aparecen nuevas ambigÃ¼edades. Eso sin embargo no es tanto problema porque lo se hace es hacer eso hasta que en algÃºn momento todas las ambigÃ¼edades se reducen a $0$ y si eso no pasa nunca simplemente el algoritmo no termina nunca (ya habÃ­amos dicho que el problema de pertenencia a un ideal no es decidible, asÃ­ que si o si va a haber alguna cosa asÃ­ inusual en cualquier algoritmo que hagamos).

Ese proceso de agregar polinomios infinitamente lo definimos matemÃ¡ticamente con la siguiente definiciÃ³n.

\begin{definition}
  Sean $F âŠ† KâŸ¨XâŸ©$ y $e_â‰¤$ una estrategia de reducciÃ³n:
  \begin{itemize}
    \item $\B_{e_â‰¤}^0(F) = F$
    \item $\B_{e_â‰¤}^{i + 1}(F) = \B_{e_â‰¤}^i(F) âˆª \{e_â‰¤(\B_{e_â‰¤}^i(F))(\S(Î±)) : Î± âˆˆ \amb(\B_{e_â‰¤}^i(F))\}$
    \item $\B_{e_â‰¤}(F) = â‹ƒ_{i = 0}^âˆ \B_{e_â‰¤}^i(F)$
  \end{itemize}
\end{definition}

Y a esos conjuntos los llamamos bases de Buchberger (este nombre es un nombre inventado para esta tesis, otros autores no le han dado ningÃºn nombre concreto a esos conjuntos).

Podemos enunciar que esos conjuntos realmente hacen lo que dijimos arriba y ademÃ¡s que si hay una base de GrÃ¶bner finita entonces en algÃºn momento se llega, con el siguiente teorema.

\begin{theorem}\label{thm:Buchberger correctitud}
  Sean $F âŠ† KâŸ¨XâŸ©$ y $e_â‰¤$ una estrategia de reducciÃ³n, entonces:
  \begin{enumerate}
    \item $\B_{e_â‰¤}(F)$ es una base de GrÃ¶bner de $(F)$
    \item $(F)$ tiene una base de GrÃ¶bner finita $â‡’ âˆƒi âˆˆ â„• : (\B_{e_â‰¤}^i(F))$ es una base de GrÃ¶bner
  \end{enumerate}
\end{theorem}

Con lo que dijimos antes tiene sentido que (q) sea cierto, pero que (2) sea cierto no es para nada obvio. Para probar ambos items primero vamos a probar algunos lemas en el contexto de este teorema (o sea con $F$ y $e_â‰¤$ fijados).

\begin{lemma}\label{lemma:Buchberger correctitud:3}
  $âˆ€i âˆˆ â„• : \B_{e_â‰¤}^{i}(F) âŠ† (F)$
\end{lemma}
\begin{proof}
  Por inducciÃ³n en $i$ el caso base es valido porque $F âŠ† (F)$, para el caso inductivo supongamos que vale para $i$ y probemos que vale para $i + 1$:

  Tomemos $f âˆˆ \B_{e_â‰¤}^{i + 1}(F)$ y probemos que $f âˆˆ (F)$.

  Por la definiciÃ³n recursiva de $\B_{e_â‰¤}^{i + 1}$ tenemos $f âˆˆ \B_{e_â‰¤}^i(F) âˆ¨ âˆƒÎ± âˆˆ \amb(\B_{e_â‰¤}^i(F)) : f = e_â‰¤(\B_{e_â‰¤}^i(F))(\S(Î±))$.

  El caso $f âˆˆ \B_{e_â‰¤}^i(F)$ es valido por hipÃ³tesis inductiva. Para el otro caso tomemos ese $Î±$.

  Por el \cref{thm:S es cerrado en ideal} tenemos que $\S(Î±) âˆˆ \B_{e_â‰¤}^i(F)$ y por la hipÃ³tesis inductiva que $\S(Î±) âˆˆ (F)$.

  Esto implica por el \cref{lemma:e mantiene pertenencia a ideal} que $e_â‰¤(\B_{e_â‰¤}^i(F))(\S(Î±)) âˆˆ \B_{e_â‰¤}^i(F)$ y por la hipÃ³tesis inductiva que $e_â‰¤(\B_{e_â‰¤}^i(F))(\S(Î±)) âˆˆ (F)$.
\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:4}
  $âˆ€i âˆˆ â„• : \B_{e_â‰¤}(F) âŠ† (F)$
\end{lemma}
\begin{proof}
  Esto es consecuencia directa de la \cref{lemma:Buchberger correctitud:3} y la definiciÃ³n de $\B_{e_â‰¤}$.
\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:5}
  $(\B_{e_â‰¤}(F)) = (F)$
\end{lemma}
\begin{proof}
  Esto vale porque por el caso base de la definiciÃ³n de $\B_{e_â‰¤}^i$ tenemos $F âŠ† \B_{e_â‰¤}$ y por la \cref{lemma:Buchberger correctitud:4}.
\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:6}
  $âˆ€Î± âˆˆ \amb(\B_{e_â‰¤}(F)) : \S(Î±) â†’^*_{â‰¤, \B_{e_â‰¤}(F)} 0$
\end{lemma}
\begin{proof}
  Tomemos $Î± = (a, b, c, d, f, g) âˆˆ \amb(\B_{e_â‰¤}(F))$ y probemos el $âˆ€$.

  Por definiciÃ³n de $\amb$ vale que $f, g âˆˆ \B_{e_â‰¤}(F)$, asÃ­ que sea $i âˆˆ â„•$ el mÃ­nimo tal que $f âˆˆ \B_{e_â‰¤}^i(F)$, $j âˆˆ â„•$ el mÃ­nimo tal que $g âˆˆ \B_{e_â‰¤}^j(F)$ y $k = \max(i, j)$.

  Notar que $Î± âˆˆ \amb(\B_{e_â‰¤}^k(F))$ por la definiciÃ³n de $\amb$ y por ende $\S(Î±) âˆˆ \B_{e_â‰¤}(F)$.

  Por definiciÃ³n de $â†’^*_{â‰¤, F}$ esto significa que $\S(Î±) â†’^*_{â‰¤, \B_{e_â‰¤}(F)} 0$, asÃ­ que queda probada la afirmaciÃ³n.
\end{proof}

\begin{proof}[DemostraciÃ³n del \cref{thm:Buchberger correctitud}]
  Por el \cref{lemma:Buchberger correctitud:5} y el \cref{lemma:Buchberger correctitud:6} vale la equivalencia de base de GrÃ¶bner del \cref{thm:condiciÃ³n de Buchberger)}, asÃ­ que (1) queda probado.

  Ahora para probar (2) supongamos el antecedente y tomemos $G = \{g_1, â€¦, g_n\}$ una base de GrÃ¶bner finita de $(F)$.

  Para cada $i âˆˆ \{1, â€¦, n\}$ sean:
  \begin{itemize}
    \item $g_{i, 1}, â€¦, g_{i, k_i} âˆˆ \B_{e_â‰¤}(F), a_{i, 1}, â€¦, a_{i, k_i}, b_{i, 1}, â€¦, b_{i, k_i} âˆˆ âŸ¨XâŸ©$ con $\lm(a_{i, j} g_{i, j} n_{i, j}) â‰¤ \lm(g_i)$ tales que $g_i = âˆ‘_{j = 1}^{k_i} a_{i, j} g_{i, j} b_{i, j}$

    Los cuales existen por (1) y por (5) del \cref{thm:equivalencias de base de GrÃ¶bner}.

    \item $F' = \{g_{i, j} : i âˆˆ \{1, â€¦, n\}, j âˆˆ \{1, â€¦, k_i\}\}$

    \item $k âˆˆ â„•$ el mÃ­nimo tal que $F' âŠ† \B_{e_â‰¤}^k(F)$

    Notar que $k$ estÃ¡ bien definido porque $F'$ es finito.
  \end{itemize}

  Ahora vamos a probar que $\B_{e_â‰¤}^k(F)$ es una base de GrÃ¶bner de $(F)$.

  Por (5) del \cref{thm:equivalencias de base de GrÃ¶bner} alcanza con probar:

  \[ âˆ€f âˆˆ (F) - \{0\} : âˆƒg_1, â€¦, g_n âˆˆ \B_{e_â‰¤}^k(F), a_1, â€¦, a_n, b_1, â€¦, b_n âˆˆ âŸ¨XâŸ© : \lm(a_i g_i b_i) â‰¤ \lm(f) : f = âˆ‘_{i = 1}^n a_i g_i b_i \]

  Tomemos $f' âˆˆ (F) - \{0\}$ y escribamoslo de esa forma:

  Por (5) del \cref{thm:equivalencias de base de GrÃ¶bner} sean $i'_1, â€¦, i'_{n'} âˆˆ G, a'_1, â€¦, a'_{n'}, b'_1, â€¦, b'_{n'} âˆˆ âŸ¨XâŸ©$ tales que $\lm(a'_i g_{i'_i} b'_i) â‰¤ \lm(f')$ y $f' = âˆ‘_{i = 1}^{n'} a'_i g_{i'_i} b'_i$

  \begin{DispWithArrows*}
    &f' = âˆ‘_{i = 1}^{n'} a'_i g_{i'_i} b'_i \Arrow{CondiciÃ³n de $g_{i, j}$} \\
    & = âˆ‘_{i = 1}^{n'} a'_i (âˆ‘_{j = 1}^{k_{i'_i}} a_{i', j} g_{i, j} b_{i', j}) b'_i \\
    & = âˆ‘_{i = 1}^{n'} âˆ‘_{j = 1}^{k_i'} a'_i a_{i', j} g_{i, j} b_{i', j} b'_i
  \end{DispWithArrows*}

  Sabemos ademÃ¡s que $g_{i',j} âˆˆ \B_{e_â‰¤}^k(F)$ y que $g_{i', j} â‰¤ g_{i'_i} â‰¤ f'$.

  Con esto queda completada la prueba.

\end{proof}

Con estos conjuntos podemos de forma directa dar un seudocÃ³digo que los calcula:

\begin{algorithm}[H] % La H es para que se quede acÃ¡, porque se iba a otra pÃ¡gina. EstarÃ­a bueno hacerlo global
  \caption{Algoritmo de Buchberger}\label{alg:Buchberger}
  \KwData{$F âŠ† KâŸ¨XâŸ©$, $e_â‰¤$ una estrategia de reducciÃ³n}
  \KwResult{$G âŠ† KâŸ¨XâŸ©$ una base de GrÃ¶bner de $(F)$ si es que termina}
  $G â† F$

  \Loop{} {
    $ambs â† \amb(G)$

    $new\_G â† G$

    \For{$Î± âˆˆ ambs$} {
      $f â† e_â‰¤(G)(\S(Î±))$

      \If{$f â‰  0$} {
        $new\_G â† new\_G âˆª \{f\}$
      }
    }

    \If{$new\_G = G$} {
      \Break
    }

    $G â† new\_G$
  }
  \Return{$G$}
\end{algorithm}

El algoritmo asÃ­, si bien es una implementaciÃ³n tal cual de la definiciÃ³n de los conjuntos $\B_{e_â‰¤}^i$ que probamos que es correcta, es muy lenta y necesita un cambio para que pase a andar bien.

Ese cambio es en lugar de para las reducciones usar el conjunto anterior usar tambiÃ©n los nuevos polinomios que ya fueron agregados, es decir, llamar a $e_â‰¤$ con $new\_G$ en lugar de con $G$ en la linea 6. % Se podrÃ¡ hacer con un label esto?

Por lo que habÃ­amos visto antes el cambio tiene sentido que sea correcto y la prueba es similar a la del \cref{thm:Buchberger correctitud}.

En la implementaciÃ³n el cambio ese hace una diferencia inmensa en la eficiencia, pasa de no andar rÃ¡pido casi nunca a andar rÃ¡pido en un montÃ³n de casos. De forma teÃ³rica porque es algo que hace tanta diferencia es algo que no se ni puede encontrar en la literatura.

Hay otras dos optimizaciones mas que se pueden hacer a este algoritmo, una es para descartar algunas ambigÃ¼edades sin tener que reducirlas y la otra es para ir sacando algunos polinomios de la base. Ambos optimizaciones estÃ¡n explicadas en â€¦, % Citar a Hof
y no se van a explicar acÃ¡.

\section{Algoritmo F4}

En esta secciÃ³n se explica el algoritmo F4, que es otro algoritmo para calcular Bases de GrÃ¶bner.

La idea de F4 es agarrar varias ambigÃ¼edades y reducir todos sus S-polinomios al mismo tiempo, tanto reduciendo por los elementos que ya estÃ¡n en la base como reduciendo entre los propios S-polinomios que se estÃ¡n considerando. Para esto lo que se hace es convertir el problema en una reducciÃ³n por filas de una matriz codificando cada monomio como una columna y cada polinomio como una columna.

Para hacer esto de codificar los polinomios como filas de una matriz vamos a necesitar algunas definiciones:

\begin{definition}
Sea $P âŠ† KâŸ¨XâŸ©$:

\begin{itemize}
  \item $\spn_K(P) = \{âˆ‘_{i = 1}^n c_i p_i : n âˆˆ â„•, c_i âˆˆ K, p_i âˆˆ P\}$
\end{itemize}

\end{definition}

\begin{definition}
Sean $M = \{m_1, â€¦, m_n\} âŠ† âŸ¨XâŸ©$ tales que $m_1 > â‹¯ > m_n$:

\begin{itemize}
  \item $\poli_T : K^n â†’ \spn_K(M)$
  \item $\poli_T(v) = âˆ‘_{i = 1}^n v_i m_i$
\end{itemize}

\end{definition}

\begin{definition}
Sean $M = \{m_1, â€¦, m_n\} âŠ† âŸ¨XâŸ©$ tales que $m_1 > â‹¯ > m_n$. $\mat_T$ aplicado a un polinomio se define como la inversa de $\poli_T$:

\begin{itemize}
  \item $\mat_T : \spn_K(M) â†’ K^n$
  \item $\mat_T(p) = \poli_T^{-1}(p)$
\end{itemize}

$\mat_T$ aplicado a una lista de polinomios da una matriz:

\begin{itemize}
  \item $\mat_T(p_1, â€¦, p_m) = \begin{pmatrix} \mat_T(p_1) \\ â‹® \\ \mat_T(p_m) \end{pmatrix}$
\end{itemize}

\end{definition}

Estas definiciones nos permiten hablar de pasar de polinomios a matrices y viceversa.

Lo que antes en la reducciÃ³n era restar un polinomio multiplicado por un escalar y un monomio a cada lado la idea es que ahora pase a ser restarle una fila multiplicada por un escalar a otra en la matriz, asÃ­ que vamos a tener que empezar ya teniendo en la matriz los polinomios que vamos a restar ya multiplicados por los monomios a cada lado. Para eso definimos el algoritmo de preprocesamiento simbÃ³lico que dado el conjunto por el cual se reduce $G$ y el conjunto a reducir $P$ calcula todos los polinomios que van a ser necesarios:

\begin{algorithm}[H] % La H es para que se quede acÃ¡, porque se iba a otra pÃ¡gina. EstarÃ­a bueno hacerlo global
  \caption{Preprocesamiento simbÃ³lico}\label{alg:Preprocesamiento simbÃ³lico}
  \KwData{$G, P âŠ† KâŸ¨XâŸ©$ conjuntos finitos}
  \KwResult{$G' âŠ† \{agb : a, b âˆˆ âŸ¨XâŸ©, g âˆˆ G\}$}
  $G' â† âˆ…$

  $conciderados â† \{\lm(g) : g âˆˆ G\}$

  $T â† â‹ƒ_{g âˆˆ G} \sop(\tail(g))$

  \While{$T â‰  âˆ…$} {
    elegir $m âˆˆ T$

    $T â† T - \{m\}$

    \For{$g âˆˆ G$} {
      \If{$\lm(g) | m$} {
        calcular $a$ y $b$ tales que $m = a \lm(g) b$

        $G' â† G' âˆª {agb}$

        $nuevos â† \{m' âˆˆ \sop(\tail(agb)) : m' âˆ‰ conciderados\}$

        $T â† T âˆª nuevos$

        $conciderados â† conciderados âˆª nuevos$
      }
    }
  }

  \Return{$G'$}
\end{algorithm}

Ahora lo que hay que hacer es, al reducir, elegir varios polinomios para reducir, poner los polinomios elegidos y el resultado del preprocesamiento simbÃ³lico en una matriz, hacer la reducciÃ³n por filas de esa matriz y despuÃ©s de alguna manera detectar filas son los polinomios elegidos reducidos para agregar solo esos polinomios a la base.

Para detectar esos polinomios lo que se hace es guardarse cuales son los monomios principales de elementos del resultado del preprocesamiento simbÃ³lico y despuÃ©s de hacer la reducciÃ³n por filas agarrar solo las filas que tengan un uno principal en una columna que no corresponda a uno de esos monomios principales.

Eso se puede entender mejor viene este seudocÃ³digo:

\begin{algorithm}[H] % La H es para que se quede acÃ¡, porque se iba a otra pÃ¡gina. EstarÃ­a bueno hacerlo global
  \caption{MultireducciÃ³n}\label{alg:MultireducciÃ³n}
  \KwData{$G, P âŠ† KâŸ¨XâŸ©$ conjuntos finitos}
  \KwResult{$P' âŠ† KâŸ¨XâŸ©$}
  $G' â†$ Preprocesamiento simbÃ³lico$(G, P)$

  $monomios â† \{\lm(g) : g âˆˆ G'\}$

  $M â† \{m : m âˆˆ \sop(g), g âˆˆ G' âˆª P\}$

  $mat â† \mat_M(G' âˆª P)$

  hacer reducciÃ³n por filas de $mat$

  $P' â† \{\poli_M(v) : v âˆˆ \filas(mat) : v â‰  0 âˆ§ \lm(\poli_M(v)) âˆ‰ monomios\}$

  \Return{$P'$}
\end{algorithm}

Y con esto se puede escribir el algoritmo F4:

\begin{algorithm}[H] % La H es para que se quede acÃ¡, porque se iba a otra pÃ¡gina. EstarÃ­a bueno hacerlo global
  \caption{F4}\label{alg:F4}
  \KwData{$F âŠ† KâŸ¨XâŸ©$, $e_â‰¤$ una estrategia de reducciÃ³n}
  \KwResult{$G âŠ† KâŸ¨XâŸ©$ una base de GrÃ¶bner de $(F)$ si es que termina}
  $G â† F$

  \Loop{} {
    $ambs â† \amb(G)$

    $new\_G â† G$

    \While{$ambs â‰  âˆ…$} {
      elegir $Î‘ âŠ† ambs$

      $ambs â† ambs - Î‘$

      $P â† \{\S(Î±) : Î± âˆˆ Î‘\}$

      $P â†$ MultireducciÃ³n$(new\_G, P)$

      $new\_G â† new\_G âˆª P$
    }

    \If{$new\_G = G$} {
      \Break
    }

    $G â† new\_G$
  }

  \Return{$G$}
\end{algorithm}

Este algoritmo no especifica cuales ambigÃ¼edades elegir, pero una buena estrategia es elegir todas las de manor grado. Otra opciÃ³n es elegir todas, pero eso puede hacer que las matrices se vuelvan muy grandes mÃ¡s rÃ¡pido.

En â€¦ % Citar a Hof
se da un algoritmo muy parecido a este (con una diferencia mÃ­nima) y se demuestra que es correcto. Eso acÃ¡ no estÃ¡ porque es muy tedioso.

Las optimizaciones mencionadas en la secciÃ³n de Buchberger para descartar ambigÃ¼edades y para sacar polinomios de la base tambiÃ©n se pueden hacer acÃ¡ y otra optimizaciÃ³n que se puede hacer acÃ¡ es usar un algoritmo de reducciÃ³n de matrices que anda mas rÃ¡pido en las matrices de este problema en particular,  que se llama eliminaciÃ³n FaugÃ¨re-Lachartre y que tambiÃ©n estÃ¡ explicada en â€¦. % Citar a Hof

\chapter{LibrerÃ­a}

Como se dijo al principio, para esta tesis se implementaron los algoritmos de Buchberger y F4 en C++ junto con estructuras para manejar polinomios no conmutativos. En este capÃ­tulo se explica como usar esa librerÃ­a en su versiÃ³n actual. % QuizÃ¡s habrÃ­a que aclarar que febrero de 2025 o algo asÃ­
Esa librerÃ­a se estÃ¡ en GitHub en el repositorio \href{https://github.com/IvanRenison/Non-commutative-Grobner-Bases}{\texttt{Non-commutative-Grobner-Bases}}. % EstÃ¡ bien poner esto asÃ­?

\section{Estructura de las carpetas}

El repositorio estÃ¡ estructurado en las siguientes carpetas:

\begin{itemize}
  \item \texttt{ncgb}: Esta es la carpeta mas importante, tiene archivos \texttt{.hpp} con todas las implementaciones para incluir en otros cÃ³digos y usar las implementaciones, en la siguiente secciÃ³n se explica como usar estos cÃ³digos.
  \item \texttt{mains}: En este carpeta hay varios archivos \texttt{.cpp} con funciÃ³n \texttt{main} que hacen distintas cosas. Cada archivo al comienzo tiene una pequeÃ±a explicaciÃ³n de que hace.
  \item \texttt{tests}: En esta carpeta estÃ¡n los tests, tanto los tests internos solo de cÃ³digo de la librerÃ­a como un test que compara con la implementaciÃ³n de \texttt{operator\_gb}. % QuizÃ¡s citar?
  \item \texttt{extras}: Esta carpeta lo Ãºnico que tiene es una estructura de aritmÃ©tica modular para usar en los mains.
  \item \texttt{.github/workflows}: En esta carpeta estÃ¡ la configuraciÃ³n para que los tests se corran automÃ¡ticamente al subir los cambios a GitHub.
\end{itemize}

En las siguientes secciones se explica como usar los archivos de la carpeta \texttt{ncgb}.

\section{Estructura general de los cÃ³digos}

En la carpeta \texttt{ncgb} hay varios archivos con implementaciones de las distintas cosas. Todo esos archivos tienen el cÃ³digo adentro del namespace \texttt{ncgb}, asÃ­ que para usar cualquier cosa hay que abrir \texttt{ncgb} o usar con \texttt{ncgb::}.

Como los polinomios son asociados a un cuerpo y ademÃ¡s muchas cosas dependen de un orden monomial todo lo que usa polinomios tiene parÃ¡metros de template para ambas cosas, poniendo el orden lexicogrÃ¡fico por grado como parÃ¡metro por defecto para esto Ãºltimo. Por ejemplo, la definiciÃ³n de polinomio empieza asÃ­:

\begin{minted}{C++}
  template<typename K, class ord = DegLexOrd>
  struct Poly {
    â‹®
  };
\end{minted}
% El â‹® no se ve

El tipo \texttt{K} tiene que tener implementadas todas las operaciones de cuerpo, incluyendo cosas como \texttt{+=}. En \texttt{extras/ModularArithmetic.hpp} se puede ver una implementaciÃ³n de aritmÃ©tica modular que tiene todo lo que \texttt{K} tiene que tener. Para los nÃºmeros racionales el tipo \texttt{mpq\_class} de la librerÃ­a \texttt{gmp} tambiÃ©n tiene todo lo que \texttt{K} tiene que tener. Esos dos tipos son los que se usan en los mains de ejemplo de la carpeta \texttt{mains}.

\texttt{DegLexOrd} es el orden lexicogrÃ¡fico por grado y ya estÃ¡ definido junto con la definiciÃ³n de monomios. Para usar otro orden hay que definirlo definiendo una estructura que tenga definido un operador \texttt{()} que sea el orden. Algo asÃ­ serÃ­a el cÃ³digo:

\begin{minted}{C++}
  struct Orden {
    bool operator()(const Monomial& a, const Monomial& b) const {
      â‹®
    }
  };
\end{minted}
% El â‹® no se ve

Esto es asÃ­ porque es una de las formas mas comunes de tomar un orden como template en C++.

\section{Monomios}

Los monomios estÃ¡n definidos como un tipo \texttt{Monomial} en el archivo \texttt{nc\_monomial.hpp}. Dentro del tipo las variables de representan con el tipo \texttt{Monomial::X} que estÃ¡ puesto en que sea \texttt{\_\_uint8\_t}. Para construir un elemento del tipo se puede usar el constructor vacÃ­o que crea el monomio vacÃ­o o el constructor que toma un vector de \texttt{Monomial::X} con las variables que tiene el monomio.

El tipo \texttt{Monomial} tiene implementada la multiplicaciÃ³n con \texttt{operator*} (y \texttt{operator*=}), la igualdad con \texttt{operator==}, un mÃ©todo \texttt{size} que devuelve el grado, un mÃ©todo \texttt{empty} que devuelve \texttt{true} si y solo si el monomio es el monomio vacÃ­o y varios relacionados a la divisiÃ³n y a la representaciÃ³n de los monomios como strings.

Relacionado a la divisiÃ³n el mÃ©todo mas importante es \texttt{divide\_indexes} que se llama como \texttt{m0.divide\_indexes(m1)} y devuelve un vector se \texttt{size\_t} que dice en que posiciones de \texttt{m1} empieza una sub-palabra igual a \texttt{m0}.

En cuanto a la representaciÃ³n como strings, hay dos pares de mÃ©todos, estÃ¡n \texttt{operator>>} y \texttt{operator<<} que leen y escriben en un formato de todo nÃºmeros que es cÃ³modo para usar en cÃ³digo y \texttt{nice\_print} y \texttt{nice\_read} que son para leer y escribir en el formato en el que se suelen escribir a mano los monomios.

El formato fÃ¡cil de leer desde cÃ³digo consiste en un nÃºmero entero no negativo $n$ seguido de $n$ nÃºmeros $x_1$, â€¦, $x_n$ que son los nÃºmeros de variables. Cuando $n = 0$ no hay ningÃºn $x_i$. Se puede representar asÃ­ el formato:

\begin{lstlisting}[escapechar=+]
  +$n$+ +$x_1$+ â‹¯ +$x_n$+
\end{lstlisting}

Por ejemplo, acÃ¡ hay un monomio en el formato como se suelen escribir a mano:

\begin{lstlisting}
  adbda
\end{lstlisting}

Y acÃ¡ estÃ¡ el mismo monomio en el formato fÃ¡cil de leer desde cÃ³digo:

\begin{lstlisting}[escapechar=+]
  5 0 3 1 3 0
\end{lstlisting}

\section{Polinomios}

Los polinomios estÃ¡n definidos en el archivo \texttt{nc\_polynomial.hpp}. Como ya se mostrÃ³ antes, el tipo de los polinomios, \texttt{Poly}, tiene el cuerpo y un orden monomial como parÃ¡metros de template:

\begin{minted}{C++}
  template<typename K, class ord = DegLexOrd>
  struct Poly â€¦
\end{minted}

Para construir un polinomio hay tres constructores, el constructor vacÃ­o que produce el polinomio $0$, un constructor que toma un monomio $m$ y un elemento del cuerpo $c$ y produce el polinomio $cm$ y un constructor que toma un vector de pares monomio coeficiente y produce el polinomio que es la suma de cada coeficiente multiplicado con su monomio.

El tipo \texttt{Poly} tiene implementadas todas las operaciones entre polinomios (como la suma) con los operadores correspondientes (como \texttt{operator+} y \texttt{operator+=} por ejemplo), mÃ©todos para lo definido en la \cref{def:cosas de polinomios} y mÃ©todos relacionados a la representaciÃ³n de los polinomios como strings.

Al igual que con los monomios, para la representaciÃ³n como strings, hay dos pares de mÃ©todos, \texttt{operator>>} y \texttt{operator<<} para formato de todo nÃºmeros y \texttt{nice\_print} y \texttt{nice\_read} para formato visualmente bonito.

El formato de solo nÃºmeros consiste en, primero un nÃºmero entero no negativo $m$, la cantidad de tÃ©rminos, seguido de la descripciÃ³n de $m$ tÃ©rminos. La descripciÃ³n de cada tÃ©rmino consiste en primero el coeficiente y despuÃ©s la descripciÃ³n del monomio. El coeficiente tiene se lee haciendo \texttt{>> c} donde \texttt{c} es una variable de tipo \texttt{K}, asÃ­ que \texttt{K} tiene que tener \texttt{>>} implementado para que se pueda leer polinomios. Se puede representar asÃ­ el formato:

\begin{lstlisting}[escapechar=+]
  +$m$+
  +$c_1$+ +$n_1$+ +$x_{1, 1}$+ +$â‹¯$+ +$x_{1, n_1}$+
  +$â‹®$+
  +$c_m$+ +$n_m$+ +$x_{m, 1}$+ +$â‹¯$+ +$x_{m, n_m}$+
\end{lstlisting}

Por ejemplo, acÃ¡ hay un polinomio en el formato como se suelen escribir a mano:

\begin{lstlisting}
  3 aaa - 5 bcc + adbda
\end{lstlisting}

Y acÃ¡ estÃ¡ el mismo monomio en el formato fÃ¡cil de leer desde cÃ³digo:

\begin{lstlisting}[escapechar=+]
  3
  3 3 0 0 0
  -5 3 1 2 2
  1 5 0 3 1 3 0
\end{lstlisting}

\section{Buchberger y F4}

Los algoritmos de Buchberger y F4 estÃ¡n ambos hechos de una forma que se usan similar, asÃ­ que por eso estÃ¡n explicados juntos.

Como ambos algoritmos tienen el problema de que puede no terminar no se puede hacer directamente una funciÃ³n que tome el conjunto generador y devuelva una base de GrÃ¶bner porque podrÃ­a no terminar.

Se podrÃ­a hacer una funciÃ³n que ademÃ¡s del conjunto generador tome un nÃºmero que sea la cantidad de pasos a ejecutar y que ademÃ¡s de devolver un conjunto devuelva si se llegÃ³ a una base de GrÃ¶bner o no. Esta opciÃ³n tiene el problema de que si se quiere despuÃ©s hacer mas pasos de la ejecuciÃ³n habrÃ­a que volver a empezar, llamando a la funciÃ³n con un nÃºmero mas grande.

Para evitar ese problema lo que se hizo es definir una estructura que el constructor tome a los polinomios y tenga un mÃ©todo \texttt{next} que calcula un paso mas del calculo de la base de GrÃ¶bner y en caso de haber terminado lo dice y un mÃ©todo \texttt{fullBase} para usar solo en el caso de que se sepa que hay una base finita, que hace las llamadas a \textt{next} hasta que termina y devuelve la base.

Para Buchberger la estructura estÃ¡ en el archivo \texttt{Buchberger.hpp} y se llama \texttt{BuchbergerIncremental} y para F4 la estructura estÃ¡ en el archivo \texttt{F4.hpp} y se llama \texttt{F4Incremental}. En el caso de Buchberger el mÃ©todo \texttt{next} devuelve un \texttt{std::optional<Poly<K, ord>>} que es vacÃ­o solo en el caso de que ya se haya llegado a una base de GrÃ¶bner y si no tiene un polinomio de la base de GrÃ¶bner. En el caso de F4 el mÃ©todo \texttt{next} devuelve un \texttt{std::vector<Poly<K, ord>>} que es vacÃ­o solo en el caso de que ya se haya llegado a una base de GrÃ¶bner y si no tiene varios polinomios de la base de GrÃ¶bner. En ambos casos devolver vacÃ­o es la forma de decir que ya terminÃ³ el algoritmo.

Para ambos algoritmos hay ademÃ¡s una funciÃ³n \texttt{inIdeal} que toma un conjunto generador, un polinomio y una cantidad pasos y trata de decir si el polinomio estÃ¡ en el ideal generado por el conjunto generador haciendo esa cantidad de llamada a \texttt{next}. Esa funciÃ³n devuelve un elemento de el siguiente tipo (con los significados que estÃ¡n comentados comentados):

\begin{minted}{C++}
  enum IdealMembershipStatus {
    InIdeal,    // The element is definitely in the ideal
    NotInIdeal, // The element is definitely not in the ideal
    Unknown     // More steps are needed to determine if the element is in the ideal
  };
\end{minted}

Esa funciÃ³n serÃ­a bÃ¡sicamente la que trata de responder a la pregunta que plantemos al comienzo de si un polinomio estÃ¡ en el ideal generado por un conjunto generador.

\section{ConstrucciÃ³n de la respuesta}

La funciÃ³n \texttt{inIdeal} hace lo de intentar responder a la pregunta de si un polinomio estÃ¡ en el ideal generado por un conjunto generador, pero en el caso de que la respuesta es que si estÃ¡ no nos da la forma de escribirlo como combinaciÃ³n lineal de elementos del conjunto generador con polinomios como coeficientes.

Con las bases de GrÃ¶bner pasa lo mismo, los algoritmos nos dan la base pero no nos dan como se escriben los elementos de la base usando los elementos del conjunto generador.

AsÃ­ como estÃ¡n todo en la explicaciÃ³n del algoritmo de Buchberger no nos da una forma directa de construir esa escritura. Pero, en todos los pasos en los que se manejan polinomios siempre se hace sumando o restando polinomios del conjunto generador o que ya estÃ¡n en la base, asÃ­ que se puede para cada polinomio ir guardando siempre que sea hace con el y usar eso para obtener la escritura usando los elementos del conjunto generador.

Para el caso de F4 no es tan directo, pero si cuando se hace la reducciÃ³n por filas de la matriz se guarda que operaciones por filas se hicieron tambiÃ©n se puede.

Para Buchberger esto estÃ¡ implementado en el mismo archivo \texttt{Buchberger.hpp} en unas funciones y structs que terminan en \texttt{Reconstruct} (esta terminaciÃ³n es porque van guardando la informaciÃ³n que permite \emph{reconstruir} la respuesta).

Estas funciones lo que hacen es devolver elementos del tipo \texttt{InIdealPoly} definido en el archivo \texttt{nc\_polyonomial\_inIdeal.hpp}. Este tipo lo que hace es representar un polinomio como una combinaciÃ³n lineal de elementos del conjunto generador, en particular guarda un vector de elementos $m$, $j$, $m'$, $c$ de forma que, si los $g_i$ son el conjunto generador, el polinomio representado es $âˆ‘ m g_i m' c$.

Para F4 esto no estÃ¡ implementado (en el siguiente capitulo se dice porque).

\chapter{ImplementaciÃ³n}

En este capitulo se explican los detalles de como estÃ¡ hecha la implementaciÃ³n.

\section{ComparaciÃ³n de bases}

Por Ãºltimo para esta secciÃ³n, en el archivo \texttt{cmpBases.hpp} estÃ¡ la funciÃ³n \texttt{cmpBases} que toma dos conjuntos generadores y, asumiendo que son bases de GrÃ¶bner, dice si generan el mismo ideal o no.

\section{Monomios}

Los monomios, o sea los elementos de $âŸ¨XâŸ©$, como son palabras se implementaron usando vectores para de nÃºmeros sin signo. La base de la implementaciÃ³n es asÃ­:

\begin{minted}{C++}
  struct Monomial {
    typedef __uint8_t X;
    vector<X> vals;
  };
\end{minted}

Con esto, como \texttt{\_\_uint8\_t} tiene 8 bits se pueden tener hasta 256 variables. Cuando los monomios se imprimen o leen de forma bonita solo hay 26 variables, correspondiendo el 0 con la \texttt{a}. Si se quiere imprimir de forma bonita un monomio que usa variables mayores o iguales a 26 salta una aserciÃ³n.

EstÃ¡ estructura tiene implementadas las operaciones y mÃ©todos que se describieron en el capitulo anterior. La mayorÃ­a tienen una implementaciÃ³n directa. Las Ãºnicas no directas son las relacionadas a la division, porque chequear divisibilidad es chequear si una palabra es sub-palabra de otra, lo cual la forma directa de hacerlo lleva tiempo cuadrÃ¡tica (en el largo de la palabras), pero se puede hacer en tiempo lineal.

Hay muchas formas de hacerlo en tiempo lineal, la que se usÃ³ es usar la funciÃ³n Z (que en el cÃ³digo estÃ¡ en el archivo \texttt{Zfunc.hpp}). En â€¦ % Citar a cp-algorithms: https://cp-algorithms.com/string/z-function.html
se explica la funciÃ³n Z y como usarla para chequear si una palabra es sub-palabra de otra.
% TambiÃ©n quizÃ¡s tiene sentido aclarar que no es la misma que la funciÃ³n Î¶ de Riemann, que es lo primero que aparece al buscar en google "funciÃ³n Z"

Junto con la implementaciÃ³n de los monomios, en el archivo \texttt{nc\_monomial.hpp} estÃ¡ la implementaciÃ³n del orden lexicogrÃ¡fico por grado.

\section{Polinomios}

Los polinomios, o sea los elementos de $KâŸ¨XâŸ©$ estÃ¡n implementados usando un vector de pares monomio coeficiente que siempre se mantiene ordenado por el orden monomial. La base de la implementaciÃ³n es asÃ­:

\begin{minted}{C++}
  template<typename K, class ord = DegLexOrd>
  struct Poly {
    vector<pair<Monomial, K>> terms;
  };
\end{minted}

Con esta estructura para los polinomios todas las operaciones se hace de forma directa.

El orden de los polinomios estÃ¡ definido como \texttt{template<typename K, class ord = DegLexOrd> struct PolyOrd}.

\section{Reducciones}

La reducciÃ³n estÃ¡n implementadas en el archivo \texttt{reductions.hpp}, en particular en la funciÃ³n \texttt{reduce} que toma un polinomio y un vector de polinomios y reduce el polinomio con los polinomios del vector. La reducciÃ³n se hace modificando el propio argumento. Esa funciÃ³n serÃ­a una implementaciÃ³n de una estrategia de reducciÃ³n concreta.

Esa reducciÃ³n concreta lo que hace es siempre tratar de reducir por los primeros elementos del vector primero y tratar de reducir primero los monomios mas grandes del polinomio.

En el archivo tambiÃ©n hay una funciÃ³n \texttt{reduce} que ademÃ¡s toma un vector de booleanos que tiene que ser del mismo largo que el vector de polinomios y hace la reducciÃ³n solo con los polinomios que tengan un \texttt{true} en la misma posiciÃ³n en el vector de booleanos. Esta funciÃ³n estÃ¡ para poder implementar la optimizaciÃ³n de ir eliminando algunos elementos de la base sin tener que estar modificando un vector.

\section{AmbigÃ¼edades}

Las ambigÃ¼edades, que son necesarias para el algoritmo de Buchberger estÃ¡n implementadas en el archivo \texttt{ambiguities.hpp} y conciten en una estructura asÃ­:

\begin{minted}{C++}
  struct Amb {
    const Monomial& p, q;
    enum Type { Inclusion, Overlap };
    Type type;
    size_t pos; // position where q starts in p
    Monomial a, b;
  };
\end{minted}

Y los mÃ©todos \texttt{size} y \texttt{lm}.

Los campos de la ambigÃ¼edad son:

\begin{itemize}
  \item \texttt{p} y \texttt{q} son referencias a los monomios sobre los cuales es la ambigÃ¼edad. El motivo por el cual se guardan en la estructura es para poder implementar una de las optimizaciones.
  \item \texttt{type} es si la ambigÃ¼edad es de inclusiÃ³n o de sobreposiciÃ³n.
  \item \texttt{pos} es en que posiciÃ³n de \texttt{p} empieza el pedazo que es en comÃºn con \texttt{q} y por el cual existe la ambigÃ¼edad.
  \item \texttt{a} y \texttt{b} son los monomios que hacen que en el caso de las de inclusiÃ³n \texttt{p} sea igual a \texttt{aqb} y en el caso de las de sobreposiciÃ³n \texttt{ap} sea igual a \texttt{qb}.
\end{itemize}

En el archivo tambiÃ©n estÃ¡ \texttt{ambiguities} que toma dos monomios y devuelve un vector de \texttt{Amb} con todas las ambigÃ¼edades entre sos dos monomios. En esta funciÃ³n al igual que en la divisibilidad de monomios se usa la funciÃ³n Z para evitar tener que hacer algo cuadrÃ¡tico en los largos de los monomios.

DespuÃ©s en el archivo estÃ¡ la funciÃ³n \texttt{S\_poly}que toma una ambigÃ¼edad y dos polinomios que deberÃ­an ser pos polinomios correspondientes y desvuelve el S-polinomio correspondiente.

Y por Ãºltimo estÃ¡ la funciÃ³n \texttt{checkDeletionCriteria} que implementa la optimizaciÃ³n que permite descartar algunas ambigÃ¼edades sin tener que reducirlas.


\section{Buchberger}

Como ya se dijo antes, por el tema de que el algoritmo puede no terminar, se hace lo de usar una estructura con una mÃ©todo \texttt{next}. En esa estructura ya estÃ¡ implementada las optimizaciones antes mencionadas, pero en esta secciÃ³n primero se explica como serÃ­a la estructura sin esas optimizaciones y despuÃ©s algo de como se agregan.

La base de esa estructura es asÃ­:

\begin{minted}{C++}
  template<typename K, class ord = DegLexOrd>
  struct BuchbergerIncremental {
    std::vector<Poly<K, ord>> G;
    std::queue<std::tuple<Amb, size_t, size_t>> ambs;
    size_t t = 0;
  };
\end{minted}

Los campos de esta estructura guardan los siguiente:

\begin{itemize}
  \item \texttt{G} es la base de GrÃ¶bner que se estÃ¡ construyendo. Al principio se inicializa con los polinomios con los que se llama al constructor.
  \item \texttt{ambs} son las ambigÃ¼edades que todavÃ­a no se procesaron junto con los Ã­ndices en \texttt{G} de los polinomios a los que corresponde la ambigÃ¼edad. Se usa una queue para procesar siempre la que hace mas tiempo estÃ¡ esparando.
  \item La variable \texttt{t} estÃ¡ porque como la base de GrÃ¶bner incluye a los polinomios originales las primeras llamadas a \texttt{next} tienen que devolver esos polinomios y \texttt{t} lo que hace es indicar cuantos de esos ya se devolvieron. Cuando \texttt{t} es igual al tamaÃ±o de \texttt{G} es porque ya se devolvieron todos esos.
\end{itemize}

% La estructura ademÃ¡s de tener los mÃ©todos \texttt{next} y


\end{document}
