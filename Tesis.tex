\documentclass{report}

\usepackage{polyglossia}
\setdefaultlanguage{spanish}

\usepackage{amsthm}
\usepackage{fontspec}
\usepackage{enumitem}
\usepackage[bookmarks]{hyperref}
\defaultfontfeatures{Renderer=Basic,Ligatures={TeX}}
\usepackage[math-style=ISO,bold-style=ISO]{unicode-math}
\setmathfont{Asana Math}
\usepackage{witharrows}
\WithArrowsOptions{fleqn,displaystyle,i,tikz={font={\small\normalfont}},ygap=0.5em,wrap-lines}

\DeclareEmphSequence{\bfseries}

\hfuzz=50pt % Elimina warnings de "Overfull \hbox"

\usepackage[margin=5mm]{geometry} % Adjust the margin values as desired

\usepackage{float}
\usepackage[ruled, vlined, linesnumbered]{algorithm2e}
\SetKw{Break}{break}
\SetKwFor{Loop}{loop}{}{end loop}

\usepackage{listings}
\lstset{basicstyle=\ttfamily} % Cambia la fuente a monospace
\usepackage{minted}

\usepackage[capitalise]{cleveref}

\setlist[enumerate,1]{label={\em{(\arabic*)}}}

\newtheoremstyle{customstyle} % <name>
{} % <Space above>
{} % <Space below>
{\slshape} % <Body font> % Preguntar que opinan, y porque hay un warning
{1.5em} % <Indent amount>
{\bfseries} % <Theorem head font>
{.} % <Punctuation after theorem head>
{.5em} % <Space after theorem head>
{} % <Theorem head spec (can be left empty, meaning `normal`)

\theoremstyle{customstyle}
\newtheorem{definition}{Definición}[chapter]
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}{Lema:}[chapter]
\addto\captionsspanish{\renewcommand{\proofname}{Demostración}}
\renewenvironment{proof}[1][\proofname]{{\bfseries #1: }}{\qed} % Cambiar estilo del título de la demostración

\newtheoremstyle{factstyle} % <name>
{} % <Space above>
{} % <Space below>
{\normalfont} % <Body font> % Preguntar que opinan, y porque hay un warning
{1.5em} % <Indent amount>
{\bfseries} % <Theorem head font>
{.} % <Punctuation after theorem head>
{.5em} % <Space after theorem head>
{} % <Theorem head spec (can be left empty, meaning `normal`)

\theoremstyle{factstyle}
\newtheorem{fact}{Afirmación}[theorem]



\DeclareMathOperator{\sop}{sop}
\DeclareMathOperator{\lm}{lm}
\DeclareMathOperator{\lc}{lc}
\DeclareMathOperator{\lt}{lt}
\DeclareMathOperator{\tail}{tail}
\DeclareMathOperator{\amb}{amb}
\renewcommand{\S}{\text{S}}
\DeclareMathOperator{\B}{B}
\DeclareMathOperator{\spn}{spn} % span está ocupado y re rompe todo si lo re-declaro
\DeclareMathOperator{\mat}{mat}
\DeclareMathOperator{\poli}{poli}
\DeclareMathOperator{\filas}{filas}


\begin{document}
\fontsize{16pt}{19pt}\selectfont % Increase the font size

\chapter{Introducción informal}

En este capitulo se explica informalmente mas o menos de que se trata el tema de la tesis.

Usted posiblemente haya escuchado hablar de los polinomios de varias variables, esos como $5  + 3 y - 2 x y + x^3 y^5$ y que todo el conjunto de los polinomios con, por ejemplo, variables $x, y$ sobre un cuerpo $K$ se denota como $K[x, y]$.

En esos polinomios es producto entre las variables conmuta, así que es lo mismo el polinomio $x y$ que el polinomio $y x$. Se puede considerar que eso no pasa, que el producto de las variables no conmuta, así que $x y ≠ y x$, (pero que el producto de las variables con los coeficientes si conmuta, así que por ejemplo $x 3 y = 3 x y$). Al hacer eso se obtiene algo como los polinomios, pero en el que los monomios son palabras. A esos polinomios se los llama polinomios no conmutativos y, por ejemplo, para las variables $x, y$ con coeficientes en un cuerpo $K$ se denota como $K⟨x, y⟩$ y en general si $X$ es un alfabeto, $K⟨X⟩$ es el conjunto de los polinomios no conmutativos sobre $X$.

Una problema de decisión que existe sobre los polinomios no conmutativos es, dado un conjunto $G$ de polinomios no conmutativos y un polinomio no conmutativo $f$ es decidir si $f$ se pude escribir como combinación lineal lineal de elementos de $G$ con coeficientes en $K⟨X⟩$, o escrito formalmente determinar si:

\[ ∃n ∈ ℕ, g_1, …, g_n ∈ F, f_1, …, f_n, f'_1, …, f'_n ∈ K⟨X⟩ : f = ∑_{i = 1}^n f_i g_i f'_i \]

Este problema en el caso general no es computable, pero si se puede hacer un algoritmo que si es verdadero termina y si no puede no terminar, o hacer un algoritmo que intenta determinarlo y puede devolver que si, que no, o que no sabe pero podría llegar a averiguarlo si sigue computando (así como podría no averiguarlo nunca).

Para eso se considera el conjunto $(G)$ de todos los polinomios no conmutativos que satisfacen ese $∃$ y se calcula algo que se llama una base de Gröbner de $(G)$, la cual puede ser finita o infinita computacionalmente enumerable y son estos últimos casos los que hacen que el problema no sea computable.

Para calcular esas bases de Gröbner hay dos algoritmos principales, llamados algoritmo de Buchberger y F4.

Antes de ahora ya hubo varias implementaciones de esos algoritmos, siendo la mas importante \texttt{operator\_gb} hecha por Clemens Hofstadler en python usando \texttt{sagemath} y que está explicada en … % Citar a Hof
junto con una explicación de toda la teoría (mucho mas en detalle que en esta tesis).

Como esa implementación está hecha en python y no corre en paralelo, el objetivo original de esta tesis fue implementar en C++ esos algoritmos y hacerlos correr en paralelo.

La parte de implementar en C++ esos algoritmos se logró, pero hay una optimización que ayuda bastante y no se hizo. La parte de hacerlo correr en paralelo se hizo, pero solo para una parte y para la parte de la optimización que no se hizo tampoco se hizo nada en paralelo. Hacer esa optimización podría ser un trabajo para una tesis futura.

\chapter{Definiciones preliminares}\label{cap:Definiciones preliminares}

En este capitulo se explica toda la parte matemática, basada principalmente en la explicación de …. % Citar a Hof
En particular, primero se explican sistemas de re-escritura, después se introduce el álgebra libre, se prueba que es un anillo, se dan algunas definiciones y teoremas de anillos y se definen las bases de Gröbner y por último se explican y dan seudocódigos para los algoritmos de Buchberger y F4, que son los dos algoritmos importantes para calcular bases de Gröbner no conmutativas.

Muchos de los conceptos y definiciones tienen un análogo en el caso conmutativo, pero eso no se cubre acá. Para una explicación de eso se puede leer …. % Citar al libro de Ideals, Varieties, and Algorithms

\section{Sistemas de re-escritura}

En esta sección se explican algunas definiciones y teoremas básicos de sistemas de re-escritura. En esta parte es muy probable que a cualquiera que haya estudiado computación muchas cosas ya las conozca o le suenen, pero están acá para que se puede entender mejor sin tener que buscar nada en otro lado.

Sistemas de re-escritura se trata básicamente del estudio de relaciones entre objetos con la idea de usar las relaciones para convertir un objeto a otro. Vamos a en general usar relaciones denotados con algún símbolo con forma de flecha porque está la idea de que se ``usa'' la relación para convertir el objeto de la izquierda en el objeto de la derecha.

Para toda está sección fijemos un conjunto $A$. Primero definimos algunas operaciones muy comunes sobre relaciones.

\begin{definition} Sean $→, ⟿ ⊆ A^2$ relaciones sobre $A$:
  \begin{itemize}
    \item $→ ∘ ⟿ = \{(x, z) ∈ A^2 : ∃y ∈ A : x → y ∧ y ⟿ z\}$
    \item $→^0 = \{(x, x) : x ∈ A\}$
    \item $→^{n + 1} = →^n ∘ →$
    \item $→^* = ⋃_{n = 0}^∞ →^n$
    \item $← = \{(y, x) ∈ A^2 : (x, y) ∈ →\}$
    \item $↔ = → ∪ ←$
  \end{itemize}
\end{definition}

Para el resto de la sección fijemos $→$ una relación sobre $A$.

Como vamos a hablar de usar $→$ para transformar un objeto en otro, es útil la proxima definiciones que nos permiten haber de la forma normal de un objeto como el elemento un que se llega aplicando $→$ hasta que no se puede mas.

\begin{definition}\
  \begin{itemize}
    \item $a$ está en forma normal $⇔ ∄x ∈ A : a → x$
    \item $b$ es forma normal de $a ⇔ a →^* b ∧ b$ está en forma normal
    \item $a$ tiene forma normal $⇔ ∃x ∈ A : x$ es forma normal de $a$
    \item $a ↓ b ⇔ ∃x ∈ A : a →^* x ∧ b →^* x$
  \end{itemize}
\end{definition}

Y también vamos a necesitar definir algunas propiedades sobre las relaciones:

\begin{definition}\
  \begin{itemize}
    \item $→$ es confluente $⇔ ∀x, y, z ∈ A : x →^* y ∧ x →^*z ⇒ y ↓ z$
    \item $→$ es Church-Rosser $⇔ ∀x, y ∈ A : x ↔️^* y ⇔ x ↓ y$
    \item $→$ es normalizante $⇔ ∀x ∈ A : x$ tiene forma normal
    \item $→$ es terminante $⇔ ∄X ∈ A^ℕ : ∀i ∈ ℕ : X_i → X_{i + 1}$
  \end{itemize}
\end{definition}

Sobre estas propiedades tenemos estos teoremas:

\begin{theorem}\label{thm:terminante ⇒ normalizante}
  $→$ es terminante $⇒ →$ es normalizante
\end{theorem}

\begin{theorem}\label{thm:confluente ⇔ Church-Rosser}
  $→$ es confluente $⇔ →$ es Church-Rosser
\end{theorem}

\section{Álgebra libre}

El álgebra libre es básicamente el conjunto de los polinomios no conmutativo con sus operaciones. En esta sección está toda la parte de la tesis de el álgebra libre.

En los polinomios no conmutativos los monomios son básicamente palabras y lo único que se puede hacer con los monomios entre si es multiplicarlos que equivale a concatenar la palabras. En la proxima definición se define eso.

\begin{definition}
  Sea $X$ un alfabeto finito. Se define la estructura $(⟨X⟩, ·)$ de la siguiente manera:
  \begin{itemize}
    \item $⟨X⟩$ son las palabras finitas sobre $X$
    \item $· : ⟨X⟩^2 → ⟨X⟩$ es la concatenación
  \end{itemize}
  A los elementos de $⟨X⟩$ se los llama monomios libres sobre $X$, a $·$ el producto de $⟨X⟩$ y a $(⟨X⟩, ·)$ el monoide libre sobre $X$.
\end{definition}

Por ejemplo, si $X = \{a, b, c\}$ algunos monomios son:

\begin{align*}
  m_0 &= abbcb \\
  m_1 &= bbc \\
  m_2 &= bcb \\
  m_3 &= ε \\
  m_1 · m_2 &= bccbcb
\end{align*}

El $ε$ de $m_3$ es la palabra vacía. Notar que $m_1 ≠ m_2$ ya que el producto es no es conmutativo.

A partir de ahora para todo el resto de la tesis fijamos $X$ un alfabeto finito.

En estos monomios al igual que no los conmutativos se puede hablar de que un monomio divida a otro, pero acá que un monomio divida a otro es equivalente a que un un monomio sea sub-palabra de otro.

\begin{definition}
  Sean $v, w ∈ ⟨X⟩$:
  \begin{itemize}
    \item $v | w ⇔ ∃a , b ∈ ⟨X⟩ : w = avb$
  \end{itemize}
  Y cuando $v | w$ se dice que $v$ divide a $w$.
\end{definition}

En el ejemplo de antes tenemos por ejemplo $m_1 | m_0$ ya que $m_0 = a m_1 b$.

De lo que es un poco mas complicado hablar acá es de el resultado de la división porque es como que tendría que haber dos resultados, así que no vamos a hablar de dividir un monomio en otro ni escribir divisiones entre monomios.

Mas adelante va a ser necesario tener un orden entre los elementos de $⟨X⟩$, pero no es necesario fijar uno concreto, así que lo que vamos a hacer es definir las propiedades que tienen que tener un orden para servir y trabajar con un orden cualquiera que las cumpla.

\begin{definition}
  Sea $≤$ un orden total sobre $⟨X⟩$, definimos que $≤$ es un buen orden monomial si y solo si:
  \begin{enumerate}
    \item $∀v, w, a, b ∈ ⟨X⟩ : v ≤ w ⇒ avb ≤ awb$
    \item $∀S ⊆ ⟨X⟩ : S ≠ ∅ ⇒ S$ tiene mínimo elemento con respecto a $≤$
  \end{enumerate}
\end{definition}

En ejemplo de orden que cumple con esta definición es el siguente:

\begin{definition}
  Fijemos $X = \{x_1, …, x_n\}$ y un orden total sobre $X$: $x_1 ≤ … ≤ x_n$, el cual se extiende (como es usual) de forma lexicográfica a $⟨X⟩$. El orden lexicográfico por grado $ ≤_{deglex}$ sobre $⟨X⟩$ se define así:
  \[ a ≤_{deglex} b ⇔ |a| < |b| ∨ (|a| = |b| ∧ a ≤ b) \]
\end{definition}

O sea, el orden lexicográfico por grado es orden primero por cardinalidad, que se llama grado también y desempatar por orden lexicográfico, por ejemplo tenemos $bc ≤_{deglex} abb$, $aabbc ≤_{deglex} abbcc$ y $ε ≤_{deglex} a$.

Se puede probar fácilmente que este orden es un bueno orden monomial.

A partir de ahora fijamos un buen orden monomial $≤$ y vamos a usar $<$, $≥$ y $>$ como se usan habitualmente.

Una propiedad sobre el orden monomial que es consecuencia directa de la definición es la siguiente:

\begin{theorem}\label{thm:≤ no cadenas dec inf}
  La relación $≤$ no tiene cadenas estrictamente decrecientes infinitas
\end{theorem}

Ahora pasemos a hablar de sumar monomios entre si para tener polinomios no conmutativos.

\begin{definition}[Álgebra libre (asociativa)]
  Sea $R$ un anillo conmutativo. Se define $R⟨X⟩$ la $R$-álgebra libre sobre $X$ como:
  \[ R⟨X⟩ = \{∑_{i = 1}^n c_i w_i : c_1, …, c_n ∈ R, w_1, …, w_n ∈ ⟨X⟩\} \]

  La suma en $R⟨X⟩$ se define de la manera esperable.

  El producto por escalares de define como:
  \[ c (∑_{i = 1}^n c_i w_i) = (∑_{i = 1}^n c c_i w_i) \]

  El producto entre elementos de $R⟨X⟩$ se define como:
  \[ (∑_{i = 1}^n c_i w_i) · (∑_{i = 1}^m c'_i w'_i) = ∑_{i = 1}^n ∑_{j = 1}^m c_i c'_j w_i w'_j \]

  A los elementos de $R⟨X⟩$ se los llama polinomios no conmutativos.
  % Esta definición creo que hay que mejorarla, pero no se como
\end{definition}

Esta definición puede ser medio difícil de entender exactamente que está haciendo, pero es lo que se espera que sean los polinomios no conmutativos y sus operaciones. Algunos ejemplos de polinomios no conmutativos sobre $ℚ⟨\{a, b, c\}⟩$ son los siguientes:
\[ p_0 = a \]
\[ p_1 = ab + cb \]
\[ p_2 = 3 abb + 4 bcca - 2 acab \]

Notar que $p_1 ≠ ab + bc$ ya que el producto es no conmutativo.

Sobre los polinomios no conmutativos se hacen las siguientes definiciones que después vamos a usar mucho:

\begin{definition}\label{def:cosas de polinomios}
  Sean $R$ un anillo conmutativo, $p ∈ R⟨X⟩$, $c_1, …, c_n ∈ R$, $w_1, …, w_n, w ∈ ⟨X⟩$, $f = ∑_{i = 1}^n c_i w_i$ y $≤$ un buen orden monomial.
  \begin{itemize}
    \item $f_w = \left\{\begin{array}{ll} w = w_i → c_i \\ \text{si no} → 0  \end{array} \right.$
    \item $\sop(f) = \{w_1, …, w_n\}$
    \item $\lm_≤(f) = \min_≤(\sop(f))$
    \item $\lc_≤(f) = f_{\lm(f)}$
    \item $\lt_≤(f) = \lc_≤(f) · \lm_≤(f)$
    \item $\tail_≤(f) = f - \lt_≤(f)$
    \item $f$ es mónico $⇔ \lc_≤(f) = 1$
  \end{itemize}

  A $\sop(f)$ se lo llama soporte de $f$, a $\lm_≤(f)$ se lo llama monomio principal de $f$, a $\lc_≤(f)$ se lo llama coeficiente principal de $f$ y a $\lt_≤(f)$ se lo llama término principal de $f$. Los nombres lm, lc, lt y tail vienen del inglés leading monomial, leading coefficient, leading term y tail respectivamente.
\end{definition}

La estructura del álgebra libre es un anillo, lo cual nos va a ser muy útil por muchas definiciones y teoremas que ya existen sobre los anillos.

\begin{theorem}
  Sea $R$ un anillo conmutativo, entonces:
  \[ (R⟨X⟩, +, ·)\text{ es un anillo} \]
\end{theorem}

Las definiciones y teoremas sobre anillos que vamos a usar las vamos a repasar a continuación para no tener que estar buscándolos en otro lado.

\begin{definition}\label{def:ideal}
  Sean $R$ un anillo e $I, B ⊆ R$, definimos que $I$ es un ideal de $R$ si y solo si:
  \begin{enumerate}
    \item $I ≠ ∅$
    \item $∀a, b ∈ I : a + b ∈ I$
    \item $∀a ∈ I, r, r' ∈ R : r a r' ∈ I$
  \end{enumerate}
  \[ (B) = \{∑_{i = 1}^n c_i b_i c_i' : n ∈ ℕ, b_1, …, b_n ∈ B, c_1, …, c_n, c_1', …, c_n' ∈ R\} \]
\end{definition}

Los ideales son básicamente conjuntos cerrados por suma producto por elementos cualquiera y $(B)$ es el ideal generado por $B$.

\begin{theorem}
  Sean $R$ un anillo y $B ⊆ R$, entonces:
  \[ (B)\text{ es un ideal de }R \]
\end{theorem}

Cada ideal define una clase de equivalencia en el anillo, la cual se llama congruencia modulo el ideal.

\begin{definition}[Congruencia modulo un ideal]\label{def:congruencia mod ideal}
  Sean $R$ un anillo e $I ⊆ R$, se define $≡_I$ como relación en $R$ así:
  \[ a ≡_I b ⇔ a - b ∈ I \]
\end{definition}

\begin{theorem}\label{thm:congruencia mod ideal es equivalencia}
  Sean $R$ un anillo y $I ⊆ R$ un ideal, entonces:
  \[ ≡_I \text{es una relación de equivalencia} \]
\end{theorem}

Esta congruencia es parecida a la de los números modulo otro número (de hecho la congruencia de los números modulo otro número es un subcaso de esta tomando como ideal a todos los múltiplos del modulo) y vale que la clase de equivalencia del $0$ es el propio ideal:

\begin{theorem}\label{thm:en ideal ⇔ congruente 0}
Sean $R$ un anillo, $I ⊆ R$ un ideal y $a ∈ R$, entonces:
\[ a ∈ I ⇔ a ≡_I 0 \]
\end{theorem}

Por último, con respecto al ideal generado por un conjunto tenemos el siguiente teorema.

\begin{theorem}\label{thm:gen B = gen B U a con a ∈ gen B}
  Sean $R$ un anillo, $B ⊆ R$ y $a ∈ (B)$, entonces:
  \[ (B) = (B ∪ {a}) \]
\end{theorem}

Ahora volvemos al álgebra libre y a partir de ahora fijamos un cuerpo $K$.

Con las definiciones que tenemos ahora la pregunta que planteábamos en la introducción se puede escribir como dado un conjunto finito $F ⊆ K⟨X⟩$ y un elemento $f ∈ K⟨X⟩$, determinar si $f ∈ (F)$. Ahora nos vamos a poner con el tema de esa pregunta.

Para varias cosas va a ser necesario comparar no solo monomios si no también polinomios, así que el orden $≤$ se extiende a $K⟨X⟩$ así:

\begin{definition}
  Sean $f, g ∈  K⟨X⟩$, definimos que $f < g$ si y solo si vale alguna de las siguientes:
  \begin{enumerate}
    \item $f = 0 ∧ g ≠ 0$
    \item $\lm_≤(f) < \lm_≤(g)$
    \item $\lm(f) = \lm(g) ∧ \tail(f) < \tail(g)$
  \end{enumerate}
  Y $f ≤ g$ si y solo si $f < g ∨ f = g$.
\end{definition}

Es decir, el orden en los polinomios es orden lexicográfico con el polinomio visto como una lista de monomios, sin coeficientes, ordenada de mayor a menor.

Por ejemplo, tenemos estas desigualdades en $K⟨X⟩$:
\[ a < ab \]
\[ bcc + c < bcc + abb \]
\[ ac < ac + aa \]

Si bien a este $<$ lo estamos llamando (y lo vamos a seguir llamando) orden en realidad no es un orden si no un pre-orden porque cuando solo cambian los coeficientes entre un polinomio y otro ninguno de los polinomios es menor que el otro.

\begin{theorem}
  La relación $<$ en $K⟨X⟩$ es un pre-orden parcial.
\end{theorem}

Sobre este orden hay varias propiedades que vamos a necesitar y que están enunciadas y probadas a continuación.

\begin{theorem}\label{thm:≤ en KX no cadenas dec inf}
  La relación $≤$ en $K⟨X⟩$ no tiene cadenas estrictamente decrecientes infinitas.
\end{theorem}
\begin{proof}
  Supongamos que existen cadenas estrictamente decreciente infinita. Tomemos una $P$ que minimize $\lm(P_1)$. Tomar este mínimo es posible por el \cref{thm:≤ no cadenas dec inf}

  Notar que:

  \begin{fact}\label{fact:≤ en KX no cadenas dec inf:1}
    $∀i ∈ ℕ : \lm(P_i) = \lm(P_1)$
  \end{fact}
  En efecto, no puede ser $\lm(P_i) < \lm(P_1)$ porque entonces $P_i, P_{i + 1}, …$ sería una cadena estrictamente decreciente infinita que rompería la minimalidad de $\lm(P_1)$ y no puede ser $\lm(P_i) > \lm(P_1)$ porque $P$ es una cadena estrictamente decreciente.

  \begin{fact}\label{fact:≤ en KX no cadenas dec inf:2}
    $\tail(P_1), \tail(P_2), …$ es una cadena estrictamente decreciente infinita.
  \end{fact}
  Esto vale por aplicar la definición del orden polinomial, por la \cref{fact:≤ en KX no cadenas dec inf:1} y por lo que estamos suponiendo sobre $P$.

  Como claramente $0$ es un mínimo:

  \begin{fact}\label{fact:≤ en KX no cadenas dec inf:3}
    $P_1 ≠ 0$.
  \end{fact}

  Sin embargo, la \cref{fact:≤ en KX no cadenas dec inf:2} contradice la minimalidad de $\lm(P_1)$ ya que por la \cref{fact:≤ en KX no cadenas dec inf:3} vale que $\lm(\tail(P_1)) < \lm(P_1)$.

\end{proof}

Ahora vamos a definir una relación de reducción en los polinomios no conmutativos (y acá es donde entre lo de sistemas de re-escritura).

La relación que vamos a definir va a ser dependiente de el orden monomial y de un conjunto de polinomios no conmutativos y lo que va a hacer es tratar de achicar un polinomio con los elementos del conjunto para que llega a quedar lo menor posible con respecto al orden polinomial.

Para definirla además de definirla para un conjunto de la define para un solo polinomio y un polinomio y dos monomios de forma auxiliar.

\begin{definition}
  Sean $F ⊆ K⟨X⟩$, $g ∈ K⟨X⟩ - \{0\}$, $a, b ∈ ⟨X⟩$ y $f, f' ∈ K⟨X⟩$:
  \begin{itemize}
    \item $f →_{≤, a, g, b} f' ⇔ \lm_≤(agb) ∈ \sop(f) ∧ f' = f - \frac{f_{\lm_≤(agb)}}{\lc_≤(g)}agb$
    \item $→_{≤, g} = ⋃_{a, b ∈ ⟨X⟩} →_{≤, a, g, b}$
    \item $→_{≤, F} = ⋃_{g ∈ F} →_{≤, g}$
  \end{itemize}
\end{definition}

A continuación la prueba de que efectivamente achica.

\begin{theorem}[Las reducciones achican]\label{thm:→ achican}
  Sean $F ⊆ K⟨X⟩$, $g ∈ K⟨X⟩ - \{0\}$, $a, b ∈ ⟨X⟩$ y $f, f' ∈ K⟨X⟩$, entonces:
  \begin{enumerate}
    \item $f →_{≤, a, g, b} f' ⇒ f' < f$
    \item $f →_{≤, g} f' ⇒ f' < f$
    \item $f →_{≤, F} f' ⇒ f' < f$
  \end{enumerate}
\end{theorem}
  \begin{proof}
  Por definición de las reducciones tenemos que (1) $⇒$ (2) $⇒$ (3), por lo cual alcanza con probar (1). Para ello supongamos el antecedente $f →_{≤, a, g, b} f'$

  Esto implica por definición de reducciones:
  \begin{enumerate}
    \setcounter{enumi}{3}
    \item $\lm_≤(agb) ∈ \sop(f)$
    \item $f' = f - \frac{f_{\lm_≤(agb)}}{\lc_≤(g)}agb$
  \end{enumerate}

  Escribamos $f = ∑_{i = 1}^n c_i m_i$ con $c_1, …, c_n ∈ K$, $m_1, …, m_n ∈ ⟨X⟩, m_1 > m_2 > ⋯ > m_n$

  Sea $i$ tal que $m_i = \lm_≤(agb)$, el cual existe por (4).

  \begin{fact}\label{fact:→ achican:3}
    Notar también que $m_i = \lm_≤(\frac{f_{\lm_≤(agb)}}{\lc_≤(g)}agb)$ porque es multiplicar por un escalar adentro del $\lm$ en la condición de $i$.
  \end{fact}
  \begin{description}
    \item[Si $i ≠ 0$] la \cref{fact:→ achican:3} significa que los términos $c_1 m_1, c_2 m_2, …, c_{i-1}, m_{i-1}$ son iguales en $f$ y en $f'$ y no hay nada mas en el medio, porque $f'$ es $f$ con cosas menores o iguales a $\lm_≤(\frac{f_{\lm_≤(agb)}}{\lc_≤(g)}agb)$ restadas (por (5)).

    Además, como $m_i = \lm_≤(\frac{f_{\lm_≤(agb)}}{\lc_≤(g)}agb)$, tenemos que $f'_{m_i} = 0$, por ende, el término que sigue después de $m_{i-1}$ (si es que hay) es menor que $m_i$ y por ende menor que $f$.

    \item[Si $i = 0$] aplica lo mismo pero directamente a $m_0$ solo que sin tener en cuenta los $m$ anteriores.
  \end{description}

\end{proof}

Está relación tiene un montón de propiedades que van a hacer falta y que se prueban a continuación.

\begin{theorem}\label{thm:suma →↓}
  Sean $F ⊆ K⟨X⟩, f, f_0, f_1 ∈ K⟨X⟩$, entonces:
  \[ f_0 →_{≤, F} f_1 ⇒ f_0 + f ↓_{≤, F} f_1 + f \]
\end{theorem}
\begin{proof}
  Supongamos el antecedente $f_0 →_{≤, F} f_1$.

  Sean $g ∈ F, a, b ∈ K⟨X⟩$ tales que $f_1 = f_0 - \frac{{f_0}_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb$, los cuales existen por el antecedente y por definición de $→_{≤, F}$.

  Dividamos en casos según si $\lm_≤(agb) ∈ \sop(f)$:

  \begin{description}
    \item[Caso $\lm_≤(agb) ∉ \sop(f)$]\

    En este caso tenemos $f_0 + f →_{≤, F} f_1 + f$ por tomar $g$, $a$ y $b$, y por ende tenemos $f_0 + f ↓_{≤, F} f_1 + f$

    \item[Caso $\lm_≤(agb) ∈ \sop(f)$]\
    \begin{description}
      \item[Subcaso $f_{\lm_≤(agb)} = -{f_0}_{\lm_≤(agb)}$]

      Este es el caso en el que $\lm_≤(agb)$ se cancela en la suma $f_0 + f$. Y como además $\lm_≤(agb) ∉ \sop(f_1)$ por el antecedente, tenemos:

      \begin{DispWithArrows*}
        &f_1 + f →_{≤, F} f_1 + f - \frac{f_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb \Arrow{Subcaso} \\
        & ⇒ f_1 + f →_{≤, F} f_1 + f + \frac{{f_0}_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb \Arrow{Condición de $g$, $a$ y $b$} \\
        & ⇒ f_1 + f →_{≤, F} f_0 + f \\
        & ⇒ f_1 + f ↓_{≤, F} f_0 + f
      \end{DispWithArrows*}

      \item[Subcaso $f_{\lm_≤(agb)} ≠ -{f_0}_{\lm_≤(agb)}$] En este caso $\lm_≤(agb)$ no se cancela en la suma $f_0 + f$, así que podemos aplicar $→_{≤, F}$:
      \begin{DispWithArrows*}
        &f_0 + f →_{≤, F} f_0 + f - \frac{(f_0 + f)_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb \\
        & ⇒ f_0 + f →_{≤, F} f_0 + f - \frac{{f_0}_{\lm_≤(agb)} + f_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb \\
        & ⇒ f_0 + f →_{≤, F} f_0 + f - \frac{{f_0}_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb - \frac{f_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb \Arrow{Condición de $g$, $a$ y $b$}\\
        & ⇒ f_0 + f →_{≤, F} f_1 + f - \frac{f_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb
      \end{DispWithArrows*}
        Llamemos (1) a este último resultado.

      Además por el caso y por subcaso también tenemos $\lm_≤(agb) ∈ \sop(f_1 + f)$, así que tenemos:
      \begin{DispWithArrows*}
        &f_1 + f →_{≤, F} f_1 + f - \frac{(f_1 + f)_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb \\
        & ⇒ f_1 + f →_{≤, F} f_1 + f - \frac{{f_1}_{\lm_≤(agb)} + f_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb \Arrow{$\lm_≤(agb) ∉ \sop(f_1)$ porque $f_0 →_{≤, F} f_1$ y definición de $→_{≤, F}$}\\
        & ⇒ f_1 + f →_{≤, F} f_1 + f - \frac{0 + f_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb \\
        & ⇒ f_1 + f →_{≤, F} f_1 + f - \frac{f_{\lm_≤(agb)}}{g_{\lm_≤(agb)}} agb
      \end{DispWithArrows*}
        Llamemos (2) a este último resultado.

      Por (1) y (2) tenemos $f_0 + f ↓_{≤, F} f_1 + f$
    \end{description}
  \end{description}
\end{proof}

\begin{theorem}[Clausura reflexo transitiva de las reducciones]\label{thm:→^* = ≡}
  Sea $F ⊆ K⟨X⟩$, entonces:
  \[ ↔^*_{≤, F} = ≡_{(F)} \]

  (Donde $≡_{(F)}$ es la congruencia modulo un ideal definida en la \cref{def:congruencia mod ideal})
\end{theorem}
\begin{proof}
  Lo vamos a probar por doble inclusión
  \begin{description}
    \item[Prueba de $↔^*_{≤, F} ⊆ ≡_{(F)}$] Como tanto $↔^*_{≤, F}$ como $≡_{(F)}$ son relaciones de equivalencia y además $↔^*_{≤, F}$ es la mínima relación de equivalencia que contiene a $→_{≤, F}$, alcanza con probar $→_{≤, F} ⊆ ≡_{(F)}$. Para eso supongamos $f →_{≤, F} f'$ y probemos $f ≡_{(F)} f'$.

    Sean $g ∈ F, a, b ∈ ⟨X⟩$ tales que $f' = f - \frac{f_{\lm_≤(agb)}}{\lc_≤(g)}agb$, los cuales existen por lo que estamos suponiendo y por la definición de $→_{≤, F}$. Tenemos:

    \begin{DispWithArrows*}
      &f ≡_{(F)} f' \\
      & ⇔ f - f' ∈ (F) \\
      & ⇔ f - (f - \frac{f_{\lm_≤(agb)}}{\lc_≤(g)}agb) ∈ (F) \\
      & ⇔ \frac{f_{\lm_≤(agb)}}{\lc_≤(g)}agb ∈ (F)
    \end{DispWithArrows*}
    Y esto último es claramente cierto por la definición de ideal (\cref{def:ideal})

    \item[Prueba de $≡_{(F)} ⊆ ↔^*_{≤, F}$] Supongamos $f ≡_{(F)} f'$ y probemos $f ↔^*_{≤, F} f'$.

    Sean:
    \begin{itemize}
      \item $g = f - f'$.
      \item $c_1, …, c_n, c_1', …, c_n' ∈ K⟨X⟩$, $g_1, …, g_n ∈ F$ tales que $g = ∑_{i = 1}^n c_i g_i c_i'$, los cuales existen porque por definición de $≡_·$ tenemos $g ∈ (F)$ y por definición de $(\ ·\ )$.
      \item $f_0 = f$
      \item Para cada $i ∈ \{1, …, n\}$: $f_i = f_{i - 1} - c_i g_i c_i'$.
    \end{itemize}

    Tenemos entonces:

    \begin{DispWithArrows*}
      &∀i ∈ \{1, …, n\} : g_i →_{≤, F} 0 \\
      & ⇒ ∀i ∈ \{1, …, n\} : - c_i g_i c_i' →_{≤, F} 0 \Arrow{\cref{thm:suma →↓}} \\
      & ⇒ ∀i ∈ \{1, …, n\} : f_{i - 1} ↓_{≤, F} f_i \\
      & ⇒ ∀i ∈ \{1, …, n\} : f_{i - 1} ↔^*_{≤, F} f_i \\
      & ⇒ f_0 ↔^*_{≤, F} f_n \Arrow{$f_n = f - g = f'$}\\
      & ⇒ f ↔^*_{≤, F} f_n
    \end{DispWithArrows*}

  \end{description}
\end{proof}

\begin{theorem}[Las reducciones se mantienen en ideal]\label{thm:→ mantiene pertenencia a ideal}
  Sean $F ⊆ K⟨X⟩, f, f' ∈ (F)$, entonces:
  \[ f →^*_{≤, F} f' ⇒ (f ∈ (F) ⇔ f' ∈ (F)) \]
\end{theorem}
\begin{proof}
  Si asumimos $f →^*_{≤, F} f'$ tenemos por el \cref{thm:→^* = ≡} $f ≡_{(F)} f'$ y entonces por el \cref{thm:en ideal ⇔ congruente 0} tenemos $f ∈ (F) ⇔ f' ∈ (F)$
\end{proof}

\begin{theorem}
  Sea $F ⊆ K⟨X⟩$, entonces:
  \begin{itemize}
    \item $→_{≤, F}$ es terminante
  \end{itemize}
\end{theorem}
\begin{proof}
  Lo vamos a demostrar por contradicción. Supongamos que $→_{≤, F}$ no es terminante, por definición de terminante podemos tomar una cadena $P ∈ K⟨X⟩^ℕ$ tal que:

  $∀i ∈ ℕ : P_i →_{≤, F} P_{i+1}$

  Por el \cref{thm:→ achican} tenemos que:

  $∀i ∈ ℕ : P_i > P_{i+1}$

  Pero esto contradice el \cref{thm:≤ en KX no cadenas dec inf} que dice que no hoy cadenas estrictamente decrecientes infinitas en $K⟨X⟩$.

\end{proof}

\begin{theorem}[Caracterización de las formas normales de $→$]
  Sea $F ⊆ K⟨X⟩, f ∈ K⟨X⟩$, entonces: % Por algún motivo acá se pone solo un salto de linea extra
  \[ f\text{ está en forma normal con respecto a} →_{≤, F} ⇔ ∄g ∈ F, m ∈ \sop(f) : \lm(g) | m \]
\end{theorem}
\begin{proof}
  Por contradicción, supongamos que tenemos $g ∈ F, m ∈ \sop(f)$ tales que $\lm(g) ∈ \sop(f)$.

  Sean $a, b ∈ ⟨X⟩$ tal que $m = agb$, los cuales existen por la definición de divisibilidad.

  Entonces tenemos $f →_{≤, F} f - \frac{f_{\lm_≤(agb)}}{\lc_≤(g)}agb$ y por ende $f$ no está en forma normal.

\end{proof}

Probamos que $→_{≤, F}$ es terminante, pero, no necesariamente es confluente. Que fuera confluente sería muy util porque significaría que para cualquier clase de equivalencia de $≡_{(F)}$ podríamos siempre llegar a una misma forma normal y así poder determinar si dos elementos son equivalentes (y en particular por poder determinar si un elemento está en el idea viendo si se llega a $0$ como la forma normal).

Sin embargo en algunas casos $→_{≤, F}$ si es confluente. Esos casos en lo que si es terminante se llaman bases de Gröbner y lo que vamos a hacer después es calcular una base de Gröbner de un ideal generado por un conjunto que no es base de Gröbner.

\begin{definition}[Bases de Gröbner]\label{def:base de Gröbner}
  Sean $I$ un ideal de $K⟨X⟩$ y $F ⊆ K⟨X⟩$:
  \begin{itemize}
    \item $F$ es una base de Gröbner de $I ⇔ (F) = I ∧ →_{≤, F}$ es confluente
  \end{itemize}
\end{definition}

Como en algunos casos $→_{≤, F}$ no es confluente vamos la siguiente definición nos perimite hablar mas comodamente de una forma normal de un elemento (tanto en las definiciones teoremas como en los algoritmos).

\begin{definition}
  Sea $e_≤ : 𝒫(K⟨X⟩) → K⟨X⟩ → K⟨X⟩$:
  \begin{itemize}
    \item $e_≤$ es una estrategia de reducción $⇔ ∀F ⊆ K⟨X⟩, f ∈ K⟨X⟩ : e_≤(F)(f)$ es forma normal de $f$ con respecto a $→_{≤, F}$
  \end{itemize}
\end{definition}

Un ejemplo de estrategia de reducción podría calcularse con el siguiente seudocódigo:

\begin{algorithm}[H] % La H es para que se quede acá, porque se iba a otra página. Estaría bueno hacerlo global
  \caption{Ejemplo de estrategia de reducción}\label{alg:estrategia de reducción}
  \KwData{$F = \{f_1, …, f_n\} ⊆ K⟨X⟩, g ∈ K⟨X⟩$}
  \KwResult{$g' ∈ K⟨X⟩$}
  $g' ← g$

  $i ← 1$

  \While{$i ≤ n$} {
    \While{$i ≤ n$} {
      \If{$f_i ∈ \sop(g')$} {
        $g' ← g' - \frac{g'_{\lm(f_i)}}{\lc(f_i)}f_i$

        $i ← 1$

        \Break
      }
      \Else{
        $i ← i + 1$
      }
    }
  }
  \Return{$g'$}
\end{algorithm}

Este algoritmo consiste básicamente en siempre buscar entre los elementos de $G$ si hay alguno con el que reducir, y parar cuando ya no hay ninguno.

Una propiedad sobre las estrategias de reducción que vamos a necesitar es la siguiente:

\begin{lemma}[Las estrategias de reducción mantienen la pertenencia a ideales]\label{lemma:e mantiene pertenencia a ideal}
  Sean $e_≤$ una estrategia de reducción, $F ⊆ K⟨X⟩$ y $f ∈ (F)$, entonces:
  \[ e_≤(F)(f) ∈ (F) \]
\end{lemma}
\begin{proof}
  Es consecuencia directa de la definición y del \cref{thm:→ mantiene pertenencia a ideal}.
\end{proof}

Las bases de Gröbner se definieron por la propiedad mas importante que queremos que tengan, pero para poder usarlas van a hacer falta las siguientes equivalencias.

\begin{theorem}\label{thm:equivalencias de base de Gröbner}
  Sean $I$ un ideal de $K⟨X⟩$ y $G ⊆ K⟨X⟩$. Las siguientes afirmaciones son equivalentes:
  \begin{enumerate}
    \item $G$ es una base de Gröbner de $I$

    \item $∀f ∈ K⟨X⟩ : (f ∈ I ⇔ f →^*_{≤, G} 0)$

    \item $∀f ∈ K⟨X⟩ : (f ∈ I ⇒ f →^*_{≤, G} 0)$

    \item $(G) = I ∧ ∀f ∈ I : ∃g ∈ G : \lm(g) | \lm(f)$

    \item $∀f ∈ I - \{0\} : ∃g_1, …, g_n ∈ G, a_1, …, a_n, b_1, …, b_n ∈ ⟨X⟩ : \lm(a_i g_i b_i) ≤ \lm(f) : f = ∑_{i = 1}^n a_i g_i b_i$
  \end{enumerate}

\end{theorem}
\begin{proof} Vamos a probar (1) $⇒$ (2), (2) $⇒$ (1), (2) $⇔$ (3), (2) $⇒$ (4), (4) $⇒$ (3), (2) $⇒$ (5) y (5) $⇒$ (4).
  \begin{description}

    \item[(1) $⇒$ (2)] Supongamos que $G$ es una base de Gröbner de $I$ y tomemos $f ∈ K⟨X⟩$. Tenemos que probar $f ∈ I ⇔ f →^*_{≤, G} 0$. Vamos de un lado para el otro:

    \begin{DispWithArrows*}
      &f ∈ I \Arrow{\cref{thm:en ideal ⇔ congruente 0}} \\
      & ⇔ f ≡_I 0 \Arrow{\cref{thm:→^* = ≡}} \\
      & ⇔ f ↔^*_{≤, G} 0 \Arrow{Al ser $G$ una base de Gröbner $→_{≤, G}$ es confluente y por ende por el \cref{thm:confluente ⇔ Church-Rosser} es Church-Rosser, así que aplico el sii de Church-Rosser} \\
      & ⇔ f ↓_{≤, G} 0 \Arrow{Definición de $↓$} \\
      & ⇔ ∃f' ∈ K⟨X⟩ : f →^*_{≤, G} f' ∧ 0 →^*_{≤, G} f' \Arrow{Como $0$ es el mínimo elemento y el \cref{thm:→ achican} dice que las reducciones achican el segundo término del $∧$ ocurre solo para $f' = 0$} \\
      & ⇔ f →^*_{≤, G} 0
    \end{DispWithArrows*}

    \item[(2) $⇒$ (1)]
    Supongamos (2), o sea $∀f ∈ K⟨X⟩ : (f ∈ I ⇔ f →^*_{≤, G} 0)$. Tenemos que probar que $G$ es una base de Gröbner de $I$, es decir $(G) = I ∧ →_{≤, G}$ es confluente.

    Probemos cada termino del $∧$ por separado:

    \begin{description}
      \item[Prueba de $(G) = I$] Tomemos $f ∈ K⟨X⟩$ y probemos $f ∈ (G) ⇔ f ∈ I$, probando ida y vuelta por separado:

      \begin{description}
        \item[Ida ($⇒$)] Supongamos antecedente $f ∈ (G)$.

        Sean $c_1, …, c_n, c_1', …, c_n' ∈ K⟨X⟩$, $g_1, …, g_n ∈ G$ tales que $f = ∑_{i = 1}^n c_i g_i c_i'$, los cuales existen por la definición de $(\ ·\ )$.

        Definamos $f_0 = f$ y para $i ∈ \{1, …, n\}$ $f_i = f_{i-1} - c_i g_i c_i'$.

        Notar que tenemos $∀i ∈ \{1, …, n\} : f_{i-1} →_{≤, G} f_i$ y que $f_n = 0$.

        Esto significa que $f →^*_{≤, G} 0$ y por ende por (2) vale $f ∈ I$.

        \item[Vuelta ($⇐$)] Supongamos el antecedente $f ∈ I$.

        Por (2) tenemos que $f →^*_{≤, G} 0$

        Así que sean $f_0, f_1, …, f_n ∈ K⟨X⟩$ tales que $f_0 = f$, $f_n = 0$ y $∀i ∈ \{1, …, n\} : f_{i-1} →_{≤, G} f_i$, los cuales existen por la definición de $^*$.

        Además, para cada $i ∈ \{1, …, n\}$ sean $c_i, c_i' ∈ K⟨X⟩, g_i ∈ G$ tales que $f_i = f_{i-1} - c_i g_i c_i'$, los cuales existen por definición de $→_{≤, G}$.

        Notar que en particular $f_{i-1} = f_i + c_i g_i c_i'$ y por ende $f = ∑_{i = 1}^n c_i g_i c_i'$, lo cual prueba que $f ∈ (G)$.

      \end{description}

      \item[Prueba de $→_{≤, G}\text{ es confluente}$]\

      Por definición de confluencia alcanza que probar $∀f, f_0, f_1 ∈ K⟨X⟩ : f →^*_{≤, G} f_0 ∧ f →^*_{≤, G} f_1 ⇒ f_0 ↓_{≤, G} f_1$.

      Así que tomemos $f, f_0, f_1 ∈ K⟨X⟩$ y probemos el implica yendo de un lado para el otro.
      \begin{DispWithArrows*}
        &f →^*_{≤, G} f_0 ∧ f →^*_{≤, G} f_1 \\
        & ⇒ f_0 ↔^*_{≤, G} f_1 \Arrow{\cref{thm:→^* = ≡}} \\
        & ⇒ f_0 ≡_{(G)} f_1 \Arrow{Definición $≡_{\ ·\ }$} \\
        & ⇒ f_0 - f_1 ∈ (G) \Arrow{(6), ya probamos que $(G) = I$} \\
        & ⇒ f_0 - f_1 →^*_{≤, G} 0 \Arrow{\cref{thm:suma →↓}} \\
        & ⇒ (f_0 - f_1) + f_1 ↓_{≤, G} 0 + f_1 \\
        & ⇒ f_0 ↓_{≤, G} f_1
      \end{DispWithArrows*}
    \end{description}

    \item[(2) $⇔$ (3)] La ida es claramente cierta y la vuelta $f ∈ I ⇐ f →^*_{≤, G} 0$ es cierta por el \cref{thm:→^* = ≡}.

    \item[(2) $⇒$ (4)] Supongamos (2).

    La parte de $(G) = I$ es valida porque (2) $⇒$ (1) y $(G) = I$ es parte de la definición de base de Gröbner.

    Para la parte de $∀f ∈ I : ∃g ∈ G : \lm(g) | \lm(f)$ tomemos $f ∈ I$ y mostremos un $g$ que cumple el $∃$:

    Por (2) tenemos $f →^*_{≤, G} 0$, esto significa que en alguno de los pasos de el $→^*_{≤, G}$ se tiene que reducir el monomio principal de $f$, o sea, uno de los pasos es de la forma $→_{≤, a, g, b}$ tal que $a \lm(g) b = \lm(f)$ con $g ∈ G, a, b ∈ ⟨X⟩$, por lo tanto, tenemos que $\lm(g) | \lm(f)$.

    \item[(4) $⇒$ (3)] Lo probamos por contradicción, o sea, supongamos que vale (4) y que no vale (3). En particular tomemos el mínimo $f$ tal que $f ∈ I$ pero no se cumple que $f →^*_{≤, G} 0$.

    Por (4) sea $g ∈ G$ tal que $\lm(g) | \lm(f)$ y sean también:
    \begin{itemize}
      \item $a, b ∈ ⟨X⟩$ tales que $a \lm(g) b = \lm(f)$
      \item $f' = f - \frac{f_{\lm_≤(agb)}}{\lc_≤(g)}agb$
    \end{itemize}

    Notar que $f' ∈ I$ ya que $f ∈ I$ y $g ∈ (G) = I$ y notar que $f →_{≤, G} f'$.

    Además por \cref{thm:→ achican} $f' < f$.

    Y como no vale $f →^*_{≤, G} 0$ tampoco puede valer $f' →^*_{≤, G} 0$, sin embargo esto contradice que $f$ sea mínimo.

    \item Los casos (2) $⇒$ (5) y (5) $⇒$ (4) son fáciles y quedan como ejercicio. % Son fáciles pero es un viaje

  \end{description}
  Con esto se termina la prueba.
\end{proof}


\section{Algoritmo de Buchberger}

En esta sección se explica un primer algoritmo para calcular bases de Gröbner llamado Algoritmo de Buchberger.

Este algoritmo se llama así porque es similar a un algoritmo en los polinomios conmutativos que fue inventado por alguien llamado Buchberger, pero no porque lo haya inventado Buchberger.

Antes de poder calcular bases de Gröbner algo que vamos a querer hacer es poder computar si un conjunto es una Base de Gröbner, porque ninguna de las equivalencias de \cref{thm:equivalencias de base de Gröbner} es directamente calculable porque hacen cuantificaciones sobre conjuntos infinitos.

Para eso vamos a definir algo llamado S-polinomio de dos polinomios que lo que hace es básicamente multiplicar cada polinomio por monomios a cada lado y por un escalar de forma que los monomios principales se cancelen. O sea para polinomios $f$ y $g$ vamos a tener una cuenta $k a f b - c g d$ de forma que se cancelen los monomios principales.

Para eso antes definimos las ambigüedades que representan los polinomios para los cuales puede pasar eso sin que todo lo importante esté en los monomios $a$, $b$, $c$ y $d$.

\begin{definition}
  Sean $p, q, a, b, c, d ∈ ⟨X⟩$
  \[ (a, b, c, d, p, q)\text{ es una ambigüedad} ⇔ apb = cqd ∧ |a|, |b| < |q| ∧ |c|, |d| < |p| \]

  La ambigüedad $(a, b, c, d, p, q)$ se dice que es:
  \begin{itemize}
    \item De superposición $⇔ a = ε = d ∨ b = ε = c$
    \item De inclusión $⇔ a = ε = b ∨ c = ε = d$
    \item Relevante $⇔$ es de superposición o de inclusión
  \end{itemize}

  Además, si $f, g ∈ K⟨X⟩$ se dice que $(a, b, c, d, f, g)$ es una ambigüedad si y solo si $(a, b, c, d, \lm_≤{(f)}, \lm_≤{(g)})$ es una ambigüedad y lo mismo para ambigüedades de superposición, de inclusión y relevantes.

  Sea además $F ⊆ K⟨X⟩$:
  \begin{itemize}
    \item $\amb(f, g) = \{(a, b, c, d, f, g) : a, b, c, d ∈ ⟨X⟩ ∧ (a, b, c, d, f, g)\text{ es una ambigüedad}\}$
    \item $\amb(F) = ⋃_{f, g ∈ F - \{0\}}{\amb(f, g)}$
  \end{itemize}

\end{definition}

\begin{definition}
  Sean $a, b, c, d ∈ ⟨X⟩, f, g ∈ K⟨X⟩$ y $α = (a, b, c, d, f, g)$ una ambigüedad.
  \[ \S(α) = \frac{afb}{\lc_≤{(f)}} - \frac{cgd}{\lc_≤{(g)}} \]
\end{definition}

Notar que por como es la definición de ambigüedad, siempre es como que hay una parte de $p$ y una parte de $q$ que son iguales y que no están en los monomios $a$, $b$, $c$ y $d$.

Ahora vamos a probar que los S-polinomios hacen eso que dijimos que hacen y después vamos a dar el teorema para calcular si un conjunto es una base de Gröbner.

\begin{theorem}\label{thm:lm ambs}
  Sean $a, b, c, d ∈ ⟨X⟩$ y $f, g ∈ K⟨X⟩$ entonces si $α = (a, b, c, d, f, g)$ es una ambigüedad tenemos que:
  \[ \lm_≤{(afb)} = \lm_≤{(cgd)} \]
\end{theorem}
\begin{proof}\
  \begin{DispWithArrows*}
    &\lm_≤{(afb)} \Arrow{Definición de ambigüedad para polinomios} \\
    & = a\lm_≤{(f)}b \Arrow{Definición de ambigüedad} \\
    & = c\lm_≤{(g)}d \Arrow{Definición de ambigüedad para polinomios} \\
    & = \lm_≤{(cgd)}
  \end{DispWithArrows*}
\end{proof}

Eso nos permite definir el monomio principal de una ambigüedad.

\begin{definition}
  Sean $a, b, c, d ∈ ⟨X⟩, f, g ∈ K⟨X⟩$ y $α = (a, b, c, d, f, g)$ una ambigüedad:
  \[ \lm_≤{(α)} = \lm_≤{(afb)} \]
\end{definition}

Notar que por el \cref{thm:lm ambs} también vale que $\lm_≤{(α)} = \lm_≤{(cgb)}$.

Lo de que los monomios principales se cancelen se enuncia en el siguiente teorema.

\begin{theorem}
  Sean $a, b, c, d ∈ ⟨X⟩, f, g ∈ K⟨X⟩$ y $α = (a, b, c, d, f, g)$ una ambigüedad, entonces:
  \[ \lm_≤{(\S(α))} < \lm_≤{(α)} \]
\end{theorem}
\begin{proof}
  Esto es porque en la resta $\frac{afb}{\lc_≤{(f)}} - \frac{cgd}{\lc_≤{(g)}}$ los monomios principales se cancelan.
\end{proof}

Otra cosa importante es que estos S-polinomios son cerraros en el ideal, es decir que el S-polinomio de dos elementos de un ideal, por ejemplo en particular del conjunto generador, es un elemento del ideal.

\begin{theorem}\label{thm:S es cerrado en ideal}
  Sean $I ⊆ K⟨X⟩$ un ideal $a, b, c, d ∈ ⟨X⟩, f, g ∈ I$ y $α = (a, b, c, d, f, g)$ una ambigüedad, entonces:
  \[ \S(α) ∈ I \]
\end{theorem}
  \begin{proof}
  En la definición de $\S$ se ve claramente que es una combinación lineal de $f$ y $g$ con elementos de $K⟨X⟩$ (en particular con los elementos $\frac{a}{\lc_≤{(f)}}$, $b$, $\frac{c}{\lc_≤{(g)}}$ y $d$)
\end{proof}

Ahora si damos el anunciado teorema para computar si un conjunto es una base de Gröbner.

\begin{theorem}[Condición de Buchberger]\label{thm:condición de Buchberger)}
  Sean $I$ un ideal de $K⟨X⟩$ y $G ⊆ K⟨X⟩$.

  Son equivalentes:
  \begin{enumerate}
    \item $G$ es una base de Gröbner de $I$
    \item $∀α ∈ \amb(G) : \S(α) →^*_{≤, G} 0$
  \end{enumerate}
\end{theorem}
% TODO: Agregar prueba. De cualquier manera, Hof no lo prueba a esto

Con esto ya se puede explicar la idea del algoritmo de Buchberger.

Cuando estamos chequeando si un conjunto es una base de Gröbner usando el \cref{thm:condición de Buchberger)} si nos encontramos con un S-polinomio $p$ que se reduce a un polinomio $q$ que es distinto de $0$ lo que podemos hacer es agregar $q$ al conjunto y con eso $p$ si se va a reducir a $0$.

Se podría pensar que agregar $q$ por ahí cambia el ideal generado, pero por el teorema \cref{thm:S es cerrado en ideal} sabemos que $q$ es un elemento del ideal y por el \cref{thm:→ mantiene pertenencia a ideal} eso implica que $p$ también está en el ideal y por ende por el \cref{thm:gen B = gen B U a con a ∈ gen B} se puede agregar al conjunto y que el ideal generado siga siendo el mismo.

El problema con eso de agregar un nuevo polinomio es que si bien hay una S-polinomio que pasa a si reducirse a $0$ también aparecen nuevas ambigüedades. Eso sin embargo no es tanto problema porque lo se hace es hacer eso hasta que en algún momento todas las ambigüedades se reducen a $0$ y si eso no pasa nunca simplemente el algoritmo no termina nunca (ya habíamos dicho que el problema de pertenencia a un ideal no es decidible, así que si o si va a haber alguna cosa así inusual en cualquier algoritmo que hagamos).

Ese proceso de agregar polinomios infinitamente lo definimos matemáticamente con la siguiente definición.

\begin{definition}
  Sean $F ⊆ K⟨X⟩$ y $e_≤$ una estrategia de reducción:
  \begin{itemize}
    \item $\B_{e_≤}^0(F) = F$
    \item $\B_{e_≤}^{i + 1}(F) = \B_{e_≤}^i(F) ∪ \{e_≤(\B_{e_≤}^i(F))(\S(α)) : α ∈ \amb(\B_{e_≤}^i(F))\}$
    \item $\B_{e_≤}(F) = ⋃_{i = 0}^∞ \B_{e_≤}^i(F)$
  \end{itemize}
\end{definition}

Y a esos conjuntos los llamamos bases de Buchberger (este nombre es un nombre inventado para esta tesis, otros autores no le han dado ningún nombre concreto a esos conjuntos).

Podemos enunciar que esos conjuntos realmente hacen lo que dijimos arriba y además que si hay una base de Gröbner finita entonces en algún momento se llega, con el siguiente teorema.

\begin{theorem}\label{thm:Buchberger correctitud}
  Sean $F ⊆ K⟨X⟩$ y $e_≤$ una estrategia de reducción, entonces:
  \begin{enumerate}
    \item $\B_{e_≤}(F)$ es una base de Gröbner de $(F)$
    \item $(F)$ tiene una base de Gröbner finita $⇒ ∃i ∈ ℕ : (\B_{e_≤}^i(F))$ es una base de Gröbner
  \end{enumerate}
\end{theorem}

Con lo que dijimos antes tiene sentido que (q) sea cierto, pero que (2) sea cierto no es para nada obvio. Para probar ambos items primero vamos a probar algunos lemas en el contexto de este teorema (o sea con $F$ y $e_≤$ fijados).

\begin{lemma}\label{lemma:Buchberger correctitud:3}
  $∀i ∈ ℕ : \B_{e_≤}^{i}(F) ⊆ (F)$
\end{lemma}
\begin{proof}
  Por inducción en $i$ el caso base es valido porque $F ⊆ (F)$, para el caso inductivo supongamos que vale para $i$ y probemos que vale para $i + 1$:

  Tomemos $f ∈ \B_{e_≤}^{i + 1}(F)$ y probemos que $f ∈ (F)$.

  Por la definición recursiva de $\B_{e_≤}^{i + 1}$ tenemos $f ∈ \B_{e_≤}^i(F) ∨ ∃α ∈ \amb(\B_{e_≤}^i(F)) : f = e_≤(\B_{e_≤}^i(F))(\S(α))$.

  El caso $f ∈ \B_{e_≤}^i(F)$ es valido por hipótesis inductiva. Para el otro caso tomemos ese $α$.

  Por el \cref{thm:S es cerrado en ideal} tenemos que $\S(α) ∈ \B_{e_≤}^i(F)$ y por la hipótesis inductiva que $\S(α) ∈ (F)$.

  Esto implica por el \cref{lemma:e mantiene pertenencia a ideal} que $e_≤(\B_{e_≤}^i(F))(\S(α)) ∈ \B_{e_≤}^i(F)$ y por la hipótesis inductiva que $e_≤(\B_{e_≤}^i(F))(\S(α)) ∈ (F)$.
\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:4}
  $∀i ∈ ℕ : \B_{e_≤}(F) ⊆ (F)$
\end{lemma}
\begin{proof}
  Esto es consecuencia directa de la \cref{lemma:Buchberger correctitud:3} y la definición de $\B_{e_≤}$.
\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:5}
  $(\B_{e_≤}(F)) = (F)$
\end{lemma}
\begin{proof}
  Esto vale porque por el caso base de la definición de $\B_{e_≤}^i$ tenemos $F ⊆ \B_{e_≤}$ y por la \cref{lemma:Buchberger correctitud:4}.
\end{proof}

\begin{lemma}\label{lemma:Buchberger correctitud:6}
  $∀α ∈ \amb(\B_{e_≤}(F)) : \S(α) →^*_{≤, \B_{e_≤}(F)} 0$
\end{lemma}
\begin{proof}
  Tomemos $α = (a, b, c, d, f, g) ∈ \amb(\B_{e_≤}(F))$ y probemos el $∀$.

  Por definición de $\amb$ vale que $f, g ∈ \B_{e_≤}(F)$, así que sea $i ∈ ℕ$ el mínimo tal que $f ∈ \B_{e_≤}^i(F)$, $j ∈ ℕ$ el mínimo tal que $g ∈ \B_{e_≤}^j(F)$ y $k = \max(i, j)$.

  Notar que $α ∈ \amb(\B_{e_≤}^k(F))$ por la definición de $\amb$ y por ende $\S(α) ∈ \B_{e_≤}(F)$.

  Por definición de $→^*_{≤, F}$ esto significa que $\S(α) →^*_{≤, \B_{e_≤}(F)} 0$, así que queda probada la afirmación.
\end{proof}

\begin{proof}[Demostración del \cref{thm:Buchberger correctitud}]
  Por el \cref{lemma:Buchberger correctitud:5} y el \cref{lemma:Buchberger correctitud:6} vale la equivalencia de base de Gröbner del \cref{thm:condición de Buchberger)}, así que (1) queda probado.

  Ahora para probar (2) supongamos el antecedente y tomemos $G = \{g_1, …, g_n\}$ una base de Gröbner finita de $(F)$.

  Para cada $i ∈ \{1, …, n\}$ sean:
  \begin{itemize}
    \item $g_{i, 1}, …, g_{i, k_i} ∈ \B_{e_≤}(F), a_{i, 1}, …, a_{i, k_i}, b_{i, 1}, …, b_{i, k_i} ∈ ⟨X⟩$ con $\lm(a_{i, j} g_{i, j} n_{i, j}) ≤ \lm(g_i)$ tales que $g_i = ∑_{j = 1}^{k_i} a_{i, j} g_{i, j} b_{i, j}$

    Los cuales existen por (1) y por (5) del \cref{thm:equivalencias de base de Gröbner}.

    \item $F' = \{g_{i, j} : i ∈ \{1, …, n\}, j ∈ \{1, …, k_i\}\}$

    \item $k ∈ ℕ$ el mínimo tal que $F' ⊆ \B_{e_≤}^k(F)$

    Notar que $k$ está bien definido porque $F'$ es finito.
  \end{itemize}

  Ahora vamos a probar que $\B_{e_≤}^k(F)$ es una base de Gröbner de $(F)$.

  Por (5) del \cref{thm:equivalencias de base de Gröbner} alcanza con probar:

  \[ ∀f ∈ (F) - \{0\} : ∃g_1, …, g_n ∈ \B_{e_≤}^k(F), a_1, …, a_n, b_1, …, b_n ∈ ⟨X⟩ : \lm(a_i g_i b_i) ≤ \lm(f) : f = ∑_{i = 1}^n a_i g_i b_i \]

  Tomemos $f' ∈ (F) - \{0\}$ y escribamoslo de esa forma:

  Por (5) del \cref{thm:equivalencias de base de Gröbner} sean $i'_1, …, i'_{n'} ∈ G, a'_1, …, a'_{n'}, b'_1, …, b'_{n'} ∈ ⟨X⟩$ tales que $\lm(a'_i g_{i'_i} b'_i) ≤ \lm(f')$ y $f' = ∑_{i = 1}^{n'} a'_i g_{i'_i} b'_i$

  \begin{DispWithArrows*}
    &f' = ∑_{i = 1}^{n'} a'_i g_{i'_i} b'_i \Arrow{Condición de $g_{i, j}$} \\
    & = ∑_{i = 1}^{n'} a'_i (∑_{j = 1}^{k_{i'_i}} a_{i', j} g_{i, j} b_{i', j}) b'_i \\
    & = ∑_{i = 1}^{n'} ∑_{j = 1}^{k_i'} a'_i a_{i', j} g_{i, j} b_{i', j} b'_i
  \end{DispWithArrows*}

  Sabemos además que $g_{i',j} ∈ \B_{e_≤}^k(F)$ y que $g_{i', j} ≤ g_{i'_i} ≤ f'$.

  Con esto queda completada la prueba.

\end{proof}

Con estos conjuntos podemos de forma directa dar un seudocódigo que los calcula:

\begin{algorithm}[H] % La H es para que se quede acá, porque se iba a otra página. Estaría bueno hacerlo global
  \caption{Algoritmo de Buchberger}\label{alg:Buchberger}
  \KwData{$F ⊆ K⟨X⟩$, $e_≤$ una estrategia de reducción}
  \KwResult{$G ⊆ K⟨X⟩$ una base de Gröbner de $(F)$ si es que termina}
  $G ← F$

  \Loop{} {
    $ambs ← \amb(G)$

    $new\_G ← G$

    \For{$α ∈ ambs$} {
      $f ← e_≤(G)(\S(α))$

      \If{$f ≠ 0$} {
        $new\_G ← new\_G ∪ \{f\}$
      }
    }

    \If{$new\_G = G$} {
      \Break
    }

    $G ← new\_G$
  }
  \Return{$G$}
\end{algorithm}

El algoritmo así, si bien es una implementación tal cual de la definición de los conjuntos $\B_{e_≤}^i$ que probamos que es correcta, es muy lenta y necesita un cambio para que pase a andar bien.

Ese cambio es en lugar de para las reducciones usar el conjunto anterior usar también los nuevos polinomios que ya fueron agregados, es decir, llamar a $e_≤$ con $new\_G$ en lugar de con $G$ en la linea 6. % Se podrá hacer con un label esto?

Por lo que habíamos visto antes el cambio tiene sentido que sea correcto y la prueba es similar a la del \cref{thm:Buchberger correctitud}.

En la implementación el cambio ese hace una diferencia inmensa en la eficiencia, pasa de no andar rápido casi nunca a andar rápido en un montón de casos. De forma teórica porque es algo que hace tanta diferencia es algo que no se ni puede encontrar en la literatura.

Hay otras dos optimizaciones mas que se pueden hacer a este algoritmo, una es para descartar algunas ambigüedades sin tener que reducirlas y la otra es para ir sacando algunos polinomios de la base. Ambos optimizaciones están explicadas en …, % Citar a Hof
y no se van a explicar acá.

\section{Algoritmo F4}

En esta sección se explica el algoritmo F4, que es otro algoritmo para calcular Bases de Gröbner.

La idea de F4 es agarrar varias ambigüedades y reducir todos sus S-polinomios al mismo tiempo, tanto reduciendo por los elementos que ya están en la base como reduciendo entre los propios S-polinomios que se están considerando. Para esto lo que se hace es convertir el problema en una reducción por filas de una matriz codificando cada monomio como una columna y cada polinomio como una columna.

Para hacer esto de codificar los polinomios como filas de una matriz vamos a necesitar algunas definiciones:

\begin{definition}
Sea $P ⊆ K⟨X⟩$:

\begin{itemize}
  \item $\spn_K(P) = \{∑_{i = 1}^n c_i p_i : n ∈ ℕ, c_i ∈ K, p_i ∈ P\}$
\end{itemize}

\end{definition}

\begin{definition}
Sean $M = \{m_1, …, m_n\} ⊆ ⟨X⟩$ tales que $m_1 > ⋯ > m_n$:

\begin{itemize}
  \item $\poli_T : K^n → \spn_K(M)$
  \item $\poli_T(v) = ∑_{i = 1}^n v_i m_i$
\end{itemize}

\end{definition}

\begin{definition}
Sean $M = \{m_1, …, m_n\} ⊆ ⟨X⟩$ tales que $m_1 > ⋯ > m_n$. $\mat_T$ aplicado a un polinomio se define como la inversa de $\poli_T$:

\begin{itemize}
  \item $\mat_T : \spn_K(M) → K^n$
  \item $\mat_T(p) = \poli_T^{-1}(p)$
\end{itemize}

$\mat_T$ aplicado a una lista de polinomios da una matriz:

\begin{itemize}
  \item $\mat_T(p_1, …, p_m) = \begin{pmatrix} \mat_T(p_1) \\ ⋮ \\ \mat_T(p_m) \end{pmatrix}$
\end{itemize}

\end{definition}

Estas definiciones nos permiten hablar de pasar de polinomios a matrices y viceversa.

Lo que antes en la reducción era restar un polinomio multiplicado por un escalar y un monomio a cada lado la idea es que ahora pase a ser restarle una fila multiplicada por un escalar a otra en la matriz, así que vamos a tener que empezar ya teniendo en la matriz los polinomios que vamos a restar ya multiplicados por los monomios a cada lado. Para eso definimos el algoritmo de preprocesamiento simbólico que dado el conjunto por el cual se reduce $G$ y el conjunto a reducir $P$ calcula todos los polinomios que van a ser necesarios:

\begin{algorithm}[H] % La H es para que se quede acá, porque se iba a otra página. Estaría bueno hacerlo global
  \caption{Preprocesamiento simbólico}\label{alg:Preprocesamiento simbólico}
  \KwData{$G, P ⊆ K⟨X⟩$ conjuntos finitos}
  \KwResult{$G' ⊆ \{agb : a, b ∈ ⟨X⟩, g ∈ G\}$}
  $G' ← ∅$

  $conciderados ← \{\lm(g) : g ∈ G\}$

  $T ← ⋃_{g ∈ G} \sop(\tail(g))$

  \While{$T ≠ ∅$} {
    elegir $m ∈ T$

    $T ← T - \{m\}$

    \For{$g ∈ G$} {
      \If{$\lm(g) | m$} {
        calcular $a$ y $b$ tales que $m = a \lm(g) b$

        $G' ← G' ∪ {agb}$

        $nuevos ← \{m' ∈ \sop(\tail(agb)) : m' ∉ conciderados\}$

        $T ← T ∪ nuevos$

        $conciderados ← conciderados ∪ nuevos$
      }
    }
  }

  \Return{$G'$}
\end{algorithm}

Ahora lo que hay que hacer es, al reducir, elegir varios polinomios para reducir, poner los polinomios elegidos y el resultado del preprocesamiento simbólico en una matriz, hacer la reducción por filas de esa matriz y después de alguna manera detectar filas son los polinomios elegidos reducidos para agregar solo esos polinomios a la base.

Para detectar esos polinomios lo que se hace es guardarse cuales son los monomios principales de elementos del resultado del preprocesamiento simbólico y después de hacer la reducción por filas agarrar solo las filas que tengan un uno principal en una columna que no corresponda a uno de esos monomios principales.

Eso se puede entender mejor viene este seudocódigo:

\begin{algorithm}[H] % La H es para que se quede acá, porque se iba a otra página. Estaría bueno hacerlo global
  \caption{Multireducción}\label{alg:Multireducción}
  \KwData{$G, P ⊆ K⟨X⟩$ conjuntos finitos}
  \KwResult{$P' ⊆ K⟨X⟩$}
  $G' ←$ Preprocesamiento simbólico$(G, P)$

  $monomios ← \{\lm(g) : g ∈ G'\}$

  $M ← \{m : m ∈ \sop(g), g ∈ G' ∪ P\}$

  $mat ← \mat_M(G' ∪ P)$

  hacer reducción por filas de $mat$

  $P' ← \{\poli_M(v) : v ∈ \filas(mat) : v ≠ 0 ∧ \lm(\poli_M(v)) ∉ monomios\}$

  \Return{$P'$}
\end{algorithm}

Y con esto se puede escribir el algoritmo F4:

\begin{algorithm}[H] % La H es para que se quede acá, porque se iba a otra página. Estaría bueno hacerlo global
  \caption{F4}\label{alg:F4}
  \KwData{$F ⊆ K⟨X⟩$, $e_≤$ una estrategia de reducción}
  \KwResult{$G ⊆ K⟨X⟩$ una base de Gröbner de $(F)$ si es que termina}
  $G ← F$

  \Loop{} {
    $ambs ← \amb(G)$

    $new\_G ← G$

    \While{$ambs ≠ ∅$} {
      elegir $Α ⊆ ambs$

      $ambs ← ambs - Α$

      $P ← \{\S(α) : α ∈ Α\}$

      $P ←$ Multireducción$(new\_G, P)$

      $new\_G ← new\_G ∪ P$
    }

    \If{$new\_G = G$} {
      \Break
    }

    $G ← new\_G$
  }

  \Return{$G$}
\end{algorithm}

Este algoritmo no especifica cuales ambigüedades elegir, pero una buena estrategia es elegir todas las de manor grado. Otra opción es elegir todas, pero eso puede hacer que las matrices se vuelvan muy grandes más rápido.

En … % Citar a Hof
se da un algoritmo muy parecido a este (con una diferencia mínima) y se demuestra que es correcto. Eso acá no está porque es muy tedioso.

Las optimizaciones mencionadas en la sección de Buchberger para descartar ambigüedades y para sacar polinomios de la base también se pueden hacer acá y otra optimización que se puede hacer acá es usar un algoritmo de reducción de matrices que anda mas rápido en las matrices de este problema en particular,  que se llama eliminación Faugère-Lachartre y que también está explicada en …. % Citar a Hof

\chapter{Librería}

Como se dijo al principio, para esta tesis se implementaron los algoritmos de Buchberger y F4 en C++ junto con estructuras para manejar polinomios no conmutativos. En este capítulo se explica como usar esa librería en su versión actual. % Quizás habría que aclarar que febrero de 2025 o algo así
Esa librería se está en GitHub en el repositorio \href{https://github.com/IvanRenison/Non-commutative-Grobner-Bases}{\texttt{Non-commutative-Grobner-Bases}}. % Está bien poner esto así?

\section{Estructura de las carpetas}

El repositorio está estructurado en las siguientes carpetas:

\begin{itemize}
  \item \texttt{ncgb}: Esta es la carpeta mas importante, tiene archivos \texttt{.hpp} con todas las implementaciones para incluir en otros códigos y usar las implementaciones, en la siguiente sección se explica como usar estos códigos.
  \item \texttt{mains}: En este carpeta hay varios archivos \texttt{.cpp} con función \texttt{main} que hacen distintas cosas. Cada archivo al comienzo tiene una pequeña explicación de que hace.
  \item \texttt{tests}: En esta carpeta están los tests, tanto los tests internos solo de código de la librería como un test que compara con la implementación de \texttt{operator\_gb}. % Quizás citar?
  \item \texttt{extras}: Esta carpeta lo único que tiene es una estructura de aritmética modular para usar en los mains.
  \item \texttt{.github/workflows}: En esta carpeta está la configuración para que los tests se corran automáticamente al subir los cambios a GitHub.
\end{itemize}

En las siguientes secciones se explica como usar los archivos de la carpeta \texttt{ncgb}.

\section{Estructura general de los códigos}

En la carpeta \texttt{ncgb} hay varios archivos con implementaciones de las distintas cosas. Todo esos archivos tienen el código adentro del namespace \texttt{ncgb}, así que para usar cualquier cosa hay que abrir \texttt{ncgb} o usar con \texttt{ncgb::}.

Como los polinomios son asociados a un cuerpo y además muchas cosas dependen de un orden monomial todo lo que usa polinomios tiene parámetros de template para ambas cosas, poniendo el orden lexicográfico por grado como parámetro por defecto para esto último. Por ejemplo, la definición de polinomio empieza así:

\begin{minted}{C++}
  template<typename K, class ord = DegLexOrd>
  struct Poly {
    ⋮
  };
\end{minted}
% El ⋮ no se ve

El tipo \texttt{K} tiene que tener implementadas todas las operaciones de cuerpo, incluyendo cosas como \texttt{+=}. En \texttt{extras/ModularArithmetic.hpp} se puede ver una implementación de aritmética modular que tiene todo lo que \texttt{K} tiene que tener. Para los números racionales el tipo \texttt{mpq\_class} de la librería \texttt{gmp} también tiene todo lo que \texttt{K} tiene que tener. Esos dos tipos son los que se usan en los mains de ejemplo de la carpeta \texttt{mains}.

\texttt{DegLexOrd} es el orden lexicográfico por grado y ya está definido junto con la definición de monomios. Para usar otro orden hay que definirlo definiendo una estructura que tenga definido un operador \texttt{()} que sea el orden. Algo así sería el código:

\begin{minted}{C++}
  struct Orden {
    bool operator()(const Monomial& a, const Monomial& b) const {
      ⋮
    }
  };
\end{minted}
% El ⋮ no se ve

Esto es así porque es una de las formas mas comunes de tomar un orden como template en C++.

\section{Monomios}

Los monomios están definidos como un tipo \texttt{Monomial} en el archivo \texttt{nc\_monomial.hpp}. Dentro del tipo las variables de representan con el tipo \texttt{Monomial::X} que está puesto en que sea \texttt{\_\_uint8\_t}. Para construir un elemento del tipo se puede usar el constructor vacío que crea el monomio vacío o el constructor que toma un vector de \texttt{Monomial::X} con las variables que tiene el monomio.

El tipo \texttt{Monomial} tiene implementada la multiplicación con \texttt{operator*} (y \texttt{operator*=}), la igualdad con \texttt{operator==}, un método \texttt{size} que devuelve el grado, un método \texttt{empty} que devuelve \texttt{true} si y solo si el monomio es el monomio vacío y varios relacionados a la división y a la representación de los monomios como strings.

Relacionado a la división el método mas importante es \texttt{divide\_indexes} que se llama como \texttt{m0.divide\_indexes(m1)} y devuelve un vector se \texttt{size\_t} que dice en que posiciones de \texttt{m1} empieza una sub-palabra igual a \texttt{m0}.

En cuanto a la representación como strings, hay dos pares de métodos, están \texttt{operator>>} y \texttt{operator<<} que leen y escriben en un formato de todo números que es cómodo para usar en código y \texttt{nice\_print} y \texttt{nice\_read} que son para leer y escribir en el formato en el que se suelen escribir a mano los monomios.

El formato fácil de leer desde código consiste en un número entero no negativo $n$ seguido de $n$ números $x_1$, …, $x_n$ que son los números de variables. Cuando $n = 0$ no hay ningún $x_i$. Se puede representar así el formato:

\begin{lstlisting}[escapechar=+]
  +$n$+ +$x_1$+ ⋯ +$x_n$+
\end{lstlisting}

Por ejemplo, acá hay un monomio en el formato como se suelen escribir a mano:

\begin{lstlisting}
  adbda
\end{lstlisting}

Y acá está el mismo monomio en el formato fácil de leer desde código:

\begin{lstlisting}[escapechar=+]
  5 0 3 1 3 0
\end{lstlisting}

\section{Polinomios}

Los polinomios están definidos en el archivo \texttt{nc\_polynomial.hpp}. Como ya se mostró antes, el tipo de los polinomios, \texttt{Poly}, tiene el cuerpo y un orden monomial como parámetros de template:

\begin{minted}{C++}
  template<typename K, class ord = DegLexOrd>
  struct Poly …
\end{minted}

Para construir un polinomio hay tres constructores, el constructor vacío que produce el polinomio $0$, un constructor que toma un monomio $m$ y un elemento del cuerpo $c$ y produce el polinomio $cm$ y un constructor que toma un vector de pares monomio coeficiente y produce el polinomio que es la suma de cada coeficiente multiplicado con su monomio.

El tipo \texttt{Poly} tiene implementadas todas las operaciones entre polinomios (como la suma) con los operadores correspondientes (como \texttt{operator+} y \texttt{operator+=} por ejemplo), métodos para lo definido en la \cref{def:cosas de polinomios} y métodos relacionados a la representación de los polinomios como strings.

Al igual que con los monomios, para la representación como strings, hay dos pares de métodos, \texttt{operator>>} y \texttt{operator<<} para formato de todo números y \texttt{nice\_print} y \texttt{nice\_read} para formato visualmente bonito.

El formato de solo números consiste en, primero un número entero no negativo $m$, la cantidad de términos, seguido de la descripción de $m$ términos. La descripción de cada término consiste en primero el coeficiente y después la descripción del monomio. El coeficiente tiene se lee haciendo \texttt{>> c} donde \texttt{c} es una variable de tipo \texttt{K}, así que \texttt{K} tiene que tener \texttt{>>} implementado para que se pueda leer polinomios. Se puede representar así el formato:

\begin{lstlisting}[escapechar=+]
  +$m$+
  +$c_1$+ +$n_1$+ +$x_{1, 1}$+ +$⋯$+ +$x_{1, n_1}$+
  +$⋮$+
  +$c_m$+ +$n_m$+ +$x_{m, 1}$+ +$⋯$+ +$x_{m, n_m}$+
\end{lstlisting}

Por ejemplo, acá hay un polinomio en el formato como se suelen escribir a mano:

\begin{lstlisting}
  3 aaa - 5 bcc + adbda
\end{lstlisting}

Y acá está el mismo monomio en el formato fácil de leer desde código:

\begin{lstlisting}[escapechar=+]
  3
  3 3 0 0 0
  -5 3 1 2 2
  1 5 0 3 1 3 0
\end{lstlisting}

\section{Buchberger y F4}

Los algoritmos de Buchberger y F4 están ambos hechos de una forma que se usan similar, así que por eso están explicados juntos.

Como ambos algoritmos tienen el problema de que puede no terminar no se puede hacer directamente una función que tome el conjunto generador y devuelva una base de Gröbner porque podría no terminar.

Se podría hacer una función que además del conjunto generador tome un número que sea la cantidad de pasos a ejecutar y que además de devolver un conjunto devuelva si se llegó a una base de Gröbner o no. Esta opción tiene el problema de que si se quiere después hacer mas pasos de la ejecución habría que volver a empezar, llamando a la función con un número mas grande.

Para evitar ese problema lo que se hizo es definir una estructura que el constructor tome a los polinomios y tenga un método \texttt{next} que calcula un paso mas del calculo de la base de Gröbner y en caso de haber terminado lo dice y un método \texttt{fullBase} para usar solo en el caso de que se sepa que hay una base finita, que hace las llamadas a \textt{next} hasta que termina y devuelve la base.

Para Buchberger la estructura está en el archivo \texttt{Buchberger.hpp} y se llama \texttt{BuchbergerIncremental} y para F4 la estructura está en el archivo \texttt{F4.hpp} y se llama \texttt{F4Incremental}. En el caso de Buchberger el método \texttt{next} devuelve un \texttt{std::optional<Poly<K, ord>>} que es vacío solo en el caso de que ya se haya llegado a una base de Gröbner y si no tiene un polinomio de la base de Gröbner. En el caso de F4 el método \texttt{next} devuelve un \texttt{std::vector<Poly<K, ord>>} que es vacío solo en el caso de que ya se haya llegado a una base de Gröbner y si no tiene varios polinomios de la base de Gröbner. En ambos casos devolver vacío es la forma de decir que ya terminó el algoritmo.

Para ambos algoritmos hay además una función \texttt{inIdeal} que toma un conjunto generador, un polinomio y una cantidad pasos y trata de decir si el polinomio está en el ideal generado por el conjunto generador haciendo esa cantidad de llamada a \texttt{next}. Esa función devuelve un elemento de el siguiente tipo (con los significados que están comentados comentados):

\begin{minted}{C++}
  enum IdealMembershipStatus {
    InIdeal,    // The element is definitely in the ideal
    NotInIdeal, // The element is definitely not in the ideal
    Unknown     // More steps are needed to determine if the element is in the ideal
  };
\end{minted}

Esa función sería básicamente la que trata de responder a la pregunta que plantemos al comienzo de si un polinomio está en el ideal generado por un conjunto generador.

\section{Construcción de la respuesta}

La función \texttt{inIdeal} hace lo de intentar responder a la pregunta de si un polinomio está en el ideal generado por un conjunto generador, pero en el caso de que la respuesta es que si está no nos da la forma de escribirlo como combinación lineal de elementos del conjunto generador con polinomios como coeficientes.

Con las bases de Gröbner pasa lo mismo, los algoritmos nos dan la base pero no nos dan como se escriben los elementos de la base usando los elementos del conjunto generador.

Así como están todo en la explicación del algoritmo de Buchberger no nos da una forma directa de construir esa escritura. Pero, en todos los pasos en los que se manejan polinomios siempre se hace sumando o restando polinomios del conjunto generador o que ya están en la base, así que se puede para cada polinomio ir guardando siempre que sea hace con el y usar eso para obtener la escritura usando los elementos del conjunto generador.

Para el caso de F4 no es tan directo, pero si cuando se hace la reducción por filas de la matriz se guarda que operaciones por filas se hicieron también se puede.

Para Buchberger esto está implementado en el mismo archivo \texttt{Buchberger.hpp} en unas funciones y structs que terminan en \texttt{Reconstruct} (esta terminación es porque van guardando la información que permite \emph{reconstruir} la respuesta).

Estas funciones lo que hacen es devolver elementos del tipo \texttt{InIdealPoly} definido en el archivo \texttt{nc\_polyonomial\_inIdeal.hpp}. Este tipo lo que hace es representar un polinomio como una combinación lineal de elementos del conjunto generador, en particular guarda un vector de elementos $m$, $j$, $m'$, $c$ de forma que, si los $g_i$ son el conjunto generador, el polinomio representado es $∑ m g_i m' c$.

Para F4 esto no está implementado (en el siguiente capitulo se dice porque).

\chapter{Implementación}

En este capitulo se explican los detalles de como está hecha la implementación.

\section{Comparación de bases}

Por último para esta sección, en el archivo \texttt{cmpBases.hpp} está la función \texttt{cmpBases} que toma dos conjuntos generadores y, asumiendo que son bases de Gröbner, dice si generan el mismo ideal o no.

\section{Monomios}

Los monomios, o sea los elementos de $⟨X⟩$, como son palabras se implementaron usando vectores para de números sin signo. La base de la implementación es así:

\begin{minted}{C++}
  struct Monomial {
    typedef __uint8_t X;
    vector<X> vals;
  };
\end{minted}

Con esto, como \texttt{\_\_uint8\_t} tiene 8 bits se pueden tener hasta 256 variables. Cuando los monomios se imprimen o leen de forma bonita solo hay 26 variables, correspondiendo el 0 con la \texttt{a}. Si se quiere imprimir de forma bonita un monomio que usa variables mayores o iguales a 26 salta una aserción.

Está estructura tiene implementadas las operaciones y métodos que se describieron en el capitulo anterior. La mayoría tienen una implementación directa. Las únicas no directas son las relacionadas a la division, porque chequear divisibilidad es chequear si una palabra es sub-palabra de otra, lo cual la forma directa de hacerlo lleva tiempo cuadrática (en el largo de la palabras), pero se puede hacer en tiempo lineal.

Hay muchas formas de hacerlo en tiempo lineal, la que se usó es usar la función Z (que en el código está en el archivo \texttt{Zfunc.hpp}). En … % Citar a cp-algorithms: https://cp-algorithms.com/string/z-function.html
se explica la función Z y como usarla para chequear si una palabra es sub-palabra de otra.
% También quizás tiene sentido aclarar que no es la misma que la función ζ de Riemann, que es lo primero que aparece al buscar en google "función Z"

Junto con la implementación de los monomios, en el archivo \texttt{nc\_monomial.hpp} está la implementación del orden lexicográfico por grado.

\section{Polinomios}

Los polinomios, o sea los elementos de $K⟨X⟩$ están implementados usando un vector de pares monomio coeficiente que siempre se mantiene ordenado por el orden monomial. La base de la implementación es así:

\begin{minted}{C++}
  template<typename K, class ord = DegLexOrd>
  struct Poly {
    vector<pair<Monomial, K>> terms;
  };
\end{minted}

Con esta estructura para los polinomios todas las operaciones se hace de forma directa.

El orden de los polinomios está definido como \texttt{template<typename K, class ord = DegLexOrd> struct PolyOrd}.

\section{Reducciones}

La reducción están implementadas en el archivo \texttt{reductions.hpp}, en particular en la función \texttt{reduce} que toma un polinomio y un vector de polinomios y reduce el polinomio con los polinomios del vector. La reducción se hace modificando el propio argumento. Esa función sería una implementación de una estrategia de reducción concreta.

Esa reducción concreta lo que hace es siempre tratar de reducir por los primeros elementos del vector primero y tratar de reducir primero los monomios mas grandes del polinomio.

En el archivo también hay una función \texttt{reduce} que además toma un vector de booleanos que tiene que ser del mismo largo que el vector de polinomios y hace la reducción solo con los polinomios que tengan un \texttt{true} en la misma posición en el vector de booleanos. Esta función está para poder implementar la optimización de ir eliminando algunos elementos de la base sin tener que estar modificando un vector.

\section{Ambigüedades}

Las ambigüedades, que son necesarias para el algoritmo de Buchberger están implementadas en el archivo \texttt{ambiguities.hpp} y conciten en una estructura así:

\begin{minted}{C++}
  struct Amb {
    const Monomial& p, q;
    enum Type { Inclusion, Overlap };
    Type type;
    size_t pos; // position where q starts in p
    Monomial a, b;
  };
\end{minted}

Y los métodos \texttt{size} y \texttt{lm}.

Los campos de la ambigüedad son:

\begin{itemize}
  \item \texttt{p} y \texttt{q} son referencias a los monomios sobre los cuales es la ambigüedad. El motivo por el cual se guardan en la estructura es para poder implementar una de las optimizaciones.
  \item \texttt{type} es si la ambigüedad es de inclusión o de sobreposición.
  \item \texttt{pos} es en que posición de \texttt{p} empieza el pedazo que es en común con \texttt{q} y por el cual existe la ambigüedad.
  \item \texttt{a} y \texttt{b} son los monomios que hacen que en el caso de las de inclusión \texttt{p} sea igual a \texttt{aqb} y en el caso de las de sobreposición \texttt{ap} sea igual a \texttt{qb}.
\end{itemize}

En el archivo también está \texttt{ambiguities} que toma dos monomios y devuelve un vector de \texttt{Amb} con todas las ambigüedades entre sos dos monomios. En esta función al igual que en la divisibilidad de monomios se usa la función Z para evitar tener que hacer algo cuadrático en los largos de los monomios.

Después en el archivo está la función \texttt{S\_poly}que toma una ambigüedad y dos polinomios que deberían ser pos polinomios correspondientes y desvuelve el S-polinomio correspondiente.

Y por último está la función \texttt{checkDeletionCriteria} que implementa la optimización que permite descartar algunas ambigüedades sin tener que reducirlas.


\section{Buchberger}

Como ya se dijo antes, por el tema de que el algoritmo puede no terminar, se hace lo de usar una estructura con una método \texttt{next}. En esa estructura ya está implementada las optimizaciones antes mencionadas, pero en esta sección primero se explica como sería la estructura sin esas optimizaciones y después algo de como se agregan.

La base de esa estructura es así:

\begin{minted}{C++}
  template<typename K, class ord = DegLexOrd>
  struct BuchbergerIncremental {
    std::vector<Poly<K, ord>> G;
    std::queue<std::tuple<Amb, size_t, size_t>> ambs;
    size_t t = 0;
  };
\end{minted}

Los campos de esta estructura guardan los siguiente:

\begin{itemize}
  \item \texttt{G} es la base de Gröbner que se está construyendo. Al principio se inicializa con los polinomios con los que se llama al constructor.
  \item \texttt{ambs} son las ambigüedades que todavía no se procesaron junto con los índices en \texttt{G} de los polinomios a los que corresponde la ambigüedad. Se usa una queue para procesar siempre la que hace mas tiempo está esparando.
  \item La variable \texttt{t} está porque como la base de Gröbner incluye a los polinomios originales las primeras llamadas a \texttt{next} tienen que devolver esos polinomios y \texttt{t} lo que hace es indicar cuantos de esos ya se devolvieron. Cuando \texttt{t} es igual al tamaño de \texttt{G} es porque ya se devolvieron todos esos.
\end{itemize}

% La estructura además de tener los métodos \texttt{next} y


\end{document}
